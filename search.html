<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Search Result</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    
    <!-- custom.css -->
    <link rel="stylesheet" type="text/css" href="/assets/built/custom.css" />
    
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- 웹폰트 추가-->
    <link rel="stylesheet" href="https://fonts.googleapis.com/earlyaccess/nanumgothic.css">

    <!-- syntax.css 추가-->
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />

    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="데이터 사이언티스트를 꿈꾸는 블로그입니다." />
    <link rel="shortcut icon" href="https://keonju2.github.io/assets/built/images/favicon.jpg" type="image/png" />
    <link rel="canonical" href="https://keonju2.github.io/search" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="주건나's Blog" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Search Result" />
    <meta property="og:description" content="데이터 사이언티스트를 꿈꾸는 블로그입니다." />
    <meta property="og:url" content="https://keonju2.github.io/search" />
    <meta property="og:image" content="https://keonju2.github.io/assets/built/images/blog-cover1.jpg" />
    <meta property="article:publisher" content="https://www.facebook.com/monkeykeonju" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Search Result" />
    <meta name="twitter:description" content="데이터 사이언티스트를 꿈꾸는 블로그입니다." />
    <meta name="twitter:url" content="https://keonju2.github.io/" />
    <meta name="twitter:image" content="https://keonju2.github.io/assets/built/images/blog-cover1.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="주건나's Blog" />
    <meta name="twitter:site" content="@" />
    <meta name="twitter:creator" content="@" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="666" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "주건나's Blog",
        "logo": "https://keonju2.github.io/"
    },
    "url": "https://keonju2.github.io/search",
    "image": {
        "@type": "ImageObject",
        "url": "https://keonju2.github.io/assets/built/images/blog-cover1.jpg",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://keonju2.github.io/search"
    },
    "description": "데이터 사이언티스트를 꿈꾸는 블로그입니다."
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Search Result" href="/feed.xml" />


</head>
<body class="page-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- < default -->
<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<!-- The big featured header, it uses blog cover image as a BG if available -->
<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="https://keonju2.github.io/">주건나's Blog</a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-R" role="menuitem"><a href="/tag/programming/">프로그래밍 언어</a></li>
    <li class="nav-python" role="menuitem"><a href="/tag/project/">프로젝트</a></li>
    <li class="nav-python" role="menuitem"><a href="/tag/license/">자격증</a></li>
    <li class="nav-python" role="menuitem"><a href="/tag/study/">이론 공부</a></li>
    <li class="nav-archive" role="menuitem">
        <a href="/archive.html">All Posts</a>
    </li>
    <li class="nav-archive" role="menuitem">
        <a href="/author_archive.html">Tag별 Posts</a>
    </li>
</ul>
        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
                <a class="social-link social-link-fb" href="https://facebook.com/monkeykeonju" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
</a>
            
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Search</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  post page no-image">

            <header class="post-full-header">
                <h1 class="post-full-title">Search Result</h1>
            </header>

            

            <section class="post-full-content">
                <form action="/search" method="get" hidden="hidden">
    <label for="search-box"></label>
    <input type="text" id="search-box" name="query">
</form>

<ul class="mylist" id="search-results"></ul>

<script>
    window.store = {
    
    "license-adsp2": {
        "title": "ADSP (2) 데이터의 가치와 미래",
            "author": "keonju",
            "category": "",
            "content": "ADSP 관련 글    ADSP (1) 데이터의 이해    ADSP (2) 데이터의 가치와 미래    ADSP (3) 데이터 분석 기회의 이해    ADSP (4) 분석 마스터플랜ADSP를 준비하면서 공부한 내용을 정리한 글입니다.1과목 2장 데이터의 가치와 미래에 대한 부분을 정리한 글입니다.  빅데이터의 이해          빅데이터의 특징      빅데이터의 출현 배경      빅데이터의 기능과 변화        데이터의 가치와 미래          빅데이터의 가치      빅데이터 활용 기술      빅데이터의 위기 요인과 통제 방안        가치창조를 위한 데이터 사이언스와 전략 인사이트          빅데이터 분석과 전략 인사이트      데이터 사이언스에 대한 이해      빅데이터의 이해빅데이터란 큰 용량과 복잡성으로 기존 애플리케이션이나 툴로는 다루기 어려운 데이터셋의 집합빅데이터의 특징3VVolume데이터 양의 증가Variety데이터 유형 증가Velocity데이터 수집 및 처리 속도의 증가4V4V는 3V에 추가된 특징이다.Value데이터 가치의 중요성Veracity예측 분석 결과에 대한 신뢰성의 중요성밑에 두개는 의견이 갈린다Visualization데이터의 시각화Variability데이터의 가변성Validility데이터의 정확성Volarility데이터의 휘발성빅데이터 출현 배경  데이터의 양적 증가과학기술의 발달로 인한 데이터의 양적 증가  산업계의 변화정보의 축적과 기술이 만나 새로운 가치를 창출할 수 있는 변화의 상태  학계의 변화다양한 분야에서의 데이터 이용으로 필요한 기술 아키텍처 및 통계 도구의 발전  관련 기술의 발전디지털화, 저장 기술의 발전과 가격 하락, 인터넷의 발전과 클라우드 컴퓨팅와 같은 빅데이터와 연관된 기술의 발전빅데이터의 기능과 변화빅데이터는 석탄, 철, 원유, 렌즈, 플랫폼과 같은 역할을 한다.빅데이터로 인한 변화사전처리 -&gt; 사후처리표본조사 -&gt; 전수조사질 -&gt; 양인과관계 -&gt; 상관관계데이터 처리, 저장, 분석, 아키텍처, 클라우드 컴퓨팅과 같은 기술 변화데이터의 양, 유형, 수집 및 처리 기술과 같은 데이터의 변화데이터 사이언티스트, 데이터 중심 조직과 같은 인재 조직 변화데이터의 가치와 미래빅데이터의 가치빅데이터의 가치는 어떻게 활용할 것인지에 달렸다.데이터의 활용 방식, 가치 창출 방식, 분석 기술의 발전과 같은 이유로 가치 산정은 어렵다.빅데이터 활용 기술      연관규칙 학습 (Association rule learning)변인간의 상관 관계를 찾는 방법        유형분석 (Classification tree analysis)새로운 사건이 속할 범주를 찾는 방법        유전 알고리즘 (Genetic algorithms)최적화가 필요한 문제의 해결책의 진화 방법        기계학습 (Machine learning)훈련 데이터로부터 학습한 알려진 특성을 활용해 예측하는 방법        회귀분석 (Regression analysis)독립변수를 조작하면서 종속변수가 어떻게 변하는지 보며 관계를 파악하는 방법        감정분석 (Sentiment analysis)특정 주제에 대한 말이나 글의 감정을 분석하는 방법        소셜 네트워크 분석 (Social network analysis)사회 관계망 분석으로 사람 사이의 관계를 분석하는 방법  빅데이터의 위기 요인과 통제 방안위기 요인      사생활 침해개인의 사생활 침해 및 정보의 오용 위험        책임 원칙 훼손알고리즘으로 인한 피해 발생 위험        데이터 오용데이터 과신 및 잘못된 지표 사용으로 피해 발생 위험  통제 방안      사생활 침해의 통제 방안제공자의 ‘동의’에서 사용자의 ‘책임’으로개인정보 비식별 기술 (데이터 마스킹, 가명 처리, 총계 처리, 값 삭제, 범주화)        책임 원칙 훼손의 통제 방안결과 기반 책임 원칙 고수        알고리즘 접근 허용알고리즘으로 인한 피해 발생 시 알고리즘 접근을 허용하여 피해자 구제  가치창조를 위한 데이터 사이언스와 전략 인사이트빅데이터 분석과 전략 인사이트빅데이터에서 중요한 것은 ‘크기’가 아니라 ‘인사이트’이다.데이터 분석을 많이 사용하는 것이 아닌 전략적으로 사용해야 효과적인 운영이 가능하다.일차원적 분석에서 시작하여 전략 도출을 위한 가치 기반 분석까지 확장되어야한다.데이터 사이언스에 대한 이해데이터 사이언스는 데이터로부터 의미 있는 정보를 추출해내는 학문데이터 마이닝은 분석에 포커스를 둔다면 데이터 사이언스는 분석뿐 아니라 효과적으로 구현하고 전달하는 과정까지 포괄하는 개념수학, 확률 모델, 머신러닝, 분석학, 패턴 인식과 같은 Analytics,프로그래밍, 데이터 엔지니어링, 데이터 웨어하우징과 같은 Data Management,커뮤니케이션, 시각화, 프레젠테이션, 스토리텔링과 같은 비즈니스 분석으로 구성된다.기술적 능력으로 이루어진 하드 스킬과 분석, 전달, 협력으로 이루어진 소프트 스킬이 합쳐져야한다.따라서 인문학적 사고 특성도 길러야한다.",
        "url": "/license-adsp2"
    }
    ,
    
    "license-adsp1": {
        "title": "ADSP (1) 데이터의 이해",
            "author": "keonju",
            "category": "",
            "content": "ADSP 관련 글    ADSP (1) 데이터의 이해    ADSP (2) 데이터의 가치와 미래    ADSP (3) 데이터 분석 기회의 이해    ADSP (4) 분석 마스터플랜ADSP를 준비하면서 공부한 내용을 정리한 글입니다.1과목 1장 데이터 이해에 대한 부분을 정리한 글입니다.  데이터의 정의          데이터의 유형        데이터와 정보          DIKW 피라미드      데이터의 단위        데이터베이스 개요          데이터베이스의 특징      데이터베이스의 활용      데이터베이스의 종류      SQL의 이해      데이터베이스 구성요소      데이터의 정의데이터란?기술적이고 사실적인 의미의 자료. 객관적 사실정보는 데이터로 부터 얻은 것으로 가공된 자료존재적 특성있는 그대로의 객관적 사실당위적 특성데이터는 추론, 예측, 전망, 추정을 위한 근거데이터의 유형정성적 데이터 (언어, 문자)집합으로 표현할 수 없는 기준이 명확하지 않은 데이터정량적 데이터 (수치, 모형, 기호)집합으로 표현할 수 있는 기준이 명확한 데이터정형 데이터 (CSV, 엑셀)고정된 틀을 가지고 있으며 연산이 가능한 데이터로 관계형 DB에 저장하며 수집과 관리가 용이비정형 데이터 (소셜 데이터, 댓글, 음성, 영상)고정된 틀이 존재하지 않고 연산이 불가능관계형 DB가 아닌 NoSQL DB에 저장반정형 데이터 (XML, JSON, 센서 데이터)고정된 형태는 있지만 연산이 불가능테이블 형태보다는 파일 형태로 저장하여 가공을 거쳐 정형 데이터로 변환 가능암묵지와 형식지암묵지학습과 체험을 통해 개인에게 습득되어 있지만 겉으로 드러나지 않는 상태의 지식형식지암묵지를 여러 사람이 공유할 수 있게 형상화된 지식개인에 내면화된 암묵지가 출화하고 이를 개인의 지식으로 연결화 되는 과정을 거치면 조직의 지식으로 공통화되어 형식지가 된다.데이터와 정보DIKW 피라미드데이터 (Data)개별 데이터 자체는 의미가 중요하지 않은 객관적 사실정보 (Information)데이터의 가공, 처리와 데이터 간 연관 관계 속에서 의미 도출정보가 내포하는 의미는 유용하지 않을 수 있음지식 (Knowledge)데이터를 통해 얻은 정보를 구조화하여 유의미한 정보를 분류하고 경험과 결합해 고유의 지식으로 내재화지혜 (Wisdom)지식의 축적과 아이디어가 결합된 창의적 산물데이터 단위비트‘0’과 ‘1’의 두 가지 값으로 신호를 나타내는 최소단위바이트8개의 비트로 구성된 데이터의 양을 나타내는 단위숫자와 영어는 1바이트, 한글은 2바이트킬로-메가-기가-테라-페타-엑사-제타-요타 (각 단위는 1024배)데이터베이스 개요DB체계적으로 수집, 축적하여 다양한 용도와 방법으로 이용할 수 있게 정리한 정보의 집합체DBMS이용자가 쉽게 데이터베이스를 구축, 유지할 수 있게 하는 관리 소프트웨어데이터베이스의 특징통합된 데이터동일한 내용의 데이터가 중복되어 있지 않다.저장된 데이터컴퓨터가 매체에 접근할 수 있는 저장 매체에 저장되어 있다.공용 데이터여러 사용자가 공유할 수 있다.변화하는 데이터삽입, 수정, 삭제를 통해 항상 현재의 정확한 데이터를 유지해야 한다.정보의 축적 및 전달 측면기계의 가독성대량의 정보를 일정한 형식에 따라 정보처리기기가 읽고 쓸 수 있다.검색 가능성다양한 방법으로 필요한 정보를 검색할 수 있다.원격 조작성정보통신망을 통해 원거리에서도 즉시 온라인으로 이용 가능하다.트랜잭션 특성트랜잭션이란 데이터 베이스에서 명령을 수행하는 하나의 논리적 기능 단위원자성데이터베이스에 모두 적용되거나 모두 적용되지 않아야 한다일관성트랜잭션의 결과는 항상 일관성을 띠어야 한다고립성하나의 트랜잭션이 다른 트랜잭션에 영향을 주지 않아야 한다지속성트랜잭션이 성공적으로 수행된 경우 그 결과는 영구적이어야 한다데이터베이스 활용기업 내부의 데이터베이스 활용인하우스 DB, OLTP, OLAP, CRM, SCM, ERP, BI, RTE 등이 있다.사회 기반 구조 데이터베이스물류 부문CALS, PORT-MIS, KROIS지리부문GIS, LBS, SIM교통부문ITS의료부문PACS, U-Health교육부문NEIS데이터베이스의 종류관계형 데이터베이스데이터를 테이블에 저장되고 하나의 열은 하나의 속성을 나타내고 같은 속성 값만 가진다. 정형 데이터를 다루는 데 좋다.Oracle, MySQL, MS-SQL, SQLiteNoSQL비관계형을 의미하며 대용량의 데이터 분석 및 분산 처리에 용이하다.MongoDB, Dynamo, BigtableSQL의 이해SQL은 DBMS에서 데이터베이스에 내리는 명령이다.DB마다 문법이 다르지만 기본적인 데이터 추출과 분석에 사용되는 문법은 거의 동일하다.데이터 정의 언어 (DDL)CREATE, ALERT, RENAME, DROP데이터 조작 언어 (DML)SELECT, INSERT, UPDATE, DELETE데이터 제어 언어 (DCL)GRANT, REVOKE트랜잭션 제어 언어 (TCL)COMMIT, SAVEPOINT, ROLLBACK데이터베이스 구성요소인스턴스하나의 객체를 의미 (홍길동, 남자,000-0000-0000)속성객체를 표현하기 위해 사용되는 값 (이름, 성별, 주민번호)엔터티데이터의 집합, 테이블과 달리 개념적인 존재메타데이터데이터를 설명하는 데이터인덱스데이터베이스에 저장할 때 지정되는 데이터의 이름",
        "url": "/license-adsp1"
    }
    ,
    
    "study-ml4": {
        "title": "머신러닝 정리 (4) &lt;br&gt; 비지도학습 (2)",
            "author": "keonju",
            "category": "",
            "content": "머신러닝 공부 관련 글    머신러닝 정리 (1)-지도학습 (1)    머신러닝 정리 (2)-지도학습 (2)    머신러닝 정리 (3)-비지도학습 (1)    머신러닝 정리 (4)-비지도학습 (2)머신러닝 정리 (4) - 비지도학습 (2)본 문서는 [파이썬 라이브러리를 활용한 머신러닝] 책을 공부하면서 요약한 내용입니다.또 데이터 청년 캠퍼스 수업과 학교 수업에서 배운 내용들도 함께 정리했습니다.글의 순서는 [파이썬 라이브러리를 활용한 머신러닝]에 따라 진행됩니다.코드는 밑에 링크에 공개되어있기 때문에 올리지않습니다.소스 코드: https://github.com/rickiepark/introduction_to_ml_with_python비지도학습 (2)  군집          계층적 군집분석      비계층적 군집분석        K-평균 군집  병합 군집  DBSCAN  군집 알고리즘의 비교와 평가          타깃 값으로 군집 평가하기      타깃 값 없이 군집 평가하기      군집군집(clusterling)은 데이터셋을 클러스터라는 그룹으로 나누는 작업입니다.기본적으로 거리에 관련된 측정 방법을 활용합니다.한 클러스터 안의 데이터 포인트끼리는 매우 비슷하고 다른 클러스터의 데이터 포인트와는 구분되도록 데이터를 나누는 것이 목표입니다.유사성을 측정하는 것에는 군집 간 분산이 최대화 되거나, 군집 내 분산을 최소화하게 됩니다.종류계층적 군집분석각 요소들로부터 시작한 클러스터들이 계층 구조를 이루도록 군집분석을 수행합니다.이 때 만들어진 계층구조를 덴드로그램이라고 합니다.비계층적 군집분석각 클러스터의 계층을 고려하지 않고 평면적으로 군집분석을 수행합니다.K-평균 군집k-평균(k-means) 군집은 데이터의 어떤 영역을 대표하는 클러스터 중심을 찾습니다.알고리즘은 먼저 데이터 포인트를 가장 가까운 클러스터 중심에 할당하고 클러스터에 할당된 데이터 포인트의 평균으로 클러스터 중심을 다시 지정합니다.클러스터에 할당되는 데이터 포인트에 변화가 없을 때 알고리즘이 종료됩니다.  데이터 포인트를 무작위로 초기화합니다.  각 데이터 포인트를 가장 가까운 클러스터 중심에 할당합니다.  할당한 포인트의 평균값으로 클러스터 중심을 갱신합니다.  더이상 포인트에 변화가 없다면 알고리즘이 멈춥니다.K 값을 설정하는 방법으로는 elbow method, silhouette method와 같은 방법이 있습니다.K-means 사용 방법from sklearn.datasets import make_blobsfrom sklearn.cluster import KMeans# 인위적으로 2차원 데이터를 생성합니다X, y = make_blobs(random_state=1)# 군집 모델을 만듭니다kmeans = KMeans(n_clusters=3)kmeans.fit(X)# 라벨을 확인합니다print(kmeans.labels_)k-means는 지정해준 cluster 값만큼 데이터를 분류해줍니다.또한 cluster 개수만큼 label은 0부터 값을 순서대로 가집니다.하지만 cluster 값을 잘 지정해준다고 하더라도 분류가 실패하는 경우가 생깁니다.‘모든 클러스터의 반경이 똑같다’, ‘클러스터에서 모든 방향이 똑같이 중요하다’ 라는 두 가지 가정을 가지고 있기 때문에 중심에서 멀리 떨어진 경우에 데이터를 잘 처리하지 못합니다.즉, 서로 원형으로 잘 모여있는 데이터에 대해서는 잘 구분하지만 모양이 복잡할수록 더 성능이 나빠집니다.K-means는 클러스터 중심, 하나의 성분으로 표현된다고 볼 수 있습니다.하나의 성분으로 분해되는 관점으로 보는 것을 벡터 양자화라고 합니다.벡터 양자화는 입력 데이터의 차원보다 더 많은 클러스터를 사용해 데이터를 인코딩할 수 있습니다.즉, 2차원 데이터에서도 10개의 클러스터를 사용해 10개의 특성을 가지는 모델을 만들 수 있습니다.장점  이해하기 쉽다.구현하기 쉽다.비교적 빠르다.유연하고 효율적이다.단점  난수 초깃값에 따라 달라진다.활용 범위가 제한적이다.클러스터의 개수를 지정해야한다.최적의 군집을 찾기 어렵다.군집 개수 파악에 대한 합리적 추측이 필요하다.이상치나 노이즈에 민감하다.병합 군집병합 군집은 알고리즘은 시작할 때 각 포인트를 하나의 클러스터로 지정하고 어떤 종료 조건을 만족할 때 까지 가장 비슷한 두 클러스터를 합쳐나갑니다.종료 조건은 클러스터 개수로 하여 지정된 개수의 클러스터가 남을 때까지 비슷한 클러스터를 합칩니다.wardward 연결은 모든 클러스터 내의 분산을 가장 작게 증가시키는 두 클러스터를 합칩니다.따라서 크기가 비슷한 클러스터가 만들어집니다.averageaverage 연결은 클러스터 포인트 사이의 평균 거리가 가장 짧은 두 클러스터를 합칩니다.completecomplete 연결은 클러스터 포인트 사이의 최대 거리가 가장 짧은 두 클러스터를 합칩니다.singlesigle 연결은 클러스터 포인트 사이의 최소 거리가 가장 짧은 두 클러스터를 합칩니다.클러스터는 다음과 같은 모습으로 합쳐집니다.클러스터의 사용 방법은 다음과 같습니다.from sklearn.cluster import AgglomerativeClusteringX, y = make_blobs(random_state=1)agg = AgglomerativeClustering(n_clusters=3)assignment = agg.fit_predict(X)mglearn.discrete_scatter(X[:, 0], X[:, 1], assignment)plt.legend([\"클러스터 0\", \"클러스터 1\", \"클러스터 2\"], loc=\"best\")plt.xlabel(\"특성 0\")plt.ylabel(\"특성 1\")병합 군집은 계층적 군집을 만듭니다.계층적 군집은 Scipy에서 덴드로그램을 통해 다차원 데이터셋을 처리하여 시각화 할 수 있습니다.from scipy.cluster.hierarchy import dendrogram, wardX, y = make_blobs(random_state=0, n_samples=12)# 데이터 배열 X 에 ward 함수를 적용합니다# SciPy의 ward 함수는 병합 군집을 수행할 때 생성된# 거리 정보가 담긴 배열을 리턴합니다linkage_array = ward(X)# 클러스터 간의 거리 정보가 담긴 linkage_array를 사용해 덴드로그램을 그립니다dendrogram(linkage_array)# 두 개와 세 개의 클러스터를 구분하는 커트라인을 표시합니다ax = plt.gca()bounds = ax.get_xbound()ax.plot(bounds, [7.25, 7.25], '--', c='k')ax.plot(bounds, [4, 4], '--', c='k')ax.text(bounds[1], 7.25, ' 두 개 클러스터', va='center', fontdict={'size': 15})ax.text(bounds[1], 4, ' 세 개 클러스터', va='center', fontdict={'size': 15})plt.xlabel(\"샘플 번호\")plt.ylabel(\"클러스터 거리\")DBSCANDBSCAN은 클러스터의 개수를 미리 지정할 필요가 없습니다.복잡한 형상도 찾을 수 있으며 어떤 클래스에 속하지 않는 포인트도 구분할 수 있습니다.병합 군집이나 k-means보다 다소 느리지만 큰 데이터 셋에도 적용할 수 있습니다.DBSCAN은 특성 공간에서 가까이 있는 데이터가 많아 붐비는 지역을 포인트로 찾습니다.밀집 지역이 한 클러스터를 구성하며 비어있는 지역을 경계로 다른 클러스터와 구분된다는 것입니다.밀도: 자기를 중심으로 반지름 안에 있는 다른 좌표점의 개수최소 거리: 이웃을 정의하기 위한 거리, 밀도 측정 반지름최소 데이터 개수: 밀집 지역을 정의하기 위해 필요한 이웃의 개수, 반지름 내에 있는 최소 데이터의 개수  무작위 포인트를 선택합니다.  포인트에서 eps 거리 안의 모든 포인트를 찾습니다.  거리 안의 포인트 수가 min_samples보다 적다면 노이즈로 레이블 합니다.  거리 안의 min_samples보다 포인트 수가 많다면 그 포인트는 핵심 샘플로 레이블하고 새로운 클러스터 레이블을 할당합니다.  포인트의 eps 거리 안의 모든 이웃을 확인하여 어떤 클러스터에도 할당되지 않았다면 방금 만든 클러스터 레이블을 할당합니다.  이 과정을 반복하여 클러스터는 eps 거리 안에 더 이상 핵심 샘플이 없을 때까지 커집니다.  아직 선택되지 못한 포인트를 기준으로 위 과정을 다시 반복합니다.DBSCAN은 다음과 같이 사용합니다.from sklearn.cluster import DBSCANX, y = make_blobs(random_state=0, n_samples=12)dbscan = DBSCAN()clusters = dbscan.fit_predict(X)print(\"클러스터 레이블:\\n\", clusters)다음 그림에서 보는 것과 같이 min_samples와 eps을 통해 모양이 많이 달라집니다.eps를 증가시키면 하나의 클러스터에 더 많은 포인트가 포함되고, min_samples를 키우면 노이즈가 증가합니다.장점  K-means와 다르게 군집의 수를 설정할 필요가 없습니다.다양한 모양의 군집이 형성될 수 있으며, 군집끼리 겹치는 경우가 없습니다.노이즈 개념 덕분에 이상치에 대응할 수 있습니다.eps, min_samples를 잘 설정하면 좋은 성능을 낼 수 있습니다.단점  한 데이터는 하나의 군집에 속하게 되므로 시작점에 따라 다른 모양의 군집이 형성됩니다.eps 값에 따라 성능이 크게 좌우됩니다.군집별로 밀도가 다른 경우 군집화가 제대로 이루어지지 않습니다.군집 알고리즘의 비교와 평가타깃 값으로 군집 평가하기1(최적일 때)과 0(무작위로 분류) 사이의 값을 제공하는 ARI, NMI가 가장 널리 사용하는 지표입니다.adjusted_rand_score과 normalized_mutual_info_score과 같은 군집용 측정 도구가 따로 존재하므로 accuracy_score을 사용하지 않아야 합니다.하지만 ARI와 NMI와 같이 정확한 클러스터를 알고 있어야 평가가 가능하다면 지도 학습 모델을 만드는 곳에만 사용되고 실제 애플리케이션 성능 평가는 사용할 수 없습니다.타깃 값 없이 군집 평가하기따라서 타깃 값 없이 실루엣 계수라는 것을 이용하여 군집용 지표가 존재합니다.실루엣 점수는 클러스터의 밀집 정도를 계산하는 것으로 높을수록 좋으며 최대 점수는 1입니다.하지만 K-평균에서 나왔던 문제와 비슷하게 모양이 복잡할 때는 밀집도를 활용한 평가는 좋지 않습니다.",
        "url": "/study-ML4"
    }
    ,
    
    "programming-baekjoon7": {
        "title": "백준 (7) &lt;br&gt; (10828,10773,1874,10799, &lt;br&gt; 4949,1406,2493)",
            "author": "keonju",
            "category": "",
            "content": "백준 관련 글    백준 (1) (2557, 8958, 1000, 1001, 1008, 2935, 2753, 2884, 5063, 4101)    백준 (2) (1018, 1085, 1181, 1259, 1436, 1654, 1874, 1920)    백준 (3) 문자열 알고리즘(11720, 8958, 1152, 10809, 1157, 9012, 11718)    백준 (4) (1157, 1546, 2577, 2675, 2908, 1018, 1436, 1259, 7568, 10250)    백준 (5) 정렬 알고리즘(2750,11399,2751,1427, 10989,1181,11650)    백준 (6) (3085, 2563, 4673, 5635, 11170)    백준 (7) 스택 알고리즘(10828,10773,1874,10799, 4949,1406,2493)백준 7문제를 풀어보았다.중복되는 문제도 있습니다스택에 관련된 7문제를 풀어보았다.https://www.acmicpc.net/problemset?sort=ac_desc&amp;algo=7110828번 스택https://www.acmicpc.net/problem/10828input()을 이용하면 시간 초과가 발생한다. (sys.stdin.readline() 사용)입력받은 값에 각 명령어들이 있으면 명령어에 따라 작동하도록 해주면 된다.push는 뒤에 숫자가 따라오기 때문에 split() 함수를 통해 뒤에 숫자를 분리해줘서 스택에 넣어준다.pop은 스택의 길이가 0 보다 클 때와 작을 때를 구분하여 pop 함수를 실행하거나 -1을 출력해주면 된다. size는 스택의 길이와 같다.empty는 스택의 길이가 0 인가 아닌가를 판별해주면 된다.top은 pop과 유사하지만 pop 함수를 사용하면 가장 위에 숫자가 스택에서 사라지기 때문에 stack[-1]을 출력해주면 된다.# 처음 문제만 읽고 풀었을 때 작성한 코드import sysstack=[]for i in range(int(input())):    command=input()    if 'push' in command:        a,b=command.split()        b=int(b)        stack.append(b)    if 'top' in command:        if len(stack)&gt;0:            print(stack[-1])        else:            print('-1')    if 'size' in command:        print(len(stack))    if 'empty' in command:        if len(stack)==0:            print('1')        else: print('0')    if 'pop' in command:        if len(stack)&gt;0:            print(stack.pop())        else:            print('-1')14push 1push 2top2size2empty0pop2pop1pop-1size0empty1pop-1push 3empty0top3# 클래스와 함수를 이용하는 것이 훨씬 보기 좋을 것 같아서 새로 작성한 코드# 클래스와 함수에 익숙하지 않아서 생각보다 오래 걸렸다.# 마찬가지로 input 대신 sys.stdin.readline()를 사용하여 제출해야한다.class stack:    def __init__(self):         self.stack_list = []    def push(self, num):        self.stack_list.append(num)    def pop(self):        if len(self.stack_list) == 0:            print(\"-1\")        else:            print(self.stack_list.pop())    def size(self):        print(len(self.stack_list))    def empty(self):        if len(self.stack_list) == 0:            print(\"1\")        else :            print(\"0\")    def top(self):        if len(self.stack_list) == 0:            print(\"-1\")        else :            print(self.stack_list[-1])import sysnumber = int(input())stack=stack()for _ in range(number):    command = input().split()    if command[0] == \"push\":        stack.push(command[1])    if 'pop' in command:        stack.pop()    if 'size' in command:        stack.size()    if 'empty' in command:        stack.empty()    if 'top' in command:        stack.top()14push 1push 2top2size2empty0pop2pop1pop-1size0empty1pop-1push 3empty0top310773번 제로https://www.acmicpc.net/problem/10773스택에서 pop과 append를 이용하여 해결할 수 있는 간단한 문제였다.재현이가 0 을 외치면 pop을 이용해서 최근의 숫자를 지워주면 된다.반대로 0이 아닌 숫자를 외치면 스택에 append 해주면 된다.출력하는 값은 stack에 남아있는 숫자이기 때문에 sum을 이용해서 출력해준다.import sysstack=[]for i in range(int(input())):    money=int(input())    if money==0:        stack.pop()    else:        stack.append(money)print(sum(stack))4304001874번 스택 수열https://www.acmicpc.net/problem/1874스택과 푸쉬, 팝 이해하기push를 세 번 하면 [1,2,3] 스택이 쌓이게 되고 여기서 pop을 하면 3이 출력된다.n을 통해 입력할 숫자의 갯수를 입력받고 num을 통해 숫자를 입력받는다.count는 입력받을 숫자가 stack에 입력되도록 해준다. 0으로 두면 0부터 시작이다.따라서 1로 한다. result를 통해 +와 -를 입력받고 stack에는 count에 생긴 숫자들을 쌓아둔다.while문을 통해 stack을 완성하고 if문을 통해 해당 숫자가 나오면 -를 입력한 뒤 pop해서 숫자를 제거한다.n=int(input())count=1result=[]stack=[]temp=Truefor i in range(n):    num=int(input())    while count&lt;=num:        stack.append(count)        result.append('+')        count=count+1    if stack[-1]==num:        stack.pop()        result.append('-')    else:        temp=False        if temp==False:    print('NO')else:    for j in result:        print(j)843687521++++--++-++-----10799번 쇠막대기https://www.acmicpc.net/problem/10799()가 쌍을 이룰 때는 레이저이므로 L로 대체했다.stack=[]을 이용하여 막대가 몇 개 있는지 저장하는 용도로 사용하였다.(가 되면 막대가 계속 쌓이는 데, 레이저를 만나면 레이저 왼쪽으로 막대의 개수만큼 잘린다.그 다음 )를 만나면 막대가 끝난 경우이므로 또 잘린 막대가 생긴다.따라서 if 문으로 (가 나오면 막대 개수를 추가해주고L은 막대의 개수만큼 답을 더해주고 )는 잘린 막대 1개를 추가해준다.word=input()()(((()())(())()))(())word=word.replace('()','L')stack=[]answer=0for i in word:    if i=='(':        stack.append(0)    elif i==')':        stack.pop()        answer+=1    else:        answer+=len(stack)print(answer)        L 0( 0( 0( 0L 3L 6) 7( 7L 10) 11L 13) 14) 15( 15L 16) 17174949번 균형잡힌 세상https://www.acmicpc.net/problem/4949하나는 replace와 re.sub을 이용하여 괄호들을 제외한 모든 문자를 지워주는 문제로 풀었다.하지만 주제가 스택이었으므로 스택으로 다시 한 번 풀었다.# replace와 sub을 이용한 풀이import reword='a'while word != '.':    word=input()    if word=='.':        break    word=word.replace('.','')    word=re.sub('[a-zA-Z]','',word)    word=re.sub(' ','',word)    while ('[]' in word) or ('()' in word):        word=word.replace('[]','')        word=word.replace('()','')    if word =='':        print('yes')    else:        print('no')A rope may form )( a trail in a maze.noHelp( I[m being held prisoner in a fortune cookie factory)].noSo when I die (the [first] I will see in (heaven) is a score list).yes[ first in ] ( first out ).yes([ (([( [ ] ) ( ) (( ))] )) ]).yes .yes.# stack을 이용한 풀이while True: # 계속 입력받기 위한 while    word=input()    stack=[] # 괄호 저장을 위한 stack    temp=True # 나중에 stack에 있는지 없는지 판단을 위한 temp    if word=='.': # .만 입력하면 while이 끝난다.          break            for i in word:        if i =='[' or i=='(': # 괄호 여는 것은 모두 스택에 append한다.            stack.append(i)        elif i==']': # 닫힌 괄호가 나왔을 때,            if len(stack) ==0 or stack[-1]=='(': # 스택에 아무것도 없거나 소괄호만 있다면 no를 출력한다.                                print('no')                temp=False #temp를 false로 두어서 나중에 stack에 짝이 맞아서 아무것도 없을 때를 대비한다.                break            else:                stack.pop() # 괄호의 짝이 맞게 있다면 '['를 없애서 스택에서 비워준다.        elif i==')':             if len(stack) ==0 or stack[-1]=='[':                print('no')                temp=False                break            else:                stack.pop()    if temp==True: #괄호의 짝이 모두 맞았다면 stack은 0이 될 것이다.        if len(stack)==0:            print('yes')        else:            print('no')So when I die (the [first] I will see in (heaven) is a score list).yes[ first in ] ( first out ).yesHalf Moon tonight (At least it is better than no Moon at all].noA rope may form )( a trail in a maze.noHelp( I[m being held prisoner in a fortune cookie factory)].no([ (([( [ ] ) ( ) (( ))] )) ]).yes .yes.1406번 에디터https://www.acmicpc.net/problem/1406처음에 짠 코드는 답은 맞았지만 시간초과가 발생한다.찾아보니까 insert와 del은 시간 복잡도가 O(n)이라고 한다.따라서 O(1)인 pop과 append를 사용해서 문제를 해결해야 한다.pop과 append를 이용하여 빈 스택에 ‘L’,’D’로 변화된 커서에 대한 정보를 저장한다.B와 P는 처음 푼 것과 다르게 커서 변경없이 pop과 append로 값만 추가, 삭제해주면 된다.word_list에는 새로 입력받은 값이 저장될 것고 새로 만든 스택에 커서 변경된 정보가 순서대로 저장될 것이다. 실제 입력받은 문자에서의 변화와 반대로 저장되기 때문에 [::-1]로 새로운 스택은 합쳐줘야한다.당연히 sys.stin.readline()으로 입력받아야한다.# 시간 초과된 insert와 defword_list=list(input())point=int(input())j=len(word_list)for i in range(point):    command=input()    if command[0]=='L' and j!=0:        j=j-1             elif command[0]=='D' and j!=len(word_list):        j=j+1        elif command[0]=='B' and j != 0:        del word_list[j-1]        j=j-1            elif command[0]=='P':        if j==len(word_list):            word_list.insert(len(word_list)+1,command[2])            j=j+1            print(j)        elif j==0:            word_list.insert(j,command[2])            print(j)        else:            word_list.insert(j,command[2])            print(''.join(word_list))dmih11BBP x3LBBBP y0DDP z3yxzword_list=list(input())point=int(input())j=len(word_list)stack=[]for i in range(point):    command=input()    if command[0]=='L' and len(word_list) !=0:        stack.append(word_list.pop())    elif command[0]=='D' and len(stack) !=0:        word_list.append(stack.pop())    elif command[0]=='B'and len(word_list) !=0:        word_list.pop()    elif command[0]=='P':        word_list.append(command[2])print(word_list)print(stack)word_list.extend(stack[::-1])    print(''.join(word_list))abc9LLLLLP xLBP y['y']['c', 'b', 'a', 'x']yxabc2493번 탑https://www.acmicpc.net/problem/2493answer은 정답을 기록하는 용도로, stack은 비교하는 탑과 인덱스를 저장한다.즉, for문으로 레이저가 출발하는 송전탑을 고르고, stack에는 이 전에 지나온 송전탑들이 저장된다.i값은 인덱스보다 1 작기 때문에 답에는 1을 추가해줘야한다.n = int(input()) #5top = list(map(int, input().split())) #[6 9 5 7]stack = [] #[]answer = [0 for i in range(n)] #[0 0 0 0 4] for i in range(n):    while stack:        if stack[-1][1] &gt; top[i]:            answer[i] = stack[-1][0] + 1            break        else:            stack.pop()    stack.append([i, top[i]]) print(*answer)56 9 5 7 40 0 2 2 4a=[1,2,3]print(*a)1 2 3",
        "url": "/programming-baekjoon7"
    }
    ,
    
    "study-ml3": {
        "title": "머신러닝 정리 (3) &lt;br&gt; 비지도학습 (1)",
            "author": "keonju",
            "category": "",
            "content": "머신러닝 공부 관련 글    머신러닝 정리 (1)-지도학습 (1)    머신러닝 정리 (2)-지도학습 (2)    머신러닝 정리 (3)-비지도학습 (1)    머신러닝 정리 (4)-비지도학습 (2)머신러닝 정리 (3) - 비지도학습 (1)본 문서는 [파이썬 라이브러리를 활용한 머신러닝] 책을 공부하면서 요약한 내용입니다.또 데이터 청년 캠퍼스 수업과 학교 수업에서 배운 내용들도 함께 정리했습니다.글의 순서는 [파이썬 라이브러리를 활용한 머신러닝]에 따라 진행됩니다.코드는 밑에 링크에 공개되어있기 때문에 올리지않습니다.소스 코드: https://github.com/rickiepark/introduction_to_ml_with_python비지도학습 (1)  비지도 학습의 종류  비지도 학습의 도전과제  데이터 전처리와 스케일 조정  여러 가지 전처리 방법          StandardScaler      RobustScaler      MinMaxScaler      Nomarlizer        데이터 변환 적용하기  Quantile Transformer 와 Power Transformer          Quantile Transformer      Power Transformer        훈련 데이터와 테스트 데이터의 스케일을 같은 방법으로 조정하기  지도 학습에서 데이터 전처리 효과  차원 축소, 특성 추출, 매니폴드 학습          주성분 분석(PCA)                  유방암 데이터 셋 시각화          고유얼굴 특성 추출                    비지도 학습의 종류책에서는 두 가지 비지도 학습을 공부합니다.비지도 변환과 군집입니다.비지도 변환은 데이터를 새롭게 표현하여 사람이나 다른 머신러닝 알고리즘이 원래 데이터보다 쉽게 해석할 수 있도록 만드는 알고리즘입니다.특히 고차원 데이터를 특성의 수를 줄이면서 꼭 필요한 특징을 포함한 데이터로 표현하는 방법인 차원축소가 대표적인 예입니다.비지도 변환으로 데이터를 구성하는 단위나 성분을 찾기도 합니다.텍스트 문서에서 주제를 추출하는 것이 예입니다.소셜 미디어에서 선거, 총기 규제, 팝스타 같은 주제로 일어나는 토론을 추적할 때 사용한다고 합니다.군집 알고리즘은 데이터를 서로 비슷하게 그룹으로 묶는 것 입니다.같은 사람이 찍힌 사진을 같은 그룹으로 묶게 추천해주는 것을 생각하면 이해하기 쉽습니다.비지도 학습의 도전과제비지도 학습에서 가장 어려운 일은 알고리즘이 유용한 가를 평가하는 것 입니다.비지도 학습은 보통 레이블이 없어서 어떤 것이 올바른 것인지 모릅니다.그래서 비지도 학습의 결과를 평가하기 위해서는 직접 확인하는 것이 유일한 방법일 때도 있다고 합니다.비지도 학습 알고리즘은 데이터를 잘 이해하고 싶을 때 탐색적 분석 단계에서도 많이 사용합니다.전처리 단계에서도 사용되는데 비지도 학습 결과를 사용하여 학습하면 지도 학습의 정확도가 좋아지기도 하고 메모리나 시간 절약도 할 수 있습니다.데이터 전처리와 스케일 조정신경망이나 SVM과 같은 스케일에 민감한 알고리즘은 데이터 특성 값을 조정해야합니다.여러 가지 전처리 방법StandardSclaer각 특성의 평균을 0, 분산을 1로 변경하여 모든 특성이 같은 크기를 가지게 합니다.특성의 최솟값과 최댓값의 크기를 제한하지는 않습니다.\\[z= \\frac {x−μ} σ ( z점수= \\frac{자료값-평균} {표준편차})\\]RobustScaler특성이 같은 스케일을 갖게되지만 평균과 분산 대신 중간 값과 사분위 값을 사용합니다.따라서 이상치에 영향을 받지 않습니다.MinMaxScaler모든 특성이 정확하게 0과 1 사이에 위치하도록 변경합니다.2차원 데이터셋일 경우에는 모든 데이터가 x 축의 0과 1, y축의 0과 1 사이의 사각 영역에 담기게 됩니다.(q는 각 사분위값을 뜻합니다.)\\[\\frac {x-q~2} {q~3-q~1}\\]Nomarlizer특성 벡터의 유클리디안 길이가 1이 되도록 데이터 포인트를 조정합니다.다른 말로 하면 지름이 1인 원(3차원에서는 구)에 들어옵니다.각 데이터 포인트가 다른 비율로 조정됩니다.  특성 벡터의 길이는 상관 없고 데이터의 방향이 중요할 때 많이 사용합니다.데이터 변환 적용하기from sklearn.preprocessing import MinMaxScalerscaler = MinMaxScaler()scaler.fit(X_train)X_train_scaled = scaler.transform(X_train)print(\"변환된 후 크기:\", X_train_scaled.shape)print(\"스케일 조정 전 특성별 최소값:\\n\", X_train.min(axis=0))print(\"스케일 조정 전 특성별 최대값:\\n\", X_train.max(axis=0))print(\"스케일 조정 후 특성별 최소값:\\n\", X_train_scaled.min(axis=0))print(\"스케일 조정 후 특성별 최대값:\\n\", X_train_scaled.max(axis=0))변환된 후 크기: (426, 30)스케일 조정 전 특성별 최소값:[  6.981   9.71   43.79  143.5     0.053   0.019   0.      0.      0.1060.05    0.115   0.36    0.757   6.802   0.002   0.002   0.      0.0.01    0.001   7.93   12.02   50.41  185.2     0.071   0.027   0.0.      0.157   0.055]스케일 조정 전 특성별 최대값:[  28.11    39.28   188.5   2501.       0.163    0.287    0.427    0.201    0.304    0.096    2.873    4.885   21.98   542.2      0.031    0.135    0.396    0.053    0.061    0.03    36.04    49.54   251.2   4254.    0.223    0.938    1.17     0.291    0.577    0.149]스케일 조정 후 특성별 최소값:[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.0. 0. 0. 0. 0. 0.]스케일 조정 후 특성별 최대값:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.1. 1. 1. 1. 1. 1.]변환 된 값들이 모두 0과 1 사이가 된 것을 알 수 있습니다.X_test_scaled = scaler.transform(X_test)print(\"스케일 조정 후 특성별 최소값:\\n\", X_test_scaled.min(axis=0))print(\"스케일 조정 후 특성별 최대값:\\n\", X_test_scaled.max(axis=0))스케일 조정 후 특성별 최소값:[ 0.034  0.023  0.031  0.011  0.141  0.044  0.     0.     0.154 -0.006-0.001  0.006  0.004  0.001  0.039  0.011  0.     0.    -0.032  0.0070.027  0.058  0.02   0.009  0.109  0.026  0.     0.    -0.    -0.002]스케일 조정 후 특성별 최대값:[0.958 0.815 0.956 0.894 0.811 1.22  0.88  0.933 0.932 1.037 0.427 0.4980.441 0.284 0.487 0.739 0.767 0.629 1.337 0.391 0.896 0.793 0.849 0.7450.915 1.132 1.07  0.924 1.205 1.631]테스트 세트의 최솟값과 최댓값은 0과 1이 아닐 수 있다.테스트 세트의 최솟값과 범위를 사용하지 않고 훈련 세트의 최솟값을 빼고 훈련 세트의 범위로 나누기 때문이다.MinMaxScaler을 사용하려면 항상 테스트와 훈련 세트 모두 같은 변환을 해야한다.Quantile Transformer 와 Power TransformerQuantile TransformerQuantile Transformer은 1000개의 분위를 사용하여 데이터를 균등하게 분포시킵니다.RobustScaler과 비슷하게 이상치에 민감하지 않으며 전체 데이터를 0과 1 사이로 압축합니다.분위 수는 n_quantiles 매개 변수로 설정할 수 있으며 속성의 크기는 (n_quantiles,n_features) 입니다.output_distribution 매개변수를 통해 균등 분포에서 정규 분포로 출력을 바꿀 수도 있습니다.Power TransformerPower Transformer는 method 매개변수에 ‘yeo-johnson’과 ‘box-cox’ 알고리즘을 지정할 수 있습니다.어떤 변환이 정규 분포에 가깝게 변환할지 사전에 알기 힘들기 때문에 히스토그램으로 확인해보는 것이 좋습니다.훈련 데이터와 테스트 데이터의 스케일을 같은 방법으로 조정하기지도 학습에서는 훈련 세트와 테스트 세트에 같은 변환을 적용하는 것이 중요합니다.잘 조정된 데이터는 같은 비율로 데이터를 바꿔 원본 데이터와 비율만 다른 그래프를 보여주지만 잘못 조정된 데이터는 배열이 엉망이 되어서 결과에 영향을 미칩니다.지도 학습에서 데이터 전처리 효과from sklearn.svm import SVCX_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)svm = SVC(gamma='auto')svm.fit(X_train, y_train)print(\"테스트 세트 정확도: {:.2f}\".format(svm.score(X_test, y_test)))테스트 세트 정확도: 0.63# 0~1 사이로 스케일 조정scaler = MinMaxScaler()scaler.fit(X_train)X_train_scaled = scaler.transform(X_train)X_test_scaled = scaler.transform(X_test)svm.fit(X_train_scaled, y_train)print(\"스케일 조정된 테스트 세트의 정확도: {:.2f}\".format(svm.score(X_test_scaled, y_test)))스케일 조정된 테스트 세트의 정확도: 0.95# 평균 0, 분산 1을 갖도록 스케일 조정from sklearn.preprocessing import StandardScalerscaler = StandardScaler()scaler.fit(X_train)X_train_scaled = scaler.transform(X_train)X_test_scaled = scaler.transform(X_test)svm.fit(X_train_scaled, y_train)print(\"SVM 테스트 정확도: {:.2f}\".format(svm.score(X_test_scaled, y_test)))SVM 테스트 정확도: 0.97차원 축소, 특성 추출, 매니폴드 학습주성분 분석은 가장 많이 사용되는 데이터 변환 방법입니다.특성 추출에서는 비음수 행렬 분해가 많이 사용됩니다.2차원 산점도를 이용한 시각화 용도로 사용되는 t-SNE 알고리즘도 있습니다.차원 축소  차원 축소의 필요성관측 치의 수는 한정되어 있습니다.차원이 커질 수록 한정된 자료는 커진 차원의 패턴을 잘 설명하지 못하고 복잡도가 기하급수적으로 늘어나게 됩니다.상관계수가 높은 변수 중 일부만 분석하게 된다면 정보의 손실이 발생하게 됩니다.  차원 축소의 여러 방법    &gt; principal component    &gt; 변수 선택법    &gt; penalty 기반 regression    &gt; convolutional neural network    &gt; drop out &amp; bagging  차원 축소의 활용    &gt; 차원 축소를 통해 데이터를 잘 설명할 수 있는 잠재적 요소 추출    &gt; 이미지 분류, 시맨틱, 토픽 분류 등주성분 분석(PCA)공분산 행렬 개념은 다음과 같습니다.Principal Components의 개념은 차원을 줄이면서 정보 손실을 최소화하는 방법입니다.더 적은 개수로 데이터를 충분히 잘 설명할 수 있는 새로운 축을 찾아냅니다.공분산이 데이터의 형태를 변형시키는 방향의 축과 그것에 직교하는 축을 찾습니다.2차원의 경우 공분산이 나타내는 타원의 장축과 단축입니다.PC score은 새로 찾아낸 축에서의 좌표값을 의미하는데 기존 값을 새로운 축에 내린 정사영입니다.즉, PCA는 데이터의 분산을 최대한 보존하면서 서로 직교하는 새 기저(축)을 찾아, 고차원 공간의 표본들을 선형 연관성이 없는 저차원 공간으로 변환하는 기법입니다.데이터의 공분산 행렬이 고유벡터와 고유값으로 분해될 수 있고, 이렇게 분해된 고유벡터를 이용해 입력데이터를 선형변환하는 것이 PCA입니다.PCA의 수학적개념_Singular Value Decomposition(SVD)SVD와 eigen value, eigen vector의 연관성주성분 분석은 특성들이 통계적으로 상관관계가 없도록 데이터셋을 회전시키는 기술입니다.회전한 뒤에 데이터를 설명하는 데 중요한 새로운 특성 중 일부만 선택합니다.주성분 찾기  분산이 가장 큰 가장 많은 정보를 가지고 있는 방향을 찾는다.  첫 번째 방향과 직각인 방향 중에서 가장 많은 정보를 가지고 있는 방향을 찾는다.두 번째 그래프는 주성분 1과 2를 x 축과 y 축에 나란히 회전한 것으로 변환된 데이터의 상관관계 행렬이 대각선 방향을 제외하고 0이 됩니다.세 번째 그래프는 차원 축소 용도로 사용될 수 있습니다.  첫 번째 주성분만 유지하므로 2차원 데이터 셋이 1차원 데이터 셋으로 차원 감소 합니다.단순히 원본 특성 중 하나만 남기는 것이 아닌 가장 유용한 방향을 찾아 그 성분을 유지하는 것입니다.마지막 그래프는 데이터에 다시 평균을 더하고 반대로 회전시킨 그래프 입니다.원래 특성 공간에 있지만 첫 번째 주성분의 정보만 가지고 있습니다.보통 노이즈 제거나 주성분에서 유지되는 정보의 시각화를 위해 사용됩니다.유방암 데이터 셋 시각화유방암 데이터는 특성이 30개를 가지고 있기 때문에 너무 많은 산점도를 요구합니다.따라서 히스토그램을 그리는 방법이 있지만 히스토그램은 특성 간의 상호작용이나 클래스와의 곤계를 알려주지 못합니다.따라서 PCA를 통해 데이터를 회전시키고 차원을 축소합니다.그러면 다음과 같이 2차원 공간에서도 잘 구분됩니다.분류를 할 때 좋은 결과를 얻을 수 있을 것 같은 그래프입니다.하지만 두 축을 해석하기 어렵다는 단점을 가지고 있습니다.따라서 pca.components_를 통해서 중요도를 확인할 수 있습니다.고유얼굴 특성 추출PCA는 특성 추출에도 이용됩니다.RGB 강도로 기록된 픽셀들을 분류하는데 유용합니다.픽셀을 사용해서 두 이미지를 비교할 때, 각 픽셀의 회색톤 값을 다른 이미지에서 동일한 위치에 있는 픽셀 값과 비교합니다.하지만 이는 사람이 얼굴을 인식하는 것과 많이 다르고 특징을 잡기 어렵습니다.따라서 주성분으로 변환하여 거리를 계산하면 정확도가 높아집니다.PCA의 화이트닝 옵션을 사용하면 주성분의 스케일이 같습니다.화이트닝 옵션은 StandardScaler과 동일한 방식입니다.PCA 모델은 픽셀을 기반으로 하므로 얼굴의 배치와 조명이 비슷한 이미지를 판단하는 데 큰 영향을 줍니다.따라서 테스트 포인트를 주성분의 가중치 합으로 나타내는 것에 PCA 변환을 사용하는 방법도 해석 중 한 가지 방법입니다.원본 데이터를 재구성하는 방법도 PCA 모델의 해석 방법 중 한가지입니다.",
        "url": "/study-ML3"
    }
    ,
    
    "programming-kaggle2": {
        "title": "캐글 (2) &lt;br&gt; 타이타닉 튜토리얼 1,2 공부하기",
            "author": "keonju",
            "category": "",
            "content": "kaggle 관련 글    캐글 (1) Simple Matplotlib &amp; Visualization Tips 공부하기    캐글 (2) 타이타닉 튜토리얼 1,2 공부하기타이타닉 튜토리얼 1,2 공부하기kaggle 타이타닉 튜토리얼을 필사하였다.해당 유튜브를 따라서 필사하였고 블로그에 자세한 설명도 나와있었다.https://www.youtube.com/watch?v=_iqz7tFhox0&amp;list=PLC_wC_PMBL5MnqmgTLqDgu4tO8mrQakuFhttps://kaggle-kr.tistory.com/17?category=868316https://kaggle-kr.tistory.com/18?category=868316# 분석에 필요한 패키지import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns# plt의 스타일 지정plt.style.use('seaborn')sns.set(font_scale=2.5) # 결측치를 알기 쉽게 하는 패키지import missingno as msno# warning무시import warningswarnings.filterwarnings('ignore')# notebook에서 바로 그림 확인하는 코드%matplotlib inline# 데이터 불러오기df_train=pd.read_csv('train.csv')df_test=pd.read_csv('test.csv')df_test.head()                  PassengerId      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      892      3      Kelly, Mr. James      male      34.5      0      0      330911      7.8292      NaN      Q              1      893      3      Wilkes, Mrs. James (Ellen Needs)      female      47.0      1      0      363272      7.0000      NaN      S              2      894      2      Myles, Mr. Thomas Francis      male      62.0      0      0      240276      9.6875      NaN      Q              3      895      3      Wirz, Mr. Albert      male      27.0      0      0      315154      8.6625      NaN      S              4      896      3      Hirvonen, Mrs. Alexander (Helga E Lindqvist)      female      22.0      1      1      3101298      12.2875      NaN      S      # 데이터 확인df_train.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      # 데이터 행렬 확인df_train.shape(891, 12)# 데이터 셋 특징 확인df_train.describe()                  PassengerId      Survived      Pclass      Age      SibSp      Parch      Fare                  count      891.000000      891.000000      891.000000      714.000000      891.000000      891.000000      891.000000              mean      446.000000      0.383838      2.308642      29.699118      0.523008      0.381594      32.204208              std      257.353842      0.486592      0.836071      14.526497      1.102743      0.806057      49.693429              min      1.000000      0.000000      1.000000      0.420000      0.000000      0.000000      0.000000              25%      223.500000      0.000000      2.000000      20.125000      0.000000      0.000000      7.910400              50%      446.000000      0.000000      3.000000      28.000000      0.000000      0.000000      14.454200              75%      668.500000      1.000000      3.000000      38.000000      1.000000      0.000000      31.000000              max      891.000000      1.000000      3.000000      80.000000      8.000000      6.000000      512.329200      # max 값만 확인df_train.max()PassengerId                            891Survived                                 1Pclass                                   3Name           van Melkebeke, Mr. PhilemonSex                                   maleAge                                     80SibSp                                    8Parch                                    6Ticket                           WE/P 5735Fare                               512.329dtype: objectdf_test.describe()                  PassengerId      Pclass      Age      SibSp      Parch      Fare                  count      418.000000      418.000000      332.000000      418.000000      418.000000      417.000000              mean      1100.500000      2.265550      30.272590      0.447368      0.392344      35.627188              std      120.810458      0.841838      14.181209      0.896760      0.981429      55.907576              min      892.000000      1.000000      0.170000      0.000000      0.000000      0.000000              25%      996.250000      1.000000      21.000000      0.000000      0.000000      7.895800              50%      1100.500000      3.000000      27.000000      0.000000      0.000000      14.454200              75%      1204.750000      3.000000      39.000000      1.000000      0.000000      31.500000              max      1309.000000      3.000000      76.000000      8.000000      9.000000      512.329200      # column값 확인df_train.columnsIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],      dtype='object')# 각 column의 null 데이터 비율 확인 {:&gt;10}:오른쪽 정렬for col in df_train.columns:    msg='column: {:&gt;10}\\t Percent of NaN value: {:.2f}%'.format(col,100*(df_train[col].isnull().sum()/df_train[col].shape[0]))    print(msg)column: PassengerId\t Percent of NaN value: 0.00%column:   Survived\t Percent of NaN value: 0.00%column:     Pclass\t Percent of NaN value: 0.00%column:       Name\t Percent of NaN value: 0.00%column:        Sex\t Percent of NaN value: 0.00%column:        Age\t Percent of NaN value: 19.87%column:      SibSp\t Percent of NaN value: 0.00%column:      Parch\t Percent of NaN value: 0.00%column:     Ticket\t Percent of NaN value: 0.00%column:       Fare\t Percent of NaN value: 0.00%column:      Cabin\t Percent of NaN value: 77.10%column:   Embarked\t Percent of NaN value: 0.22%# 값 확인df_train[col]0      S1      C2      S3      S4      S      ..886    S887    S888    S889    C890    QName: Embarked, Length: 891, dtype: object# null 값 확인df_train[col].isnull()0      False1      False2      False3      False4      False       ...  886    False887    False888    False889    False890    FalseName: Embarked, Length: 891, dtype: bool# null 값의 합df_train[col].isnull().sum()2# shape를 통해 총 데이터 갯수 확인하기df_train[col].isnull().sum()/df_train[col].shape[0]0.002244668911335578for col in df_test.columns:    msg='column: {:&gt;10}\\t Percent of NaN value: {:.2f}%'.format(col,100*(df_test[col].isnull().sum()/df_test[col].shape[0]))    print(msg)column: PassengerId\t Percent of NaN value: 0.00%column:     Pclass\t Percent of NaN value: 0.00%column:       Name\t Percent of NaN value: 0.00%column:        Sex\t Percent of NaN value: 0.00%column:        Age\t Percent of NaN value: 20.57%column:      SibSp\t Percent of NaN value: 0.00%column:      Parch\t Percent of NaN value: 0.00%column:     Ticket\t Percent of NaN value: 0.00%column:       Fare\t Percent of NaN value: 0.24%column:      Cabin\t Percent of NaN value: 78.23%column:   Embarked\t Percent of NaN value: 0.00%# missingno를 통해 확인하기msno.matrix(df=df_train.iloc[:,:],figsize=(8,8),color=(0.8,0.5,0.2))&lt;AxesSubplot:&gt;# iloc으로 가져오고 싶은 위치 찾기df_train.iloc[:,-1]0      S1      C2      S3      S4      S      ..886    S887    S888    S889    C890    QName: Embarked, Length: 891, dtype: objectmsno.bar(df=df_train.iloc[:,:],figsize=(8,8),color=(0.8,0.5,0.2))&lt;AxesSubplot:&gt;# pie plot과 count-plot 그래프 그리기# 도화지를 준비하는 과정 (1,2): 행렬 f, ax=plt.subplots(1,2,figsize=(18,8)) #'Survived'에 있는 값 count하기, 떨어뜨리기, 글자 규칙, 그리는 위치, 그림자df_train['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)ax[0].set_title('Pie plot-Survived') # 제목ax[0].set_ylabel('')sns.countplot('Survived',data=df_train,ax=ax[1]) #countplot을 [1] 위치에 그리기ax[1].set_title('Count plot-Survived')plt.show()2.1 PClass# class 별 생존자 수 count는 객체가 몇명인가df_train[['Pclass','Survived']].groupby(['Pclass'],as_index=True).count()                  Survived              Pclass                        1      216              2      184              3      491      # sum은 숫자 자체의 데이터의 갯수 [0,1]에서 1을 다 더한 값df_train[['Pclass','Survived']].groupby(['Pclass'],as_index=True).sum()                  Survived              Pclass                        1      136              2      87              3      119      # crosstab을 통해 비교 (margin은 All 표현,style.background_gradient를 통해 색상 조절)pd.crosstab(df_train['Pclass'],df_train['Survived'],margins=True).style.background_gradient(cmap='summer_r')            Survived        0        1        All                Pclass                                                                    1                        80                        136                        216                                                2                        97                        87                        184                                                3                        372                        119                        491                                                All                        549                        342                        891                # 평균 알아보기 (as_index를 통해 그래프 그리기 설정, sort_values를 통한 오름차순, ascending=False는 내림차순)df_train[['Pclass','Survived']].groupby(['Pclass'],as_index=True).mean().sort_values(by='Survived',ascending=False)                  Survived              Pclass                        1      0.629630              2      0.472826              3      0.242363      # 그래프 기리기df_train[['Pclass','Survived']].groupby(['Pclass'],as_index=True).mean().sort_values(by='Survived',ascending=False).plot()&lt;AxesSubplot:xlabel='Pclass'&gt;# as_index=False일때는 Pclass도 같이 그린다df_train[['Pclass','Survived']].groupby(['Pclass'],as_index=False).mean().sort_values(by='Survived',ascending=False).plot()&lt;AxesSubplot:&gt;# 막대그래프 그리기df_train[['Pclass','Survived']].groupby(['Pclass'],as_index=True).mean().sort_values(by='Survived',ascending=False).plot.bar()&lt;AxesSubplot:xlabel='Pclass'&gt;y_position=1.02f,ax=plt.subplots(1,2,figsize=(18,8))# Class별 탑승자 수df_train['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'],ax=ax[0])ax[0].set_title('Number of passenger By Pclass',y=y_position)ax[0].set_ylabel('Count')# Class별 Survived와 Dead 구분 (hue를 통해 색깔 구분)sns.countplot('Pclass',hue='Survived',data=df_train,ax=ax[1])ax[1].set_title('Pclass:Survived vs Dead',y=y_position)plt.show()2.2 Sexf,ax=plt.subplots(1,2,figsize=(18,8))df_train[['Sex','Survived']].groupby(['Sex'],as_index=True).mean().plot.bar(ax=ax[0])ax[0].set_title('Survived vs Sex')sns.countplot('Sex',hue='Survived',data=df_train,ax=ax[1])ax[1].set_title('Sex:Survived vs Dead')plt.show()df_train[['Sex','Survived']].groupby(['Sex'],as_index=False).mean()                  Sex      Survived                  0      female      0.742038              1      male      0.188908      pd.crosstab(df_train['Sex'],df_train['Survived'],margins=True).style.background_gradient(cmap='summer_r')            Survived        0        1        All                Sex                                                                    female                        81                        233                        314                                                male                        468                        109                        577                                                All                        549                        342                        891                2.2 Both Sex and Pclass# factorplot 그래프 그리기# 선은 error barsns.factorplot('Pclass','Survived',hue='Sex',data=df_train,size=6,aspect=1.5)&lt;seaborn.axisgrid.FacetGrid at 0x2248b7c1c10&gt;# 축과 보는 방향을 바꾼 것sns.factorplot(x='Sex',y='Survived',col='Pclass',data=df_train,saturation=.5,size=9,aspect=1)&lt;seaborn.axisgrid.FacetGrid at 0x2248b8ad310&gt;sns.factorplot(x='Sex',y='Survived',hue='Pclass',data=df_train,saturation=.5,size=9,aspect=1)&lt;seaborn.axisgrid.FacetGrid at 0x2248ba293a0&gt;Ageprint('제일 나이 많은 탑승객: {:.1f} years'.format(df_train['Age'].max()))print('제일 나이 어린 탑승객: {:.1f} years'.format(df_train['Age'].min()))print('탑승객 평균 나이: {:.1f} years'.format(df_train['Age'].mean()))제일 나이 많은 탑승객: 80.0 years제일 나이 어린 탑승객: 0.4 years탑승객 평균 나이: 29.7 years# kdeplot(커널 밀도 함수) 그리기 (히스토그램과 유사)fig,ax=plt.subplots(1,1,figsize=(9,5))sns.kdeplot(df_train[df_train['Survived']==1]['Age'],ax=ax)sns.kdeplot(df_train[df_train['Survived']==0]['Age'],ax=ax)plt.legend(['Survived'==1,'Survived'==0])plt.show()# 히스토그램df_train[df_train['Survived']==1]['Age'].hist()&lt;AxesSubplot:&gt;그래프 그리는 다양한 방법f=plt.figure(figsize=(10,10))a=np.arange(100)b=np.sin(a)plt.plot(b)[&lt;matplotlib.lines.Line2D at 0x2248d260070&gt;]f,ax=plt.subplots(1,1,figsize=(10,10))a=np.arange(100)b=np.sin(a)plt.plot(b)[&lt;matplotlib.lines.Line2D at 0x2248d2c4040&gt;]plt.figure(figsize=(10,10))a=np.arange(100)b=np.sin(a)plt.plot(b)[&lt;matplotlib.lines.Line2D at 0x2248bd55280&gt;]# 탑승객의 연령별 분포plt.figure(figsize=(8,6))df_train['Age'][df_train['Pclass']==1].plot(kind='kde')df_train['Age'][df_train['Pclass']==2].plot(kind='kde')df_train['Age'][df_train['Pclass']==3].plot(kind='kde')plt.xlabel('Age')plt.title('Age Distribution within classes')plt.legend(['1st Class','2nd Class','3rd Class'])&lt;matplotlib.legend.Legend at 0x2248d2f8a00&gt;# 히스토그램은 겹치면 보이지 않음plt.figure(figsize=(8,6))df_train['Age'][df_train['Pclass']==1].plot(kind='hist')df_train['Age'][df_train['Pclass']==2].plot(kind='hist')df_train['Age'][df_train['Pclass']==3].plot(kind='hist')plt.xlabel('Age')plt.title('Age Distribution within classes')plt.legend(['1st Class','2nd Class','3rd Class'])&lt;matplotlib.legend.Legend at 0x2248b74fd30&gt;fig,ax=plt.subplots(1,1,figsize=(9,5))sns.kdeplot(df_train[(df_train['Survived']==0)&amp;(df_train['Pclass']==1)]['Age'],ax=ax)sns.kdeplot(df_train[(df_train['Survived']==1)&amp;(df_train['Pclass']==1)]['Age'],ax=ax)plt.legend(['Survived==1','Survived==0'])plt.title('1st class')plt.show()# 히스토그램은 겹치면 보이지 않음plt.figure(figsize=(8,6))df_train['Age'][(df_train['Pclass']==1)&amp;(df_train['Survived']==0)].plot(kind='hist')df_train['Age'][(df_train['Pclass']==1)&amp;(df_train['Survived']==1)].plot(kind='hist')plt.xlabel('Age')plt.title('Age Distribution within classes')Text(0.5, 1.0, 'Age Distribution within classes')fig,ax=plt.subplots(1,1,figsize=(9,5))sns.kdeplot(df_train[(df_train['Survived']==0)&amp;(df_train['Pclass']==2)]['Age'],ax=ax)sns.kdeplot(df_train[(df_train['Survived']==1)&amp;(df_train['Pclass']==2)]['Age'],ax=ax)plt.legend(['Survived==1','Survived==0'])plt.title('2nd class')plt.show()# 히스토그램은 겹치면 보이지 않음plt.figure(figsize=(8,6))df_train['Age'][(df_train['Pclass']==2)&amp;(df_train['Survived']==0)].plot(kind='hist')df_train['Age'][(df_train['Pclass']==2)&amp;(df_train['Survived']==1)].plot(kind='hist')plt.xlabel('Age')plt.title('Age Distribution within classes')Text(0.5, 1.0, 'Age Distribution within classes')fig,ax=plt.subplots(1,1,figsize=(9,5))sns.kdeplot(df_train[(df_train['Survived']==0)&amp;(df_train['Pclass']==3)]['Age'],ax=ax)sns.kdeplot(df_train[(df_train['Survived']==1)&amp;(df_train['Pclass']==3)]['Age'],ax=ax)plt.legend(['Survived==1','Survived==0'])plt.title('3rd class')plt.show()# 히스토그램은 겹치면 보이지 않음plt.figure(figsize=(8,6))df_train['Age'][(df_train['Pclass']==3)&amp;(df_train['Survived']==0)].plot(kind='hist')df_train['Age'][(df_train['Pclass']==3)&amp;(df_train['Survived']==1)].plot(kind='hist')plt.xlabel('Age')plt.title('Age Distribution within classes')Text(0.5, 1.0, 'Age Distribution within classes')change_age_range_survival_ratio=[]for i in range(1,80):    change_age_range_survival_ratio.append(df_train[df_train['Age']&lt;i]['Survived'].sum()/len(df_train[df_train['Age']&lt;i]['Survived']))    plt.figure(figsize=(7,7))plt.plot(change_age_range_survival_ratio)plt.title('Survial rate change depending on range of Age',y=1.02)plt.ylabel=('Survival rate')plt.xlabel('Range of Age(0~x)')plt.show()i=10df_train[df_train['Age']&lt;i]['Survived'].sum() / len(df_train[df_train['Age']&lt;i]['Survived'])0.6129032258064516Pclass, Sex, Agef,ax=plt.subplots(1,2,figsize=(18,8))sns.violinplot('Pclass','Age',hue='Survived',data=df_train,scale='count',split=True,ax=ax[0])ax[0].set_title('Pclass and Age vs Survived')ax[0].set_yticks(range(0,110,10))sns.violinplot('Sex','Age',hue='Survived',data=df_train,scale='count',split=True,ax=ax[1])ax[1].set_title('Sex and Age vs Survived')ax[1].set_yticks(range(0,110,10))plt.show()# split=Falsef,ax=plt.subplots(1,2,figsize=(18,8))sns.violinplot('Pclass','Age',hue='Survived',data=df_train,scale='count',split=False,ax=ax[0])ax[0].set_title('Pclass and Age vs Survived')ax[0].set_yticks(range(0,110,10))sns.violinplot('Sex','Age',hue='Survived',data=df_train,scale='count',split=False,ax=ax[1])ax[1].set_title('Sex and Age vs Survived')ax[1].set_yticks(range(0,110,10))plt.show()# scale 차이 같은 면적이기 때문에 count보다 숫자의 개념이 보기 힘듬f,ax=plt.subplots(1,2,figsize=(18,8))sns.violinplot('Pclass','Age',hue='Survived',data=df_train,scale='area',split=False,ax=ax[0])ax[0].set_title('Pclass and Age vs Survived')ax[0].set_yticks(range(0,110,10))sns.violinplot('Sex','Age',hue='Survived',data=df_train,scale='area',split=False,ax=ax[1])ax[1].set_title('Sex and Age vs Survived')ax[1].set_yticks(range(0,110,10))plt.show()Embarked# Embarked 비율f, ax= plt.subplots(1,1, figsize=(7,7))df_train[['Embarked','Survived']].groupby(['Embarked'],as_index=True).mean().sort_values(by='Survived',ascending=False).plot.bar(ax=ax)&lt;AxesSubplot:xlabel='Embarked'&gt;# sort_valuesdf_train[['Embarked','Survived']].groupby(['Embarked'],as_index=True).mean().sort_values(by='Survived')                  Survived              Embarked                        S      0.336957              Q      0.389610              C      0.553571      # 내림차순df_train[['Embarked','Survived']].groupby(['Embarked'],as_index=True).mean().sort_values(by='Survived',ascending=False)                  Survived              Embarked                        C      0.553571              Q      0.389610              S      0.336957      # sort_indexdf_train[['Embarked','Survived']].groupby(['Embarked'],as_index=True).mean().sort_index()                  Survived              Embarked                        C      0.553571              Q      0.389610              S      0.336957      f, ax=plt.subplots(2,2,figsize=(20,15))sns.countplot('Embarked',data=df_train,ax=ax[0,0])ax[0,0].set_title('(1) No. Of Passengers Boarded')sns.countplot('Embarked', hue='Sex',data=df_train,ax=ax[0,1])ax[0,1].set_title('(2) Male-Feamle split for embarked')sns.countplot('Embarked', hue='Survived',data=df_train,ax=ax[1,0])ax[1,0].set_title('(3) Embarked vs Survived')sns.countplot('Embarked', hue='Pclass',data=df_train,ax=ax[1,1])ax[1,1].set_title('(4) Embarked vs Pclass')# 좌우간격, 상하간격 맞추기plt.subplots_adjust(wspace=0.2,hspace=0.5)plt.show()Family - Sibsp + Parchdf_train['FamilySize']=df_train['SibSp']+df_train['Parch']+1print('Maximum size of Family:',df_train['FamilySize'].max())print('Minimum size of Family:',df_train['FamilySize'].min())Maximum size of Family: 11Minimum size of Family: 1f, ax=plt.subplots(1,3,figsize=(40,10))sns.countplot('FamilySize',data=df_train,ax=ax[0])ax[0].set_title('(1) No. Of Passenger Boarded',y=1.02)sns.countplot('FamilySize',hue='Survived',data=df_train,ax=ax[1])ax[1].set_title('(2) Survived countplot depending on FamilSize',y=1.02)df_train[['FamilySize','Survived']].groupby(['FamilySize'],as_index=True).mean().sort_values(by='Survived',ascending=False).plot.bar(ax=ax[2])ax[2].set_title('(3) Survived rate depending on FamilySize',y=1.02)plt.subplots_adjust(wspace=0.2,hspace=0.5)plt.show()Faredf_test.loc[df_test.Fare.isnull(), 'Fare'] = df_test['Fare'].mean()df_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i &gt; 0 else 0)df_test['Fare'] = df_test['Fare'].map(lambda i: np.log(i) if i &gt; 0 else 0)fig, ax=plt.subplots(1,1,figsize=(8,8))g=sns.distplot(df_train['Fare'],color='b',label='Skweness {:.2f}'.format(df_train['Fare'].skew()),ax=ax)g=g.legend(loc='best')df_train['Fare']=df_train['Fare'].map(lambda i:np.log(i) if i&gt;0 else 0)df_train['Ticket'].value_counts()1601        7347082      7CA. 2343    7347088      63101295     6           ..PC 17318    131418       1345765      1244270      1244278      1Name: Ticket, Length: 681, dtype: int64Fill Null in Agedf_train['Age'].isnull().sum()177df_train['Age'].mean()29.69911764705882# str로 변환한 뒤 extract와 정규표현식을 통해 추출df_train['Initial']= df_train.Name.str.extract('([A-Za-z]+)\\.')df_test['Initial']= df_test.Name.str.extract('([A-Za-z]+)\\.') pd.crosstab(df_train['Initial'],df_train['Sex']).T.style.background_gradient(cmap='summer_r')            Initial        Capt        Col        Countess        Don        Dr        Jonkheer        Lady        Major        Master        Miss        Mlle        Mme        Mr        Mrs        Ms        Rev        Sir                Sex                                                                                                                                                                                    female                        0                        0                        1                        0                        1                        0                        1                        0                        0                        182                        2                        1                        0                        125                        1                        0                        0                                                male                        1                        2                        0                        1                        6                        1                        0                        2                        40                        0                        0                        0                        517                        0                        0                        6                        1                df_train['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)df_test['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)df_train.groupby('Initial').mean()                  PassengerId      Survived      Pclass      Age      SibSp      Parch      Fare      FamilySize              Initial                                                                  Master      414.975000      0.575000      2.625000      4.574167      2.300000      1.375000      1.190112      4.675000              Miss      411.741935      0.704301      2.284946      21.860000      0.698925      0.537634      1.085686      2.236559              Mr      455.880907      0.162571      2.381853      32.739609      0.293006      0.151229      0.932798      1.444234              Mrs      456.393701      0.795276      1.984252      35.981818      0.692913      0.818898      1.207905      2.511811              Other      564.444444      0.111111      1.666667      45.888889      0.111111      0.111111      0.958425      1.222222      df_train.groupby('Initial')['Survived'].mean().plot.bar()&lt;AxesSubplot:xlabel='Initial'&gt;df_train.loc[(df_train['Age'].isnull())&amp;(df_train['Initial']=='Mr'),'Age']=33df_train.loc[(df_train['Age'].isnull())&amp;(df_train['Initial']=='Mrs'),'Age']=36df_train.loc[(df_train['Age'].isnull())&amp;(df_train['Initial']=='Master'),'Age']=5df_train.loc[(df_train['Age'].isnull())&amp;(df_train['Initial']=='Miss'),'Age']=22df_train.loc[(df_train['Age'].isnull())&amp;(df_train['Initial']=='Other'),'Age']=46df_test.loc[(df_test['Age'].isnull())&amp;(df_test['Initial']=='Mr'),'Age']=33df_test.loc[(df_test['Age'].isnull())&amp;(df_test['Initial']=='Mrs'),'Age']=36df_test.loc[(df_test['Age'].isnull())&amp;(df_test['Initial']=='Master'),'Age']=5df_test.loc[(df_test['Age'].isnull())&amp;(df_test['Initial']=='Miss'),'Age']=22df_test.loc[(df_test['Age'].isnull())&amp;(df_test['Initial']=='Other'),'Age']=46df_train.loc[(df_train['Initial']=='Mr'),'Age'].isnull().sum&lt;bound method Series.sum of 0      False4      False5      False6      False12     False       ...  881    False883    False884    False889    False890    FalseName: Age, Length: 529, dtype: bool&gt;Fill Null in Embarked and categorize Agedf_train['Embarked'].isnull().sum()2df_train['Embarked'].fillna('S',inplace=True)df_train['Embarked'].isnull().sum()0df_train.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked      FamilySize      Initial                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      0.683603      NaN      S      2      Mr              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      1.450832      C85      C      2      Mrs              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      0.727559      NaN      S      1      Miss              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      1.379314      C123      S      2      Mrs              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      0.735091      NaN      S      1      Mr      df_train.loc[df_train['Age']&lt;10,'Age_cat']=0df_train.loc[(df_train['Age']&gt;=10)&amp;(df_train['Age']&lt;20),'Age_cat']=1df_train.loc[(df_train['Age']&gt;=20)&amp;(df_train['Age']&lt;30),'Age_cat']=2df_train.loc[(df_train['Age']&gt;=30)&amp;(df_train['Age']&lt;40),'Age_cat']=3df_train.loc[(df_train['Age']&gt;=40)&amp;(df_train['Age']&lt;50),'Age_cat']=4df_train.loc[(df_train['Age']&gt;=50)&amp;(df_train['Age']&lt;60),'Age_cat']=5df_train.loc[(df_train['Age']&gt;=60)&amp;(df_train['Age']&lt;70),'Age_cat']=6df_train.loc[df_train['Age']&gt;=70,'Age_cat']=7df_test.loc[df_test['Age']&lt;10,'Age_cat']=0df_test.loc[(df_test['Age']&gt;=10)&amp;(df_test['Age']&lt;20),'Age_cat']=1df_test.loc[(df_test['Age']&gt;=20)&amp;(df_test['Age']&lt;30),'Age_cat']=2df_test.loc[(df_test['Age']&gt;=30)&amp;(df_test['Age']&lt;40),'Age_cat']=3df_test.loc[(df_test['Age']&gt;=40)&amp;(df_test['Age']&lt;50),'Age_cat']=4df_test.loc[(df_test['Age']&gt;=50)&amp;(df_test['Age']&lt;60),'Age_cat']=5df_test.loc[(df_test['Age']&gt;=60)&amp;(df_test['Age']&lt;70),'Age_cat']=6df_test.loc[df_test['Age']&gt;=70,'Age_cat']=7df_train.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked      FamilySize      Initial      Age_cat                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      0.683603      NaN      S      2      Mr      2.0              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      1.450832      C85      C      2      Mrs      3.0              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      0.727559      NaN      S      1      Miss      2.0              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      1.379314      C123      S      2      Mrs      3.0              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      0.735091      NaN      S      1      Mr      3.0      df_test.head()                  PassengerId      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked      Initial      Age_cat                  0      892      3      Kelly, Mr. James      male      34.5      0      0      330911      2.057860      NaN      Q      Mr      3.0              1      893      3      Wilkes, Mrs. James (Ellen Needs)      female      47.0      1      0      363272      1.945910      NaN      S      Mrs      4.0              2      894      2      Myles, Mr. Thomas Francis      male      62.0      0      0      240276      2.270836      NaN      Q      Mr      6.0              3      895      3      Wirz, Mr. Albert      male      27.0      0      0      315154      2.159003      NaN      S      Mr      2.0              4      896      3      Hirvonen, Mrs. Alexander (Helga E Lindqvist)      female      22.0      1      1      3101298      2.508582      NaN      S      Mrs      2.0      def category_age(x):    if x&lt;10:        return 0    elif x&lt;20:        return 1    elif x&lt;30:        return 2    elif x&lt;40:        return 3    elif x&lt;50:        return 4    elif x&lt;60:        return 5    elif x&lt;70:        return 6    else:        return 7df_train['Age_cat_2']=df_train['Age'].apply(category_age)df_train.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked      FamilySize      Initial      Age_cat      Age_cat_2                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      0.683603      NaN      S      2      Mr      2.0      2              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      1.450832      C85      C      2      Mrs      3.0      3              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      0.727559      NaN      S      1      Miss      2.0      2              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      1.379314      C123      S      2      Mrs      3.0      3              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      0.735091      NaN      S      1      Mr      3.0      3      (df_train['Age_cat']==df_train['Age_cat_2']).all()Truedf_train.drop(['Age','Age_cat_2'],axis=1,inplace=True)df_test.drop(['Age'],axis=1,inplace=True)Change string to categorical and Pearson coefficientdf_train.Initial.unique()array(['Mr', 'Mrs', 'Miss', 'Master', 'Other'], dtype=object)df_train.loc[df_train['Initial']=='Master','Initial']7      Master16     Master50     Master59     Master63     Master65     Master78     Master125    Master159    Master164    Master165    Master171    Master176    Master182    Master183    Master193    Master261    Master278    Master305    Master340    Master348    Master386    Master407    Master445    Master480    Master489    Master549    Master709    Master751    Master755    Master787    Master788    Master802    Master803    Master819    Master824    Master827    Master831    Master850    Master869    MasterName: Initial, dtype: objectdf_train['Initial'] = df_train['Initial'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4})df_test['Initial'] = df_test['Initial'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4})df_train.Embarked.unique()array(['S', 'C', 'Q'], dtype=object)df_train['Embarked'].value_counts()S    646C    168Q     77Name: Embarked, dtype: int64df_train['Embarked']=df_train['Embarked'].map({'C':0,'Q':1,'S':2})df_test['Embarked']=df_test['Embarked'].map({'C':0,'Q':1,'S':2})df_train.head()                  PassengerId      Survived      Pclass      Name      Sex      SibSp      Parch      Ticket      Fare      Cabin      Embarked      FamilySize      Initial      Age_cat                  0      1      0      3      Braund, Mr. Owen Harris      male      1      0      A/5 21171      0.683603      NaN      2      2      2      2.0              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      1      0      PC 17599      1.450832      C85      0      2      3      3.0              2      3      1      3      Heikkinen, Miss. Laina      female      0      0      STON/O2. 3101282      0.727559      NaN      2      1      1      2.0              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      1      0      113803      1.379314      C123      2      2      3      3.0              4      5      0      3      Allen, Mr. William Henry      male      0      0      373450      0.735091      NaN      2      1      2      3.0      df_train.Embarked.isnull().any()Falsedf_train['Sex'].unique()array(['male', 'female'], dtype=object)df_train['Sex']=df_train['Sex'].map({'female':0,'male':1})df_test['Sex']=df_test['Sex'].map({'female':0,'male':1})heatmap_data=df_train[['Survived','Pclass','Sex','Fare','Embarked','FamilySize','Initial','Age_cat']]heatmap_data.corr()                  Survived      Pclass      Sex      Fare      Embarked      FamilySize      Initial      Age_cat                  Survived      1.000000      -0.338481      -0.543351      0.332593      -0.167675      0.016639      -0.085529      -0.095002              Pclass      -0.338481      1.000000      0.131900      -0.659932      0.162098      0.065997      -0.133054      -0.314809              Sex      -0.543351      0.131900      1.000000      -0.271514      0.108262      -0.200988      0.051687      0.122917              Fare      0.332593      -0.659932      -0.271514      1.000000      -0.177469      0.410847      -0.016650      0.068385              Embarked      -0.167675      0.162098      0.108262      -0.177469      1.000000      0.066516      0.026550      -0.033173              FamilySize      0.016639      0.065997      -0.200988      0.410847      0.066516      1.000000      -0.204574      -0.280537              Initial      -0.085529      -0.133054      0.051687      -0.016650      0.026550      -0.204574      1.000000      0.481309              Age_cat      -0.095002      -0.314809      0.122917      0.068385      -0.033173      -0.280537      0.481309      1.000000      colormap=plt.cm.BuGnplt.figure(figsize=(12,10))plt.title('Pearson Correlation of Features',y=1.05,size=15)sns.heatmap(heatmap_data.astype(float).corr(),linewidths=0.1,vmax=2,square=True,cmap=colormap,linecolor='white',annot=True,annot_kws={'size':16},fmt='.2f')&lt;AxesSubplot:title={'center':'Pearson Correlation of Features'}&gt;One-hot encoding on the Initial and Embarkeddf_test.head()                  PassengerId      Pclass      Name      Sex      SibSp      Parch      Ticket      Fare      Cabin      Embarked      Initial      Age_cat                  0      892      3      Kelly, Mr. James      1      0      0      330911      2.057860      NaN      1      2      3.0              1      893      3      Wilkes, Mrs. James (Ellen Needs)      0      1      0      363272      1.945910      NaN      2      3      4.0              2      894      2      Myles, Mr. Thomas Francis      1      0      0      240276      2.270836      NaN      1      2      6.0              3      895      3      Wirz, Mr. Albert      1      0      0      315154      2.159003      NaN      2      2      2.0              4      896      3      Hirvonen, Mrs. Alexander (Helga E Lindqvist)      0      1      1      3101298      2.508582      NaN      2      3      2.0      df_train = pd.get_dummies(df_train, columns=['Initial'], prefix='Initial')df_test = pd.get_dummies(df_test, columns=['Initial'], prefix='Initial')df_train = pd.get_dummies(df_train, columns=['Embarked'], prefix='Embarked')df_test = pd.get_dummies(df_test, columns=['Embarked'], prefix='Embarked')df_train.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)df_test.drop(['PassengerId', 'Name',  'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)df_test.head()                  Pclass      Sex      Fare      Age_cat      Initial_0      Initial_1      Initial_2      Initial_3      Initial_4      Embarked_0      Embarked_1      Embarked_2                  0      3      1      2.057860      3.0      0      0      1      0      0      0      1      0              1      3      0      1.945910      4.0      0      0      0      1      0      0      0      1              2      2      1      2.270836      6.0      0      0      1      0      0      0      1      0              3      3      1      2.159003      2.0      0      0      1      0      0      0      0      1              4      3      0      2.508582      2.0      0      0      0      1      0      0      0      1      df_train.head()                  Survived      Pclass      Sex      Fare      FamilySize      Age_cat      Initial_0      Initial_1      Initial_2      Initial_3      Initial_4      Embarked_0      Embarked_1      Embarked_2                  0      0      3      1      0.683603      2      2.0      0      0      1      0      0      0      0      1              1      1      1      0      1.450832      2      3.0      0      0      0      1      0      1      0      0              2      1      3      0      0.727559      1      2.0      0      1      0      0      0      0      0      1              3      1      1      0      1.379314      2      3.0      0      0      0      1      0      0      0      1              4      0      3      1      0.735091      1      3.0      0      0      1      0      0      0      0      1      Machine learningl(Randomforest)from sklearn.ensemble import RandomForestClassifierfrom sklearn import metricsfrom sklearn.model_selection import train_test_splitdf_train.head()                  Survived      Pclass      Sex      Fare      FamilySize      Age_cat      Initial_0      Initial_1      Initial_2      Initial_3      Initial_4      Embarked_0      Embarked_1      Embarked_2                  0      0      3      1      0.683603      2      2.0      0      0      1      0      0      0      0      1              1      1      1      0      1.450832      2      3.0      0      0      0      1      0      1      0      0              2      1      3      0      0.727559      1      2.0      0      1      0      0      0      0      0      1              3      1      1      0      1.379314      2      3.0      0      0      0      1      0      0      0      1              4      0      3      1      0.735091      1      3.0      0      0      1      0      0      0      0      1      df_test.head()                  Pclass      Sex      Fare      Age_cat      Initial_0      Initial_1      Initial_2      Initial_3      Initial_4      Embarked_0      Embarked_1      Embarked_2                  0      3      1      2.057860      3.0      0      0      1      0      0      0      1      0              1      3      0      1.945910      4.0      0      0      0      1      0      0      0      1              2      2      1      2.270836      6.0      0      0      1      0      0      0      1      0              3      3      1      2.159003      2.0      0      0      1      0      0      0      0      1              4      3      0      2.508582      2.0      0      0      0      1      0      0      0      1      X_train=df_train.drop('Survived',axis=1).valuestarget_label=df_train['Survived'].valuesX_test=df_test.valuesX_tr, X_vld, y_tr, y_vld = train_test_split(X_train, target_label, test_size=0.3, random_state=2018)model = RandomForestClassifier()model.fit(X_tr, y_tr)prediction = model.predict(X_vld)print('총 {}명 중 {:.2f}% 정확도로 생존 맞춤'.format(y_vld.shape[0], 100 * metrics.accuracy_score(prediction, y_vld)))총 268명 중 82.09% 정확도로 생존 맞춤feature importance and prediction on test setmodel.feature_importances_array([0.09818595, 0.10792619, 0.32805606, 0.09146926, 0.1232598 ,       0.01214762, 0.04206886, 0.11624336, 0.02958443, 0.0041871 ,       0.01512252, 0.01363153, 0.01811731])from pandas import Seriesfeature_importance = model.feature_importances_Series_feat_imp = Series(feature_importance, index=df_test.columns)plt.figure(figsize=(8, 8))Series_feat_imp.sort_values(ascending=True).plot.barh()plt.xlabel('Feature importance')plt.ylabel('Feature')plt.show()submission = pd.read_csv('gender_submission.csv')submission.head()                   PassengerId      Survived                  0      892      0              1      893      1              2      894      0              3      895      0              4      896      1      prediction = model.predict(X_test)submission['Survived'] = prediction",
        "url": "/programming-kaggle2"
    }
    ,
    
    "programming-baekjoon6": {
        "title": "백준 (6) &lt;br&gt; (3085, 2563, 4673, 5635, 11170)",
            "author": "keonju",
            "category": "",
            "content": "백준 관련 글    백준 (1) (2557, 8958, 1000, 1001, 1008, 2935, 2753, 2884, 5063, 4101)    백준 (2) (1018, 1085, 1181, 1259, 1436, 1654, 1874, 1920)    백준 (3) 문자열 알고리즘(11720, 8958, 1152, 10809, 1157, 9012, 11718)    백준 (4) (1157, 1546, 2577, 2675, 2908, 1018, 1436, 1259, 7568, 10250)    백준 (5) 정렬 알고리즘(2750,11399,2751,1427, 10989,1181,11650)    백준 (6) (3085, 2563, 4673, 5635, 11170)    백준 (7) 스택 알고리즘(10828,10773,1874,10799, 4949,1406,2493)백준 5문제를 풀어보았다.중복되는 문제도 있습니다3085번 사탕 게임https://www.acmicpc.net/problem/3085먼저 보드는 한 글자당 리스트 한 요소를 차지하게끔 이중으로 만든다.check 함수를 통해 보드에 연속된 사탕이 몇개인지 만들어준다.그 다음 for문을 통해 값들을 하나씩 변경해보고 가장 많은 값을 찾는다.num=int(input())board=[]answer=0for i in range(num):    candy=list(input())    board.append(candy)3CCPCCPPCCdef check(board):    n=len(board)    answer=1 #연속된 사탕의 결과        for i in range(n):        count=1        for j in range(1, n):            if board[i][j] == board[i][j-1]:  #열에서 같다면 +1 해주기                count += 1            else:                count=1    # 같지 않다면 1로 초기화            if count &gt; answer:                answer = count # 가장 큰 값을 answer로 반환        count=1 # 행 결과를 찾기 위한 초기화        for j in range(1, n):            if board[j][i] == board[j-1][i]: # 행에서 최대값 찾기                count += 1            else:                count=1            if count &gt; answer:                answer = count    return answeranswer=0for i in range(num):    for j in range(num):        if j+1 &lt; num:            board[i][j],board[i][j+1] =board[i][j+1],board[i][j] # 열에서 값 바꾸기            temp=check(board) # 최대 개수 확인하기            if temp &gt; answer:                answer = temp # 가장 많은 값으로 저장            board[i][j], board[i][j+1] = board[i][j+1], board[i][j] # 값 초기화하기        if i+1 &lt; num: #행에서 마찬가지로 진행            board[i][j], board[i+1][j] = board[i+1][j], board[i][j]            temp=check(board)            if temp &gt; answer:                answer = temp                        board[i][j], board[i+1][j] = board[i+1][j], board[i][j]            print(answer)32563번 색종이https://www.acmicpc.net/problem/2563100 * 100의 흰 색종이를 먼저 만들어준다.다음 입력받은 색종이만큼 0을 1로 바꿔주면 중복도 해결하면서 검은색을 표시할 수 있다.1이 된 숫자의 부분만 세면 된다.paper=[[0 for i in range(101)] for j in range(101)]for i in range(int(input())):    x,y=map(int,input().split())    for j in range(x,x+10):        for k in range(y,y+10):            paper[j][k]=1result=0for i in paper:    result += i.count(1)print(result)33 715 75 22604673번 색종이https://www.acmicpc.net/problem/4673for문을 통해 숫자들의 셀프 넘버를 구해서 초기 [1:10000]의 리스트에서 셀프 넘버가 나오면 제거해주었다.self_num=[i for i in range(1,10001)]for i in range(1,10001):    total=i    num=str(i)    for j in range(len(num)):        total=total+int(num[j])    if total in self_num:        self_num.remove(total)for i in range(len(self_num)):    print(self_num[i])135792031425364758697108110121132143154165176187198209211222233244255266277288299310312323334345356367378389400411413424435446457468479490501512514525536547558569580591602613615626637648659670681692703714716727738749760771782793804815817828839850861872883894905916918929940951962973984995100610211032104310541065107610871098110911111122113311441155116611771188119912101212122312341245125612671278128913001311131313241335134613571368137913901401141214141425143614471458146914801491150215131515152615371548155915701581159216031614161616271638164916601671168216931704171517171728173917501761177217831794180518161818182918401851186218731884189519061917191919301941195219631974198519962007202220332044205520662077208820992110211221232134214521562167217821892200221122132224223522462257226822792290230123122314232523362347235823692380239124022413241524262437244824592470248124922503251425162527253825492560257125822593260426152617262826392650266126722683269427052716271827292740275127622773278427952806281728192830284128522863287428852896290729182920293129422953296429752986299730083023303430453056306730783089310031113113312431353146315731683179319032013212321432253236324732583269328032913302331333153326333733483359337033813392340334143416342734383449346034713482349335043515351735283539355035613572358335943605361636183629364036513662367336843695370637173719373037413752376337743785379638073818382038313842385338643875388638973908391939213932394339543965397639873998400940244035404640574068407940904101411241144125413641474158416941804191420242134215422642374248425942704281429243034314431643274338434943604371438243934404441544174428443944504461447244834494450545164518452945404551456245734584459546064617461946304641465246634674468546964707471847204731474247534764477547864797480848194821483248434854486548764887489849094920492249334944495549664977498849995010502550365047505850695080509151025113511551265137514851595170518151925203521452165227523852495260527152825293530453155317532853395350536153725383539454055416541854295440545154625473548454955506551755195530554155525563557455855596560756185620563156425653566456755686569757085719572157325743575457655776578757985809582058225833584458555866587758885899591059215923593459455956596759785989600060116026603760486059607060816092610361146116612761386149616061716182619362046215621762286239625062616272628362946305631663186329634063516362637363846395640664176419643064416452646364746485649665076518652065316542655365646575658665976608661966216632664366546665667666876698670967206722673367446755676667776788679968106821682368346845685668676878688969006911692269246935694669576968697969907001701270277038704970607071708270937104711571177128713971507161717271837194720572167218722972407251726272737284729573067317731973307341735273637374738573967407741874207431744274537464747574867497750875197521753275437554756575767587759876097620762276337644765576667677768876997710772177237734774577567767777877897800781178227824783578467857786878797890790179127923792579367947795879697980799180028013802880398050806180728083809481058116811881298140815181628173818481958206821782198230824182528263827482858296830783188320833183428353836483758386839784088419842184328443845484658476848784988509852085228533854485558566857785888599861086218623863486458656866786788689870087118722872487358746875787688779879088018812882388258836884788588869888088918902891389248926893789488959897089818992900390149029904090519062907390849095910691179119913091419152916391749185919692079218922092319242925392649275928692979308931993219332934393549365937693879398940994209422943394449455946694779488949995109521952395349545955695679578958996009611962296249635964696579668967996909701971297239725973697479758976997809791980298139824982698379848985998709881989299039914992599279938994999609971998299935635번 생일https://www.acmicpc.net/problem/5635for문을 통해 글자들을 입력받고 연-월-일 부분을 정수형으로 치환한다.sort와 lambda를 이용해서 오름차순으로 정렬하면 가장 마지막 사람이 어리고 가장 처음 사람이 나이가 가장 많을 것이다.people=[]for i in range(int(input())):    person=list(input().split(' '))    person[1]=int(person[1])    person[2]=int(person[2])    person[3]=int(person[3])    people.append(person)people.sort(key=lambda x:[x[3],x[2],x[1]])print(people[-1][0])print(people[0][0])4Mickey 1 10 1991Jerry 18 9 1990Tom 15 8 1993Alice 30 12 1990[['Jerry', 18, 9, 1990], ['Alice', 30, 12, 1990], ['Mickey', 1, 10, 1991], ['Tom', 15, 8, 1993]]TomJerry11170번 0의 개수https://www.acmicpc.net/problem/11170a,b 두 숫자 사이의 모든 숫자들을 붙여서 하나의 글자로 만들어준다음 count함수를 사용하였다.for i in range(int(input())):    a,b=input().split()        word=''    for j in range(int(a),int(b)+1):        word=word+str(j)        print(word.count('0'))30 10233 10051991 40",
        "url": "/programming-baekjoon6"
    }
    ,
    
    "programming-baekjoon5": {
        "title": "백준 (5) 정렬 알고리즘 &lt;br&gt; (2750,11399,2751,1427, &lt;br&gt; 10989,1181,11650,2309)",
            "author": "keonju",
            "category": "",
            "content": "백준 관련 글    백준 (1) (2557, 8958, 1000, 1001, 1008, 2935, 2753, 2884, 5063, 4101)    백준 (2) (1018, 1085, 1181, 1259, 1436, 1654, 1874, 1920)    백준 (3) 문자열 알고리즘(11720, 8958, 1152, 10809, 1157, 9012, 11718)    백준 (4) (1157, 1546, 2577, 2675, 2908, 1018, 1436, 1259, 7568, 10250)    백준 (5) 정렬 알고리즘(2750,11399,2751,1427, 10989,1181,11650)    백준 (6) (3085, 2563, 4673, 5635, 11170)    백준 (7) 스택 알고리즘(10828,10773,1874,10799, 4949,1406,2493)정렬에 관련된 8문제를 풀어보았다.중복되는 문제도 있습니다https://www.acmicpc.net/problemset?sort=ac_desc&amp;algo=158정렬은 병합 정렬, 분할 정복, 퀵 정렬, 힙 정렬, 계수 정렬 등 공부할 개념들이 많았다.2750번 수 정렬하기https://www.acmicpc.net/problem/2750sorted를 통해 입력받은 숫자들을 오름차순으로 정렬하는 문제였다.num=int(input())n_list=sorted([int(input()) for i in range(num)])for j in n_list:    print(j)5523411234511399번 ATMhttps://www.acmicpc.net/problem/11399total과 temp를 통해 temp에서는 n번째 사람이 걸리는 시간을 저장해주고 total에 전 사람까지 걸린 시간을 저장해주었다.people=int(input()) #사람수 입력time=sorted(list(map(int,input().split()))) #map으로 split된 값을 list로 저장 후 sorted로 오름차순 정렬53 1 4 3 2total=0 #n번째 사람까지 걸린 시간의 총합temp=0 #n번째 사람이 기다린 시간for i in time:    temp=temp+i #n번째 사람이 기다린 시간= 이전 사람이 기다린 시간+ 그 사람이 걸리는 시간    total=temp+total print(total)322751번 수 정렬하기 2https://www.acmicpc.net/problem/2751pypy3으로 제출하면 이렇게도 해결이 된다.num=int(input())n_list=sorted([int(input()) for i in range(num)])for j in n_list:    print(j)55432112345하지만 python3로는 시간초과가 발생한다.이 문제는 앞에 2750번과 다르게 N의 범위가 100만까지이다. 따라서 시간복잡도 문제라고 볼 수 있다.시간복잡도를 할 수 있는 방법은 병합 정렬, 퀵 정렬, 힙 정렬이 있다.병합 정렬병합 정렬은 데이터를 절반씩 나누어 끝까지 갔다가 다시 절반씩 합치면서 정렬하는 방법이다.이 때 분할 단계에서 깊이가 logN에 비례하지만, 깊이별로 수행되는 merge의 시간복잡도는 O(N)이다.  리스트 요소가 1개가 될때까지 나눈다.  분리한 왼쪽리스트, 오른쪽 리스트의 각각 첫번째 요소를 비교해 더 작은 값을 결과 리스트에 저장한다.  저장한 값은 리스트에서 지운다.  두 리스트 모두 요소가 하나도 안남을 때까지 반복한다.병합 정렬을 이용한 풀이병합 정렬을 이용할 때는 먼저 def로 병합 정렬 함수를 만들어준다.모든 리스트 요소가 1개가 될때까지 나눈다.따라서 중간값을 기준으로 나누어주면 된다.여기서도 input 대신 sys.stdin.readline()를 사용해야한다.import sysn=int(input())unsorted=[]result=[]# 분할def Divided(list):    #길이가 1일때 중단    if len(list)&lt;=1:        return list    #중간값을 기준으로 리스트 분할    mid = len(list)//2    less_part=list[:mid]    more_part=list[mid:]    less_part=Divided(less_part)    more_part=Divided(more_part)    return merge(less_part,more_part)#비교와 합병def merge(less,more):    merged_list=[]    l,h=0,0    #less와 more을 돌면서 대소관계 비교 후 작은 곳에 append    while l&lt;len(less) and h&lt;len(more):        if less[l]&lt;more[h]:            merged_list.append(less[l])            l=l+1        else:            merged_list.append(more[h])            h=h+1    merged_list+=less[l:]    merged_list+=more[h:]    return merged_listfor i in range(n):    num=int(input())    unsorted.append(num)result=Divided(unsorted)for i in result:    print(i)7643125712345671427번 소트인사이드https://www.acmicpc.net/problem/1427N을 문자열로 입력받아서 각 글자들을 list에 넣고 sort를 해줘도 오름차순으로 정렬이 된다.따라서 reverse를 통해 내림차순으로 만들어주고 join으로 다시 문자열로 만들어주었다.N=input()2143print(''.join(sorted([i for i in N],reverse=True)))432110989 수 정렬하기 3https://www.acmicpc.net/problem/10989메모리 초과가 발생하는 코드sys.stdin.readline()를 사용하여도, pypy3를 사용하여도 메모리 초과가 발생한다.아마 첫째 줄에 범위가 1&lt;=N&lt;=10000000 까지 넓고 수 또한 10000 이하의 자연수로 매우 크기 때문이 아닐까 생각된다.num=int(input())n_list=sorted([int(input()) for i in range(num)])for j in n_list:    print(j)1052314235171122334557계수 정렬(counting sort) 알고리즘따라서 검색을 해보니 계수 정렬 알고리즘이라는 방식이 있다고 한다.계수 정렬의 특징은  데이터의 크기 범위가 제한되어 정수 형태로 표현할 수 있을 때만 사용할 수 있다.매우 빠르다.모든 범위를 담을 수 있는 리스트를 선언해야한다.즉, 일단 범위가 되는 모든 자연수의 크기와 같은 리스트를 생성해야한다.숫자를 입력 받으면 해당하는 숫자가 나타내는 리스트 인덱스에 +1을 해주는 것이다.따라서 숫자가 입력 받았으면 1 이상이 나올 것이고 아니라면 0일 것이다.입력받은 숫자의 빈도를 물어본다면 인덱스와 값을 출력시키면 될 것이고입력받은 숫자를 정렬한다면 0이 아닌 리스트의 인덱스 값을 순서대로 출력해주면 된다.계수 정렬을 이용한 풀이따라서 nlist를 통해 자연수 범위만큼 0인 리스트를 선언해주었다.그 다음 입력받은 n값을 nlist의 인덱스에서 찾아서 +1 해주었다.그 다음 nlist의 값들을 찾으면서 0보다 큰 값들만 찾아주고 그 값들의 인덱스만 추출해주면 된다.이 문제도 input을 사용하면 시간 초과가 발생한다.#계수 정렬을 이용한 풀이import sysn=int(input())nlist=[0 for i in range(10001)]for i in range(n):    nlist[int(input())]+=1for i in range(len(nlist)):    if nlist[i]&gt;0:        for j in range(nlist[i]):            print(i)105231423517112233455711650번 좌표 정렬하기https://www.acmicpc.net/problem/11650 sort() 함수에서 key 파라미터에 (x,y)를 넣어주면 x를 우선 정렬해주고 y를 정렬해준다.주피터 노트북을 사용하면서 sys.stdin.readline()을 사용한 적이 없었는데 주피터 노트북에선 stdin이 잘 구현이 안된다고 한다.따라서 밑에 코드에는 input()을 사용하였지만 백준에 제출할 때는 sys.stdin.readline()으로 제출하였다.input()을 하게되면 시간 초과 결과가 나오고 pypy3로 제출하면 input()을 사용해도 괜찮은 것으로 보인다.import sysN=input()nlist=[]for i in range(int(N)):    x,y=map(int,input().split()) #실제 제출에서는 sys.stdin.readline()을 사용하였다    nlist.append((x,y))53 41 11 -12 23 3nlist.sort(key=lambda x: (x[0],x[1]))for j in nlist:    print(j[0],j[1])1 -11 12 23 33 42309번 일곱 난쟁이https://www.acmicpc.net/problem/2309이 문제는 input()을 사용하여도 시간초과는 나오지 않는다.n_list에서 두 가지씩 고르는 모든 경우의 수를 찾아야하기 때문에 이중 for문을 사용하였다.j는 i와 같이 않아야하기 때문에 i+1로 중복을 피했다.모든 값의 합이 100 이 되기 때문에 두 개씩 골라서 빼주었을 때 100 이 되면 그 두 값을 remove를 통해 제거하고 sorted로 내림차순 정렬한 뒤 출력해주면 된다.첫 for문이 끝나야하기 때문에 조건에 맞는 답을 골라주면 멈추면 된다.n_list=[]for i in range(1,10):    tall=int(input())    n_list.append(tall)2072319101525813result= sum(n_list)for i in range(9):    for j in range(i+1,9):        if result-(n_list[i]+n_list[j])==100:            a,b=n_list[i],n_list[j]            n_list.remove(a)            n_list.remove(b)            n_list=sorted(n_list)            for k in range(7):                print(n_list[k])            break    if len(n_list)==7:        break781013192023",
        "url": "/programming-baekjoon5"
    }
    ,
    
    "study-ml2": {
        "title": "머신러닝 정리 (2) &lt;br&gt; 지도학습 (2)",
            "author": "keonju",
            "category": "",
            "content": "머신러닝 공부 관련 글    머신러닝 정리 (1)-지도학습 (1)    머신러닝 정리 (2)-지도학습 (2)    머신러닝 정리 (3)-비지도학습 (1)    머신러닝 정리 (4)-비지도학습 (2)머신러닝 정리 (2) - 지도학습 (2)본 문서는 [파이썬 라이브러리를 활용한 머신러닝] 책을 공부하면서 요약한 내용입니다.또 데이터 청년 캠퍼스 수업과 학교 수업에서 배운 내용들도 함께 정리했습니다.글의 순서는 [파이썬 라이브러리를 활용한 머신러닝]에 따라 진행됩니다.코드는 밑에 링크에 공개되어있기 때문에 올리지않습니다.소스 코드: https://github.com/rickiepark/introduction_to_ml_with_python지도학습 (2)  결정 트리  결정 트리의 앙상블  배깅, 엑스트라 트리, 에이다부스트          배깅      엑스트라 트리      선형 모델      에이다부스트        커널 서포트 벡터 머신  신경망 (딥러닝)  분류 예측의 불확실성 추정          결정 함수      예측 확률      다중 분류에서의 불확실성      결정 트리Decision Tree 결정 트리는 분류와 회귀 문제에서 사용되는 모델입니다.스무고개처럼 예/아니오로 나눌 수 있는 조건을 통해서 결정에 다다르게 됩니다.질문과 정답은 노드가 되고 특히 마지막 노드는 리프라고 합니다. 결정트리의 구조는 왼쪽 하단에 사진처럼 가장 위에는 Root node, 질문과 답을 연결하는 Edge, 내부의 Internal node, 마지막 노드는 Leaf node, 그리고 Depth로 구성됩니다.결정 트리 만들기 결정 트리를 학습한다는 것은 정답에 가장 빨리 도달하는 예/아니오 질문 (TEST) 목록을 학습한다는 뜻입니다.보통 데이터들은 예/아니오 특성으로 구분되지 않고  연속적인 특성을 가진 2차원 데이터 셋에서 보통 ‘특성 i는 값 a보다 큰가?’의 형태와 같은 테스트를 가집니다.이 데이터들을 X[1]&lt;=0.6인 테스트로 나누어 봅니다.알고리즘은 가능한 모든 테스트에서 타깃 값에 대해 가장 많은 정보를 가진 것을 고르게 됩니다.따라서 X[1]&lt;=0.6인 테스트를 선택하게 됩니다.결정 트리에서 각 테스트는 하나의 축을 따라 데이터를 나눕니다.하나의 질문당 하나의 축을 만들어서 영역이 한 개의 타깃값을 가질 때까지 반복됩니다. 결정 트리의 멈춤 조건입니다.즉, 미리 정의한 조건들이 없다면 가지를 만들 수 있을 때까지 만드는 것을 알 수 있습니다.결정트리의 예측은 그 포인트가 어느 리프에 들어갈지 확인하는 것인데 분류는 타깃 값 중 다수인 것이 예측 결과가 되고 회귀의 경우 리프 노드의 훈련 데이터 평균값이 결과로 출력됩니다.결정 트리 복잡도 제어하기 결정 경계가 클래스 포인트에 멀리 떨어진 이상치에 민감하게 되어 모든 리프 노드가 순수 노드가 될 때까지 진행하면 모델이 복잡해지고 과대적합이 발생합니다.과대적합을 막기 위한 방법은 크게 사전가지치기, 사후 가지치기 두 가지입니다.사전 가지치기는 이름에서 알 수 있듯이 모델을 만들 때 깊이나 리프의 개수 또는 테스트의 최소 개수를 미리 제한하는 것입니다.미리 제한하기 때문에 정말로 중요한 포인트를 분류하지않을 수 있습니다.사후 가지치기 역시 이름에서 알 수 있듯이 트리가 만들어진 뒤 포인트가 적은 노드를 삭제 혹은 병합하게 되는데 에러감소 프루닝, 룰 포스트 프루닝 같은 방법들이 있습니다.참고에러감소 프루닝  모든 노드를 프루닝 대상으로 고려노드 제거 후 검증을 통해 제거 전, 후 정확도 비교제거 전보다 정확도가 낮아지기 전까지 반복룰 포스트 프루닝  의사결정 트리를 룰셋으로 변환 (룰은 루트부터 리프까지의 경로)이 룰셋 속성들에 정확도를 떨어뜨리는 속성을 제거프루닝 완료 후 정확도 순으로 정렬해 이 순서대로 적용결정 트리는 다음과 같이 만들 수 있고 정확도를 확인할 수 있습니다.Default값은 모든 리프가 순수 노드가 되는 모델을 만들기 때문에 훈련 세트의 정확도가 100%가 됩니다.하지만 트리가 무한정 깊어지고 복잡해지고 일반화가 잘 되지 않습니다.from sklearn.tree import DecisionTreeClassifiercancer = load_breast_cancer()X_train, X_test, y_train, y_test = train_test_split(    cancer.data, cancer.target, stratify=cancer.target, random_state=42)tree = DecisionTreeClassifier(random_state=0)tree.fit(X_train, y_train)print(\"훈련 세트 정확도: {:.3f}\".format(tree.score(X_train, y_train)))print(\"테스트 세트 정확도: {:.3f}\".format(tree.score(X_test, y_test)))훈련 세트 정확도: 1.000테스트 세트 정확도: 0.937과대적합 때문에 반드시 훈련 세트의 정확도가 테스트 정확도와 비례하지 않아서 max_depth와 같은 파라미터를 통해 과대적합을 줄이고 테스트 세트 정확도를 높일 수 있습니다.tree = DecisionTreeClassifier(max_depth=4, random_state=0)tree.fit(X_train, y_train)print(\"훈련 세트 정확도: {:.3f}\".format(tree.score(X_train, y_train)))print(\"테스트 세트 정확도: {:.3f}\".format(tree.score(X_test, y_test)))훈련 세트 정확도: 0.988테스트 세트 정확도: 0.951결정 트리 분석 결정 트리를 생성하고 시각화하기 위해서는 다음과 같은 모듈이 필요합니다.# 트리 모델 생성from sklearn.tree import DecisionTreeClassifier # 트리의 시각화_1from sklearn.tree import export graphviz # 트리의 시각화_2 (.dot 파일을 만들지 않아도 가능)from sklearn.tree import plot_tree 그래프를 시각화하는 코드는 다음과 같이 쓸 수 있습니다.# graphviz 이용from sklearn.tree import export_graphvizexport_graphviz(tree, out_file=\"tree.dot\", class_names=[\"악성\", \"양성\"],                feature_names=cancer.feature_names, impurity=False, filled=True)#plot_treefrom sklearn.tree import plot_treeplot_tree(tree, class_names=[\"악성\", \"양성\"], feature_names=cancer.feature_names,         impurity=False, filled=True, rounded=True, fontsize=4)filled=True를 넣어주면 다음과 같이 색상이 들어가는 트리 모델을 얻을 수 있습니다.트리의 특성 중요도tree.feature_importane를 통해 특성 중요도를 알 수 있습니다.특성 중요도는 0부터 1 사이에 존재하는데 0은 전혀 사용되지 않은 특성, 1은 완벽하게 타깃 클래스를 예측한 특성을 의미합니다. 특성 중요도가 낮다는 유용하지 않다가 아닌 모델이 만들어질 때 특성을 선택하지 않았거나 특성과 중복되는 정보가 있다는 것을 의미합니다.전체 합은 1이 되고 따라서 특성중요도는 ‘이 모델이 만들어지는데 어떤 특성의 비율이 높은가?’ 정도의 해석이라고 생각하면 될 것 같습니다.Worst_radius만 보고 ‘반지름이 크면 양성이다?’ 를 알 수 없는 것처럼 특성 중요도는 어떤 클래스를 지지하는지 알려주지 않습니다.결정 트리의 회귀도 분류와 비슷하게 적용됩니다.단, 결정 트리를 회귀 모델로 사용하게 되면 훈련 데이터 범위 밖의 정보가 없어서 그 부분에 대한 예측이 불가능하게 됩니다.다음 모델은 트리 복잡도에 제한을 두지않아서 훈련 데이터는 완벽하게 예측하지만 데이터 범위 밖으로 나가면 마지막 포인트로 예측값을 출력합니다.따라서 트리 모델은 가격의 등락과 같은 예측을 할 때는 좋은 예측 모델을 만들 수 있지만 시계열 데이터에서는 데이터가 가진 시간 범위 밖의 예측은 안되기 때문에 잘 맞지 않습니다.장단점과 매개변수장점  해석력이 높습니다.데이터의 스케일에 구애받지 않습니다. 정규화나 표준화 같은 전처리 불필요합니다.특성의 스케일이 다르거나 이진특성, 연속적인 특성이 혼합되어도 잘 작동합니다.단점  과대적합되는 경향이 있어 일반화 성능이 좋지 않습니다.  축 평행을 구분하여 일부 관계에서 모델링이 어려움이 있습니다. 훈련 데이터에 대한 약간의 변경은 전체 결정논리에 큰 변화를 야기하여 샘플에 민감합니다.            매개변수      설명                  min_samples_split      - 노드를 분할하기 위한 최소한의 샘플 데이터수 → 과적합을 제어하는데 사용  - Default = 2 → 작게 설정할 수록 분할 노드가 많아져 과적합 가능성 증가              min_samples_leaf      - 리프노드가 되기 위해 필요한 최소한의 샘플 데이터수- min_samples_split과 함께 과적합 제어 용도- 불균형 데이터의 경우 특정 클래스의 데이터가 극도로 작을 수 있으므로 작게 설정 필요              max_features      - 최적의 분할을 위해 고려할 최대 feature 개수- Default = None → 데이터 세트의 모든 피처를 사용- int형으로 지정 →피처 갯수 / float형으로 지정 →비중- sqrt 또는 auto : 전체 피처 중 √(피처개수) 만큼 선정- log : 전체 피처 중 log2(전체 피처 개수) 만큼 선정              max_depth      - 트리의 최대 깊이- default = None→ 완벽하게 클래스 값이 결정될 때 까지 분할 또는 데이터 개수가 min_samples_split보다 작아질 때까지 분할- 깊이가 깊어지면 과적합될 수 있으므로 적절히 제어 필요              max_leaf_nodes      리프노드의 최대 개수      여기서 max_depth, max_leaf_nodes,min_samples_leaf 중 하나만 지정해도 과대적합을 막는데 충분한 역할을 합니다.결정 트리의 앙상블Ensemble앙상블은 여러 머신러닝 모델을 연결하여 더 강력한 모델을 만드는 기법입니다.책에서는 결정 트리의 앙상블로 한정하고 가장 많이 쓰이는 랜덤포레스트나 부스팅 모델은 트리 기반 모델이지만 앙상블은 다른 분류 모델을 결합하여 사용할 수도 있습니다.  Voting – 서로 다른 알고리즘을 가진 분류기를 결합  Bagging – 각각의 분류기는 모두 같은 유형의 알고리즘 기반, 모델을 다양하게 만들기 위해 데이터를 재구성 (랜덤포레스트)  Boosting – 맞추기 어려운 데이터에 대해 좀 더 가중치를 두어 학습 (Adaboost, Gradient Boosting)  Stacking – 모델의 output 값을 새로운 독립변수로 사용앙상블의 조건입니다.랜덤 포레스트랜덤 포레스트는 조금씩 다른 결정 트리의 묶음입니다.      데이터의 일부에 과대적합되는 경향을 이용하여 서로 다른 방향으로 과대적합된 트리를 많이 만들어 그 결과를 평균냄으로써 예측 성능은 유지되면서 결과적으론 과대적합이 줄어드는 아이디어에 기초합니다.결정 트리를 많이 만들면서 각 트리는 타깃 예측을 잘 해야 하고 다른 트리와 구별되어야 합니다.따라서 무작위성을 주입하는데 트리를 만들 때 사용하는 데이터 포인트를 무작위로 선택하거나 분할 테스트에서 특성을 무작위로 선택하는 방법을 이용합니다.랜덤 포레스트 구축from sklearn.ensemble import RandomForestClassifier (or RandomForestRegressor)n_estimators로 생성할 트리의 개수를 정합니다.부트스트랩 샘플은 n_samples개의 데이터 포인트 중에서 n_samples 횟수만큼 무작위로 중복 가능하게 반복 추출하는 것을 의미합니다.따라서 데이터 셋이 원래 크기와 같지만 누락되거나 중복되는 데이터가 만들어집니다.각 노드에서 전체 특성을 대상으로 최선의 테스트를 찾는 것이 아닌 알고리즘이 각 노드에서 후보 특성을 무작위로 선택한 후 이 후보들 중에서 최선의 테스트를 찾습니다. (max_features) 부트스트랩 샘플링을 통해 트리가 조금씩 다른 데이터셋을 이용해 만들어지도록 합니다.각 노드에서 특성의 일부만 사용하기 때문에 트리의 각 분기는 각기 다른 특성 부분 집합을 사용됩니다.max_features=n_features는 특성 선택에 무작위성이 들어가지 않습니다. (부트스트랩 샘플링에는 무작위성 그대로 입니다.)max_feature=1 트리의 분기는 테스트할 특성을 고를 필요가 없게 되고 무작위로 선택한 특성의 임계값 찾기만 하면 됩니다.max_feature이 커지면 랜덤 포레스트 트리들은 매우 비슷하고 가장 두드러진 특성으로 데이터에 잘 맞춰질 것이고 작으면 트리들은 서로 많이 달라지고 각 트리는 데이터에 맞추기 위해 깊이가 깊어지게 됩니다.랜덤 포레스트 예측의 경우 알고리즘이 모델에 있는 모든 트리의 예측을 만듭니다.회귀의 경우 이 예측들을 평균하여 최종 예측을 만듭니다.분류의 경우 약한 투표 전략을 사용합니다.약한 투표 전략은 각 알고리즘이 가능성 있는 출력 레이블의 확률을 제공하고 예측한 확률을 평균으로 가장 높은 확률을 가진 클래스가 예측값이 됩니다.참고로 강한 투표 전략은 다수의 분류기가 결정한 예측값을 최대로 하는 것을 말합니다.랜덤 포레스트 분석랜덤 포레스트 훈련 모델from sklearn.ensemble import RandomForestClassifierfrom sklearn.datasets import make_moonsX, y = make_moons(n_samples=100, noise=0.25, random_state=3)X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)forest = RandomForestClassifier(n_estimators=5, random_state=2)forest.fit(X_train, y_train)부트스트랩 샘플링 때문에 한쪽 트리에 나타나는 훈련 포인트가 다른 트리에는 포함되지 않을 수 있어 각 트리는 불완전하지만 랜덤포레스트의 결과는 좋은 결정경계를 보여줍니다.단일 트리와 다르게 랜덤 포레스트에서 가장 특성 중요도가 높은 특성은 worst perimeter입니다.랜덤 포레스트에서 더 많은 특성이 0 이상의 중요도를 갖고 따라서 더 넓은 시각으로 데이터를 바라볼 수 있습니다.X_train, X_test, y_train, y_test = train_test_split(    cancer.data, cancer.target, random_state=0)forest = RandomForestClassifier(n_estimators=100, random_state=0)forest.fit(X_train, y_train)print(\"훈련 세트 정확도: {:.3f}\".format(forest.score(X_train, y_train)))print(\"테스트 세트 정확도: {:.3f}\".format(forest.score(X_test, y_test)))훈련 세트 정확도: 1.000테스트 세트 정확도: 0.972랜덤 포레스트에선 훈련 데이터 정확도가 100% 이지만 단일 트리에 비해서 테스트 정확도가 상승한 것을 확인 할 수 있습니다.장단점과 매개변수장점  매개변수 튜닝을 많이 하지 않습니다. 데이터의 스케일에 구애받지 않습니다. 단일 트리의 단점을 보완하고 장점을 그대로 가지고 있습니다.단점  랜덤 포레스트의 트리는 특성의 일부만 사용하므로 결정 트리보다 더 깊어지는 경향이 있습니다.다른 random_state를 지정하면 전혀 다른 모델이 만들어집니다.텍스트 데이터와 같은 차원이 높고 희소한 데이터에 잘 작동하지 않습니다.선형 모델에 비해 많은 메모리를 사용하며 훈련과 예측이 느림            매개변수      설명                  n_estimators      - 결정트리의 갯수를 지정- Default = 10 (0.22버전부터 100)- 무작정 트리 갯수를 늘리면 성능 좋아지는 것 대비 시간이 걸릴 수 있음              min_samples_split      - 노드를 분할하기 위한 최소한의 샘플 데이터수 → 과적합을 제어하는데 사용- Default = 2 → 작게 설정할 수록 분할 노드가 많아져 과적합 가능성 증가              min_samples_leaf      - 리프노드가 되기 위해 필요한 최소한의 샘플 데이터수- min_samples_split과 함께 과적합 제어 용도- 불균형 데이터의 경우 특정 클래스의 데이터가 극도로 작을 수 있으므로 작게 설정 필요              max_features      - 최적의 분할을 위해 고려할 최대 feature 개수- Default = ‘auto’ (결정트리에서는 default가 none이었음)- int형으로 지정 →피처 갯수 / float형으로 지정 →비중- sqrt 또는 auto : 전체 피처 중 √(피처개수) 만큼 선정 (RandomForestClassifier-sqrt(n_feature), RandomForestRegressor-n_feature)- log : 전체 피처 중 log2(전체 피처 개수) 만큼 선정              max_depth      - 트리의 최대 깊이- default = None→ 완벽하게 클래스 값이 결정될 때 까지 분할 또는 데이터 개수가 min_samples_split보다 작아질 때까지 분할- 깊이가 깊어지면 과적합될 수 있으므로 적절히 제어 필요              max_leaf_nodes      리프노드의 최대 개수      N_estimatiors는 클수록 좋고 max_features와 max_depth와 같은 사전 가지치기 옵션은 단일 트리와 같이 주어집니다.그레이디언트 부스팅 회귀 트리이름은 회귀이지만 회귀와 분류 모두 사용됩니다. (GradientBoostingClassifier, GradientBoostingRegressor)그레이디언트 부스팅은 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듭니다.따라서 기본적으로 무작위성이 없습니다.대신 강력한 사전 가지치기가 사용되고 깊지 않은 트리를 사용합니다.각 트리는 데이터의 일부에 대해서만 예측을 잘 수행하여 트리가 많이 추가될수록 성능이 향상됩니다.이때 손실 함수를 정의하고 경사 하강법을 사용해서 다음 값을 보정합니다.random_state=0 만 입력했을 때from sklearn.ensemble import GradientBoostingClassifier​X_train, X_test, y_train, y_test = train_test_split(    cancer.data, cancer.target, random_state=0)​gbrt = GradientBoostingClassifier(random_state=0)gbrt.fit(X_train, y_train)​print(\"훈련 세트 정확도: {:.3f}\".format(gbrt.score(X_train, y_train)))print(\"테스트 세트 정확도: {:.3f}\".format(gbrt.score(X_test, y_test)))훈련 세트 정확도: 1.000테스트 세트 정확도: 0.965random_state=0, max_depth=1 을 입력했을 때gbrt = GradientBoostingClassifier(random_state=0, max_depth=1)gbrt.fit(X_train, y_train)​print(\"훈련 세트 정확도: {:.3f}\".format(gbrt.score(X_train, y_train)))print(\"테스트 세트 정확도: {:.3f}\".format(gbrt.score(X_test, y_test)))훈련 세트 정확도: 0.991테스트 세트 정확도: 0.972random_state=0, learning_rate=0.01을 입력했을 때gbrt = GradientBoostingClassifier(random_state=0, learning_rate=0.01)gbrt.fit(X_train, y_train)print(\"훈련 세트 정확도: {:.3f}\".format(gbrt.score(X_train, y_train)))print(\"테스트 세트 정확도: {:.3f}\".format(gbrt.score(X_test, y_test)))훈련 세트 정확도: 0.988테스트 세트 정확도: 0.965훈련 세트의 정확도가 100%로 과대적합이 된 모델은 max_depth나 learning_rate로 보완할 수 있습니다.Random_state는 고정시켜야 같은 모델이 나오는 것을 볼 수 있습니다.Learning_rate는 오차에 곱을 해서 예측값을 업데이트 해주는 값입니다.랜덤 포레스트에 비해 그레이디언트 부스팅은 특성들이 더 적습니다.안정성에서는 랜덤 포레스트가 더 좋지만 그레이디언트가 성능적으로 더 좋은 모습을 보여줄수 있습니다.참고XGBoost  XGBoost는 데이터 별 오류를 다음 round 학습에 반영 시킨다는 측면에서 기존 Gradient Boosting과 큰 차이는 없음Gradient Boosting과 달리 학습을 위한 목적식(loss function)에 Regularization term이 축가되어 모델이 과적합 되는 것을 방지해줌Regularization term을 통해 XGBoost는 복잡한 모델에 패널티를 부여함LighGBM  XGBoost와 다르게 lear-wise loss 사용 (loss를 더 줄일 수 있음)XGBoost 대비 2배 이상 빠른 속도 (동일 파라미터 기준)과대적합에 민감하여, 대량의 학습데이터를 필요로 함장단점과 매개변수장점  이진 특성이나 연속적인 특성에도 잘 작동합니다. 데이터의 스케일에 구애받지 않습니다.단점  매개변수의 조정이 필수입니다.휸련시간이 깁니다.  차원이 높고 희소한 데이터에 잘 작동하지 않습니다.N_estimators가 클수록 랜덤 포레스트는 좋았지만 그래이디언트 부스팅에서는 과대적합될 가능성이 높아집니다.N_estimator을 정하고 난 뒤에 learning_rate를 정하게 되는데 learning_rate를 낮추면 비슷한 복잡도의 모델을 만들기 위해 더 많은 트리를 추가해야합니다.            매개변수      설명                  n_estimators      - 트리의 개수를 지정- 커지면 모델이 복잡해지고 과대적합 가능성 높아짐              learning_rate      - 관례상 n_estimators를 맞추고 learning_rate를 찾음 - 이전 트리의 오차를 보정하는 정도              n_iter_no_change / validation_fraction      -조기 종료를 위한 매개변수 (default값: n_iter_no_change =None (조기 종료 x), validation_fraction=0.1) - validation_fraction 비율만큼 검증 데이터로 사용하여 n_iter_no_change 만큼 반복하여 향상되지 않으면 훈련 종료              max_depth / max_leaf_nodes      -각 트리의 복잡도를 낮춤 - max_depth는 보통 매우 작게 설정하며 트리의 깊이가 5보다 깊어지지 않게 함      배깅, 엑스트라 트리, 에이다부스트Baggingfrom sklearn.ensemble import BaggingClassifier배깅은 중복을 허용한 랜덤샘플링으로 만든 훈련 세트를 사용해 분류기를 각기 다르게 학습합니다.랜덤포레스트는 배깅의 일종이지만 설명변수도 무작위로 선택하는 것이 차이가 있습니다.predict_proba() 지원하면 메서드를 통해 확률값을 평균하여 예측을 수행합니다. (지원하지 않는다면 가장 빈도가 높은 클래스 레이블)oob_score=True로 지정하면 매개변수는 부트스트래핑에 포함되지 않은 샘플로 훈련된 모델을 평가할 수 있습니다. (OOB 오차, default=False)from sklearn.linear_model import LogisticRegressionfrom sklearn.ensemble import BaggingClassifierbagging = BaggingClassifier(LogisticRegression(), n_estimators=100, oob_score=True, n_jobs=-1, random_state=42)bagging.fit(Xc_train, yc_train)print(\"훈련 세트 정확도: {:.3f}\".format(bagging.score(Xc_train, yc_train)))print(\"테스트 세트 정확도: {:.3f}\".format(bagging.score(Xc_test, yc_test)))print(\"OOB 샘플의 정확도: {:.3f}\".format(bagging.oob_score_))훈련 세트 정확도: 0.953테스트 세트 정확도: 0.951OOB 샘플의 정확도: 0.946배깅은 랜덤포레스트와 달리 max_samples에 부트스트랩 샘플의 크기를 정할 수 있습니다. 또한 로지스틱 회귀가 들어갈 수도 있고 결정 트리가 들어갈 수도 있습니다.Extra Tree후보 특성을 무작위로 분할한 다음 최적의 분할을 찾습니다.엑스트라 트리도 랜덤 포레스트와 비슷하지만 splitter=‘random’을 사용합니다. 랜덤 포레스트는 splitter=‘best’가 고정입니다.Splitter=‘best’의 의미는 모든 변수의 정보 이득을 계산하고 그중 가장 설명력이 높은 변수를 선택하는 것입니다.또한 부트스트랩 샘플링을 적용하지 않습니다. 무작위성을 증가시키면 모델 편향은 늘어나지만 분산이 감소하는 모습을 보입니다.개별 트리는 매우 복잡하지만 결정 경계는 안정적입니다.계산 비용은 위 splitter에서의 feature의 차이 때문에 랜덤 포레스트보다 적지만  일반화 성능을 높이려면 많은 트리를 만들어야합니다.from sklearn.ensemble import ExtraTreesClassifierxtree = ExtraTreesClassifier(n_estimators=100, n_jobs=-1, random_state=0)xtree.fit(Xc_train, yc_train)print(\"훈련 세트 정확도: {:.3f}\".format(xtree.score(Xc_train, yc_train)))print(\"테스트 세트 정확도: {:.3f}\".format(xtree.score(Xc_test, yc_test))훈련 세트 정확도: 1.000테스트 세트 정확도: 0.972Adaptive Boosting이전의 모델이 잘못 분류한 샘플에 가중치를 높여서 다음 모델을 훈련합니다.훈련된 각 모델은 성능에 따라 가중치 부여합니다.예측을 만들 때는 모델이 예측한 레이블을 기준으로 모델의 가중치를 합산하여 가장 높은 값을 가진 레이블을 선택합니다.AdaBoostClassifier은 기본값으로 DecisionTreeClassifier(max_depth=1)를 갖습니다.AdaBoostRegressor은 기본값으로 DecisionTreeRegressor(max_depth=3)을 갖습니다. (base_estimator을 이용하여 다른 모델 지정 가능)에이다 부스팅의 원리와 수식예측정확도와 가중치의 곱의 합이 되어 높은 정확도를 만들게 됩니다.from sklearn.ensemble import AdaBoostClassifierada = AdaBoostClassifier(n_estimators=100, random_state=42)ada.fit(Xc_train, yc_train)print(\"훈련 세트 정확도: {:.3f}\".format(ada.score(Xc_train, yc_train)))print(\"테스트 세트 정확도: {:.3f}\".format(ada.score(Xc_test, yc_test)))훈련 세트 정확도: 1.000테스트 세트 정확도: 0.986커널 서포트 벡터 머신커널 서포트 벡터 머신은 보통 SVM이라고 한다.입력 데이터에서 단순한 초평면으로 정의되지 않는 더 복잡한 모델을 만들 수 있도록 확장한 것이다.분류와 회귀 모두 사용 가능하다. (SVC는 분류, SVR은 회귀)from sklearn.svm import LinearSVC #선형 모델LinearSVC(max_iter=)from sklearn.svm import SVCSVC(kernel='',C=,gamma=) # kernel, C, gamma 파라미터 존재선형 모델과 비선형 특성선형 모델은 직선으로만 데이터 포인트를 나눌 수 있어 밑에 같은 데이터는 잘 들어맞지 않는다.SVM 모델은 3차원에서 2차원으로 투영해본다면 더이상 선형 모델이 아니다.커널 기법커널 기법은 실제로 데이터를 확장하지 않고 확장된 특성에 대한 데이터 포인트들의 거리를 계산한다.$ (특성1)^2 * (특성2)^5 $하는 다항식 커널이 있고 가우시안 커널로 불리우는 RBF 커널이 있다.가우시안 커널은 차원이 무한한 특성 공간에 매핑하는 것이다.모든 차수의 모든 다항식을 고려하지만 특성의 중요도는 고차항이 될수록 줄어든다.SVM 이해하기두 클래스 사이에 경계한 데이터 포인트들을 서포트 벡터라고 한다.새로운 데이터 포인트에 대해 예측하려면 각 서포트 벡터와의 거리를 측정한다.서포트 벡터의 중요도는 훈련 과정에서 학습하는데 dual_coef_ 속성에 저장된다.가우시안 커널 공식 사진가우시안 커널에 의해 계산되며 $ X_1, X_2 $는 데이터 포인트이며 $ ||X_1 - X_2|| $는 유클리디안 거리이고 $Γ$ 은 가우시안 커널의 폭을 제어하는 매개변수이다.SVM 매개변수 튜닝$Γ$는 가우시안 커널 폭의 역수에 해당하는데 하나의 훈련 샘플이 미치는 영향의 범위를 결정한다.(1~0 사이의 범위이다.)작은 값은 넓은 영역을 뜻하고, 큰 값은 영향이 미치는 범위가 제한적이다.즉 커널의 반경이 클수록 훈련 샘플의 영향 범위도 커진다.작은 $Γ$ 값은 모델의 복잡도를 낮출 수 있다.C 매개 변수는 규제 매개변수이다. dual_coef_값을 제한합니다.작은 C는 매우 제약이 큰 모델을 만들고 각 데이터 포인트의 영향력이 작다.C를 증가시키면 이 포인트들이 영향을 크게 줘서 결정 경계를 휘게 만든다.SVM을 위한 데이터 전처리커널 SVM에서는 데이터셋의 특성 자릿수가 완전히 다르면 영향을 크게 미친다.따라서 특성 값을 평균이 0이고 단위 분산이 되도록 하거나, 0과 1 사이로 맞추는 방법을 많이 사용한다.(StandardScaler와 MinMaxScalar)장단점과 매개변수SVM은 저차원과 고차원의 데이터에 모두 잘 작동하지만 샘플이 많으면 잘 맞지 않는다.또한 전처리와 매개변수 설정에 신경을 많이 써야하는데 그래서 랜덤 포레스트나 그레이디언트 부스팅과 같은 전처리가 거의 필요 없는 트리 기반 모델이 선호된다.SVM은 분석도 어려워서 예측이 어떻게 결정되었는지 설명하기가 난해하다.하지만 모든 특성이 비슷한 단위이고 스케일이 비슷하다면 시도해볼 만하다.중요한 매개변수는 C이고 어떤 커널을 사용할지와 각 커널에 따른 매개변수이다.RBF는 $Γ$ 매개변수를 갖지만 다른 커널 종류도 많다.신경망 (딥러닝)다층 퍼셉트론은(MLP)는 간단하게 분류와 회귀에서 쓰일 수 있다.신경망 모델MLP는 여러 단계를 거처 결정을 만들어내는 선형 모델의 일반화된 모습이다.선형 회귀 모델의 예측 공식 사진$\\hat Y $는 x[0]에서 x[p]까지의 입력특성과 학습된 계수의 가중치의 합이다.퍼셉트론 사진왼쪽 노드는 입력 특성을 나타내며 연결선은 학습된 계수를 표현하고 오른쪽 노드는 입력의 가중치 합, 즉 출력을 나타낸다.MLP는 가중치 합을 만드는 과정이 여러 번 반복되며 먼저 중간 단계를 구성하는 은닉 유닛을 계산하고 이를 이용하여 최종 결과를 산출하기 위해 다시 가중치 합을 계산한다.다중 퍼셉트론 사진각 은닉 유닛의 가중치 합을 계산한 후 결과에 비선형 함수인 렐루나 하이퍼볼릭 탄젠트, 시그모이드 함수를 적용합니다.회귀 분석 사진w는 입력 x와 은닉층 h 사이의 가중치이고, v는 은닉층 h와 출력 $\\hat Y$ 사이의 가중치입니다.w와 v는 훈련 데이터에서 학습하고 x는 입력 특성이며 $ \\hat Y $는 계산된 출력, h는 중간 계산값 입니다.신경망 튜닝더 복잡도가 낮은 모델을 만들고 싶다면 hidden_layer_size를 통해 은닉 유닛의 개수를 줄인다.은닉 유닛을 추가하거나, 은닉층을 추가하거나 활성화함수를 바꾸면 더 매끄러운 결정 경계를 얻을 수도 있다.선형 분류와 리지 회귀 처럼 L2 페널티를 사용해서 가중치를 0에 가깝게 감소시킬 수도 있다.(default는 매우 낮다)신경망에서는 학습을 시작하기 전에 가중치를 무작위로 설정하며 이 무작위한 초기화가 모델의 학습에 영향을 준다.따라서 같은 매개변수를 사용하더라도 초깃값이 다르면 모델이 많이 달라질 수 있다.신경망도 입력 특성이 평균은 0 분산이 1이 되도록 변형하는 것이 좋다.은닉 유닛에서 작은 가중치를 가진 특성은 모델에 덜 중요하다고 추론할 수 있다.from sklearn.neural_network import MLPClassifier # MLP분류MLPClassifier(solver='',activation='',random_state=,hidden_layer_sizes=[,],max_itter=,alpha=) #solver에 최적화 알고리즘,activation에 활성화 함수 ,hidden_layer_size로 은닉 유닛의 개수 설정(default=100),max_itter은 반복 횟수,alpha는 L2 페널티장단점과 매개변수머신러닝 알고리즘을 뛰어넘는 성능을 보일 수 있지만 학습이 오래걸리고 데이터 전처리를 주의해서 해야한다.모든 특성이 같은 의미를 가지면 SVM, 다른 종류의 특성이라면 트리 기반 메딜이 더 잘 작동할 수 있다.신경망의 복잡도 추정가장 중요한 매개변수는 은닉층의 개수와 각 은닉층의 유닛 수이다.복잡도에 관해 연관된 측정치는 학습된 가중치 또는 계수의 수이다.특성이 100개 은닉 유닛 100개인 이진 분류라면 입력층과 첫 번째 은닉층 사이에는 편향을 포함하여 $ 100 * 100 + 100 = 10100 $개의 가중치가 있습니다.은닉층과 출력층 사이에 $ 100 * 1 + 1 = 101 $개의 가중치가 더 있어 가중치는 10201개 이다.이렇게 가중치는 은닉층을 추가할수록 훨씬 커지게 된다.매개변수를 조정하는 일반적인 방법은 충분히 과대적합되어 문제를 해결할만한 큰 모델을 만든 뒤 훈련 데이터가 충분히 학습될 수 있다고 생각되면 신경망 구조를 줄이거나 규제 강화를 위해 alpha 값을 증가시켜 일반화 성능을 향상시킨다.층의 개수, 층당 유닛 개수, 규제, 비선형성으로 모델 구성을 할 수 있으며, solver 매개변수를 통해서 학습시키는 방법을 지정할 수 있다.solver의 경우 기본값은 adam이고 데이터 스케일에 민감하다.lbfgs는 안정적이지만 규모가 크면 시간이 오래 걸린다sgd는 momentum과 nesterovs_momentom의 영향을 받는데 다른 여러 매개변수와 함께 튜닝하여 최선의 결과를 만들 수 있다.분류 예측의 불확실성 추정decision_function과 predict_proba로 추정 할 수 있다.결정 함수decision_function의 반환값의 크기는 (n_samples,)이며각 샘플이 하나의 실수 값을 반환한다.모델이 데이터 포인트가 양성 클래스인 클래스 1에 속한다고 믿는 정도이다.즉, 음수값은 다른 클래스에 속함을 의미한다.값의 범위는 데이터와 모델 파라미터에 따라 달라지게 된다.예측 확률predict_proba의 출력은 각 클래스에 대한 확률이고 이진 분류에서 이 값의 크기는 항상 (n_samples,2)이다.두 클래스의 확률 합은 1이므로 두 클래스 중 하나는 50% 이상의 확신을 가질 것이고 그 클래스가 예측값이 된다.데이터에 있는 불확실성이 얼마나 이 값에 잘 반영되는지는 모델과 매개변수 설정에 달렸다.그래서 과대적합된 모델 혹은 잘못된 예측도 예측의 확신이 강한 편이다.복잡도가 낮을 수록 예측에 불확실성이 더 많다.불확실성과 모델의 정확도가 동등하면 이 모델이 보정되었다고 한다.다중 분류에서의 불확실성다중 분류에서도 decision_funcion과 predict_proba를 사용할 수 있다.decision_function에서는 (n_samples, n_classes)가 결과값이 된다.글 클래스에 대한 확신 점수를 담고 그 수치가 크면 그 클래스일 가능성이 크다.데이터 포인트마다 점수들에서 가장 큰 값을 찾아 예측 결과를 재현할 수 있다.predict_proba는 (n_samples,n_classes)가 출력값이 된다.마찬가지로 각 데이터 포인트에서 클래스 확률의 합은 1이다.argmax 함수를 적용해서 예측 결과를 재현할 수 있지만 클래스가 문자열이거나 정수형을 사용하지만 연속적이지 않고 0부터 시작하지 않을 수 있다.따라서 predict 결과와 decision_function, predict_proba의 결과를 비교하기 위해서는 분류기의 classes_ 속성을 사용해 클래스의 실제 이름을 얻어야 한다.",
        "url": "/study-ML2"
    }
    ,
    
    "programming-baekjoon4": {
        "title": "백준 (4) &lt;br&gt; (1157, 1546, 2577, 2675, 2908, &lt;br&gt; 1018, 1436, 1259, 7568, 10250)",
            "author": "keonju",
            "category": "",
            "content": "백준 관련 글    백준 (1) (2557, 8958, 1000, 1001, 1008, 2935, 2753, 2884, 5063, 4101)    백준 (2) (1018, 1085, 1181, 1259, 1436, 1654, 1874, 1920)    백준 (3) 문자열 알고리즘(11720, 8958, 1152, 10809, 1157, 9012, 11718)    백준 (4) (1157, 1546, 2577, 2675, 2908, 1018, 1436, 1259, 7568, 10250)    백준 (5) 정렬 알고리즘(2750,11399,2751,1427, 10989,1181,11650)    백준 (6) (3085, 2563, 4673, 5635, 11170)    백준 (7) 스택 알고리즘(10828,10773,1874,10799, 4949,1406,2493)백준 10문제를 풀어보았다.중복되는 문제도 있습니다1157번 단어공부https://www.acmicpc.net/problem/1157upper을 이용한 대문자 받기count로 dictionary형태로 word 개수 세기개수가 중복되는 단어들이 있으므로 max_list에서 따로 추출하기조건에 맞게 최댓값이 하나면 알파벳을, 아니면 물음표를 출력하기word=input().upper()count={}for i in word:    if i not in count:        count[i]=0    count[i]+=1max_list=[j for j,k in count.items() if max(count.values())==k]if len(max_list)==1:    print(max_list[0])else:    print('?')Mississipi?1546번 평균https://www.acmicpc.net/problem/1546map 함수를 통해서 점수 입력받기new_mean()이라는 함수는 문제에서 나온 $점수/최대점수*100$ 이다.map함수를 통해 new_mean함수를 score에 모두 적용해주고 sum을 통해 총합을 구한 뒤,count로 나눠주면 된다.count=int(input())score=list(map(int,input().split())) # 점수 입력받기340 80 60max_score=max(score) # 점수 최댓값 찾기def new_mean(x): #최댓값과의 비율로 새로운 점수 만드는 함수    return x/max_score*100print(sum(map(new_mean,score))/count) #평균을 구하는 식75.02577번 숫자의 개수https://www.acmicpc.net/problem/2577입력받는 숫자가 3개로 한정되어있으니까 for문을 통해서 세 숫자의 곱을 구했다.count함수의 인덱스 0-9까지를 0-9숫자가 나왔을 때 하나씩 늘려주는 방법을 택했다.mul=1for i in range(3): # 세 숫자의 곱 구하기    a=int(input())    mul=mul*aprint(mul)15026642717037300count=[0]*10 #0-9의 개수가 들어갈 listfor j in str(mul): #str(mul)로 해줘야 for문이 성립된다.    for k in range(10): #0-9까지의 숫자를 확인하는 for문        if int(j)==k:            count[k]=count[k]+1 #숫자가 등장했을때 1 늘려주기for l in count:    print(l)31020002002675번 문자열 반복https://www.acmicpc.net/problem/2675각 글자마다 R번 반복해서 출력해주는 문제이다.case를 통해서 몇 번 반복할지를 결정해준다.word_list에 각 단어마다 R번씩 반복하여 append해준다.join으로 리스트에 있는 단어들을 문장으로 만들어준다.case=int(input()) # 시도할 횟수for i in range(case):     R,P=input().split() # R,P입력받기    word_list=[] #반복한 뒤 append해줄 list    for j in P: #P에 있는 글자 순서대로 반복해주기        for k in range(int(R)): #R을 str로 입력받아서 int로 변경해줘야함            word_list.append(j) #반복된 글자를 append    print(''.join(word_list)) #list안에 글자들 붙여서 출력해주기23 ABCAAABBBCCC5 /HTP/////HHHHHTTTTTPPPPP2908번 상수https://www.acmicpc.net/problem/2908list(A)로 숫자들을 리스트화 해준다.[::-1]로 거꾸로 뒤집어준다. A로 다시 저장하기 싫으면 reverse() 함수를 사용하면 된다.join을 통해 숫자로 바꿔주고 int 형태로 바꿔준 뒤, max를 통해 최댓값을 찾는다.A,B=input().split() # A,B 숫자 거꾸로 만들기A=list(A)[::-1] B=list(B)[::-1]# A,B 다시 숫자로 만든 뒤 대소비교A=int(''.join(A))B=int(''.join(B))print(max(A,B))734 8934371018번 체스판 다시 칠하기https://www.acmicpc.net/problem/1018N,M 크기를  받고 보드 만들기nXm형태의 위치를 파악하기 쉽게 리스트 형태로 받았다.n, m=map(int,input().split())if 8&lt;=n&lt;=50 and 8&lt;=m&lt;=50:    board = [input() for i in range(n)]10 13BBBBBBBBWBWBWBBBBBBBBBWBWBBBBBBBBBWBWBWBBBBBBBBBWBWBBBBBBBBBWBWBWBBBBBBBBBWBWBBBBBBBBBWBWBWBBBBBBBBBWBWBWWWWWWWWWWBWBWWWWWWWWWWBWB위치가 짝수일 때와 홀수일 때로 나눠서  W, B가 아닐 때마다 점수를 추가해준 다음 가장 최소가 되는 값만 찾아내면 된다.따라서 n * m의 보드에서 가능한 경우의 수는 n-7 * m-7이다. ex)10 13을 입력받을 경우 18가지.8 * 8로 잘라주기 위해서 k와 l을 (i,i+8), (j,j+8)로 한정짓는다.k+l이 홀수일 경우와 짝수일 경우, W로 시작할 경우와 B로 시작할 경우를 나눠서 모든 경우의 수를 반복문으로 확인해준다.마지막으로 total_score에 들어있는 값들 중 최솟값을 구해준다.total_score=[]# 보드에서 경우의 수 나누어주기for i in range(n-7):    for j in range(m-7):        count_w=0 #w가 아닐때        count_b=0 #b가 아닐때        #8*8 크기로 잘라주기        for k in range(i,i+8):             for l in range (j,j+8):                #각 경우의 수마다 비교해서 점수 추가하기                if (k+l)%2==0:                    if board[k][l]!='W':                                                    count_w=count_w+1                    if board[k][l]!='B':                        count_b=count_b+1                else:                    if board[k][l]!='W':                        count_b=count_b+1                    if board[k][l]!='B':                                                    count_w=count_w+1        # 점수들 한 list에 모아주기        total_score.append(count_w)        total_score.append(count_b)print(min(total_score)) #최솟값 출력121436번 영화감독 숌https://www.acmicpc.net/problem/1436666이 적어도 3개이상 연속으로 들어가는 수를 만든다처음에 문제를 풀 때 중간에 666이 3개 이상 들어가는 경우를 제외해서 틀렸다.list666에 가장 작은 숫자인 666부터 ‘666’이 문자열로 들어가있는 숫자들을 확인해서 추가하였다.입력받은 숫자가 list666의 길이보다 크면 계속 추가해주었고 list666[num-1]을 통하여 값을 출력해준다.num=int(input())list666=[]i=666while len(list666)&lt;num:    if '666' in str(i):        list666.append(i)    i=i+1print(list666[num-1]) 326661259번 팰린드롬수https://www.acmicpc.net/problem/1259앞에서 읽어도 뒤에서 읽어도 같은 숫자 찾기0을 입력하면 반복문이 끝나게 while과 if를 이용하였다.입력받은 숫자는 위치를 찾기 편하게 문자형으로 입력받았다.입력받은 숫자의 길이/2 만큼의 반복문을 돌리면 반대쪽은 (숫자의 길이-i-1)로 대응된다.한가지 숫자라도 값이 다르면 False 값을 가지고 ‘no’를 출력하면 ‘yes’를 출력하는 것을 만들 때보다 길이가 짧아질 수 있다.while True:    word=input() # 숫자를 무한으로 입력받기 위해 while문 사용    quest=True # 한가지 입력값을 처리하고나서 True, False값을 True로 초기화    if word=='0': # 0을 입력하면 반복문 종료        break    else:        word_len=len(word)        for i in range(int((word_len)/2)): #단어 길이의 반만 확인하면 반대쪽 숫자와 대응된다.                if word[i]!=word[word_len-1-i]: #반대쪽 숫자와 대응하기 위해서 word_len-1-i 사용                    quest=False # 하나의 경우라도 False가 나오면 반복문 종료                    continue        if quest==False: # False가 나오면 바로 'no' 출력            print('no')        else: print('yes')121yes1231no12421yes07568번 덩치https://www.acmicpc.net/problem/7568처음에 문제를 풀 때 너무 복잡하게 생각해서 무게 따로, 키 따로 점수 매기고 sort해서 index로 출력하려고 했는데 예제 문제는 옳게 나오지만 다른 경우에서 틀렸었다.또 and 말고 &amp; 로 써서 한 번 더 틀렸는데 이건 bitwise 연산자라서 답이 다르게 나왔다.# r값 입력 받고 (무게, 키) 형태로 리스트 만들기count=int(input())human=[]for i in range(count):    weight,tall=input().split()    human.append((int(weight),int(tall)))print(human)555 18558 18388 18660 17546 155[(55, 185), (58, 183), (88, 186), (60, 175), (46, 155)]for j in human:    rank=1 # 등수는 1등 부터니까 1    for k in human:        if j[0]&lt;k[0] and j[1]&lt;k[1]: # 둘 다 k가 우세할 경우에만 rank에 1 추가-&gt;순위 하락            rank+=1    print(rank,end=' ')2 2 1 2 5 for m in human:    rank=1    for n in human:        if m[0]&lt;n[0] &amp; m[1]&lt;n[1]: # &amp;는 비트 연산자기 때문에 결과가 다르게 나온다.            rank+=1    print(rank,end=' ')3 1 1 1 1 10250번 ACM호텔https://www.acmicpc.net/problem/102501호가 우선시 된다면 H명씩 순서대로 채운다고 생각하면 편하다.따라서 층수는 N/H의 나머지가 되고 호수는 N/H의 몫+1이 된다.하지만 N이 H의 배수일 때, 층수가 최고층이 되기때문에 H를 대신 입력해준다.또한 호수도 N/H의 몫과 같아지기 때문에 +1 한 것을 다시 -1 해준다.또한 호수가 10보다 작을 때 앞에 0을 적어줘야한다.for i in range(int(input())):    H,W,N=map(int,input().split())    floor=N%H #나머지가 층수가 된다.    order=(N//H)+1 #몫을 정수로 받은 뒤 +1해주면 호수가 된다.    if floor==0: #N이 H의 배수일 때만 따로 구분해서 값을 준다.        floor=H        order=order-1    if order&lt;10: # 호수 앞에 0을 붙여준다.        print(str(floor)+'0'+str(order))    else:        print(str(floor)+str(order))23 2 33014 1 8402 ```",
        "url": "/programming-baekjoon4"
    }
    ,
    
    "programming-baekjoon3": {
        "title": "백준 (3) 문자열 알고리즘 &lt;br&gt;(11720, 8958, 1152, 10809, &lt;br&gt; 1157, 9012, 11718)",
            "author": "keonju",
            "category": "",
            "content": "백준 관련 글    백준 (1) (2557, 8958, 1000, 1001, 1008, 2935, 2753, 2884, 5063, 4101)    백준 (2) (1018, 1085, 1181, 1259, 1436, 1654, 1874, 1920)    백준 (3) 문자열 알고리즘(11720, 8958, 1152, 10809, 1157, 9012, 11718)    백준 (4) (1157, 1546, 2577, 2675, 2908, 1018, 1436, 1259, 7568, 10250)    백준 (5) 정렬 알고리즘(2750,11399,2751,1427, 10989,1181,11650)    백준 (6) (3085, 2563, 4673, 5635, 11170)    백준 (7) 스택 알고리즘(10828,10773,1874,10799, 4949,1406,2493)문자열에 관련된 7문항을 풀어보았다.https://www.acmicpc.net/problemset?sort=ac_desc&amp;algo=15811720번 숫자의 합https://www.acmicpc.net/problem/11720공백없는 숫자들의 합구하기방법 1. for문을 이용해서 풀기n=int(input())m=input()554321range를 이용한 풀이 방법result=0for i in range(n):    result=int(m[i])+resultprint(result)15m을 읽어가면서 더해주는 방법result=0for i in m:    result=int(i)+resultprint(result)15방법 1. sum과 map을 이용해서 풀기print(sum(map(int,input())))54321158958 번 OX퀴즈https://www.acmicpc.net/problem/8958for문을 이용하여 입력받을 ox의 개수를 입력받고 for문 중첩을 이용하여 ox의 길이를 파악하고 if문으로 ox 여부를 확인하였다.ox의 연속성에 따른 점수변화를 num_score로 두고 total_score을 num_score의 합으로 설정하였다.num=int(input())for i in range(num):    ox=input()    total_score=0    num_score=0    for i in range(len(ox)):        if (ox[i]=='O') is True:            num_score=num_score+1        else:            num_score=0        total_score=total_score+num_score    print(total_score)5OOXXOXXOOO10OOXXOOXXOO9OXOXOXOXOXOXOX7OOOOOOOOOO55OOOOXOOOOXOOOOX301152번 단어의 개수https://www.acmicpc.net/problem/1152단어의 개수=공백의 위치마다 구분해줘서 입력받았다.sentence=list(map(str,input().split()))print(len(sentence))The Curious Case of Benjamin Button610809번 알파벳찾기https://www.acmicpc.net/problem/10809for문과 알파벳 list 선언s=list(map(str,input()))alpha=list('abcdefghijklmnopqrstuvwxyz')array=[-1 for i in range(len(alpha))]for i in range(len(s)):    if array[alpha.index(s[i])]==-1:        array[alpha.index(s[i])]=ifor j in array:    print(j,end=' ')baekjoon1 0 -1 -1 2 -1 -1 -1 -1 4 3 -1 -1 7 5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 아스키코드 이용알파벳의 아스키코드는 (97,123)이다.s=input()alpha=list(range(97,123))for i in alpha:    print(s.find(chr(i)),end=' ')baekjoon1 0 -1 -1 2 -1 -1 -1 -1 4 3 -1 -1 7 5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 1157번 단어 공부https://www.acmicpc.net/problem/1157upper을 이용한 대문자 받기count로 dictionary형태로 word 개수 세기개수가 중복되는 단어들이 있으므로 max_list에서 따로 추출하기조건에 맞게 최댓값이 하나면 알파벳을, 아니면 물음표를 출력하기word=input().upper()count={}for i in word:    if i not in count:        count[i]=0    count[i]+=1max_list=[j for j,k in count.items() if max(count.values())==k]if len(max_list)==1:    print(max_list[0])else:    print('?')Mississipi?9012번 괄호https://www.acmicpc.net/problem/9012 while문을 통해 ‘()’가 vps에 존재한다면 계속 replace를 통해 제거해주었다.만약 VPS 문장이었다면 문자열에 아무것도 남지않고 VPS 문장이 아니라면 어떤 문자라도 남았을 것이다.따라서 결과물의 길이로 YES와 NO를 구분지어줬다.num=int(input())for i in range(num):    vps=input()    while '()' in vps:        vps=vps.replace('()','')    if len(vps)==0:        print('YES')    else:        print('NO')6(())())NO(((()())()NO(()())((()))YES((()()(()))(((())))()NO()()()()(()()())()YES(()((())()(NO11718번 그대로 출력하기https://www.acmicpc.net/problem/11718while True로 반복문을 만들어주고 try~except문으로 오류가 발생했을때는 멈출수 있게 해준다.while True:    try:        print(input())    except:        breakOnline JudgeOnline Judge",
        "url": "/programming-baekjoon3"
    }
    ,
    
    "study-ml1": {
        "title": "머신러닝 정리 (1) &lt;br&gt; 지도학습 (1)",
            "author": "keonju",
            "category": "",
            "content": "머신러닝 공부 관련 글    머신러닝 정리 (1)-지도학습 (1)    머신러닝 정리 (2)-지도학습 (2)    머신러닝 정리 (3)-비지도학습 (1)    머신러닝 정리 (4)-비지도학습 (2)머신러닝 정리 (1) - 지도학습 (1)본 문서는 [파이썬 라이브러리를 활용한 머신러닝] 책을 공부하면서 요약한 내용입니다.또 데이터 청년 캠퍼스 수업과 학교 수업에서 배운 내용들도 함께 정리했습니다.글의 순서는 [파이썬 라이브러리를 활용한 머신러닝]에 따라 진행됩니다.코드는 밑에 링크에 공개되어있기 때문에 올리지않습니다.소스 코드: https://github.com/rickiepark/introduction_to_ml_with_python지도학습 (1)  분류와 회귀  일반화, 과대적합, 과소적합          모델복잡도와 데이터셋 크기의 관계        지도 학습 알고리즘          예제에 사용할 데이터셋      k-nn 모델      선형 모델      Naive Bayes 분류기      분류와 회귀분류란? 미리 정의된 가능성 있는 여러 클래스 레이블 중 하나를 예측하는 것이다.이진 분류: 예, 아니오로 구분할 수 있다. ex) 이 이메일은 스팸인가요?다중 분류: 셋 이상의 클래스로 분류된다. ex) 붓꽃 데이터회귀란? 부동소수점수(수학으로 말하면 실수)를 예측하는 것이다.어떤 사람의 여러 조건들을 통해 연간 소득을 예측하는 것과 같은 문제이다.출력 값에 연속성이 있다면 회귀 문제 없다면 분류 문제이다.일반화, 과대적합, 과소적합모델이 처음 보는 데이터에 대해 정확히 예측할 수 있다면 훈련 세트(train_set)에서 테스트 세트(test_set)으로 일반화되었다고 한다.훈련 세트에 대해서 정확히 예측하고 테스트 세트에서도 정확히 예측하길 바란다.하지만 모델이 복잡하다면 훈련 세트에서만 정확한 모델이 될 수 있다.예를 들어 “내 주변 20대가 모두 아이폰을 쓰기 때문에 다른 20대도 모두 아이폰을 살 것이다.”라는 예측을 한다면 훈련 세트가 내 주변 20대가 될 것이고 테스트 세트가 다른 모든 20대가 될 것이다.이처럼 알고리즘이 새로운 데이터를 잘 처리하는지 측정하는 방법은 테스트 세트로 평가를 해야한다.이 때, 너무 복잡한 모델을 만들어 훈련 세트에 집중되어 테스트 세트에 일반화가 부족하다면 과대적합(overfitting)이라 한다.반대로 너무 간단한 모델이라 훈련 세트에도 잘 맞지 않다면 과소적합(underfitting)이라 한다.모델복잡도와 데이터셋 크기의 관계모델의 복잡도는 훈련 데이터 셋에 담긴 입력 데이터의 다양성과 관련이 있다.데이터셋에 데이터 포인트가 다양하면 과대적합 없이 복잡한 모델을 만들 수 있다.따라서 중복이거나 비슷한 데이터를 모으는 것은 도움이 되지않는다.위의 예를 생각해보면 내 주변 20대라는 특징말고 대학 동기, 친구라는 데이터를 얻더라도 모두 20대라는 범주안에 들어갈테니 불필요한 데이터라 할 수 있다.따라서 좋은 데이터를 많이 얻는 것이 좋다.지도 학습 알고리즘각 모델의 장단점과 어떤 데이터와 어울리는지, 매개변수와 옵션의 의미를 알아보도록 하자.scikit-learn 문서를 참고하면 더 자세한 정보를 얻을 수 있다.예제에 사용할 데이터셋forge 데이터셋은 인위적으로 만든 이진 분류 데이터셋이다.k-NN 모델k-NN 모델은 단순히 데이터셋을 분류하는 것이다.k개의 레이블 중에서 어느 쪽에 더 가까운 것인지 투표를 하여 결정한다고 생각하면 이해하기 편하다.k=1일 때는 가장 가까운 것이 빨간색이었다면, k=3일 때는 파란색 두 개와 빨간색 한 개가 가까울 수도 있다.그렇게 된다면 k=3일 때는 파란색으로 분류가 된다.KNeighborClassifier(n_neighbors)을 통해 분류 모델을 만들 수 있다.이를 통해 확인할 수 있는 것은 k의 값이 커질수록 보다 단순한 모델이 만들어질 수 있다는 것이다.하지만 반드시 k가 커진다고 좋은 모델은 아니다. 정확도가 낮아질 수 있기 때문이다.KNeighborsRegressor(n_neighbors)을 통해 회귀 모델 또한 만들 수 있다.회귀 모델에서도 k를 너무 적게 쓴다면 모든 데이터를 지나가고 불안정한 모델이 만들어진다.장단점과 매개변수가장 중요한 매개변수는 거리를 재는 방법과 k값이다.보통 거리를 재는 방법은 유클리디안 거리 방식을 사용한다.장점은 이해하기가 쉬운 모델이고 조정을 많이 하지않아도 좋은 성능을 발휘할 수 있다는 것이다.단점은 훈련 세트가 크면 예측이 느려지고 전처리 과정이 중요하다는 것이다.데이터가 특성이 많거나 대부분이 0인 데이터셋에서는 잘 작동하지 않는다.선형 모델선형 모델은 $y=w[0]*x[0]+b$와 같은 모델을 갖는 예측 함수이다.y는 예측값, w와 b는 모델이 학습할 파라미터, x는 데이터의 특성이다. 위 식은 특성이 하나인 데이터 셋의 선형 함수이다.선형 회귀(최소제곱법)선형 회귀는 예측과 훈련 세트에 있는 타깃 사이의 평균제곱오차(MSE)를 최소화하는 파라미터를 찾는 것이다.평균제곱오차는 예측값과 타깃값의 차이를 제곱하여 더한 후에 샘플의 개수로 나눈 것이다.매개변수가 없는 것이 장점이지만 복잡도를 제어할 방법도 없다.LinearRegression()리지 회귀리지 회귀도 예측 함수를 사용하지만 가중치의 절댓값을 가능한 작게 만드는 목적을 갖는다.이런 제약을 규제라고 하며 L2 규제라고 한다.리지는 덜 자유로운 모델이라 과대적합이 적다. 따라서 일반화에 도움이 된다.Ridge(alpha)라소리지의 대안으로 라소가 있다. L1 규제라고도 하며 완전히 제외하는 특성이 생긴다.일부 계수가 0이 되고 모델을 이해하기 쉬워지며 중요한 특성을 찾기 쉽ㄴ다.max_itter을 조절하여 과소적합을 줄인다.Lasso(alpha, max_itter())분류용 선형 모델이진 분류의 경우 선형 회귀와 비슷하지만 가중치 합을 그냥 사용하는 대신 예측값을 임계치 0과 비교한다.0보다 작으면 -1, 크면 1이라고 예측한다. 결정 경계를 선형 함수로 잡는다.LogisticRegression과 LinearSVC가 잘 알려져있는데 규제의 강도를 결정하는 매개변수 C를 주의해야한다.C가 높으면 훈련 세트에 최대로 맞추려 노력하고 낮추면 계수 벡터(w)가 0에 가까워지도록 만든다.로지스틱 회귀분석을 제외하면 다중 클래스를 대부분 지원하지 않는다.장단점과 매개변수회귀 모델에서는 alpha, LinearSVC와 LogisticRegression에서는 C가 중요하다.alpha가 클수록, C가 작을수록 모델이 단순해진다. 로그 스케일로 최적치를 정한다.L1, L2를 결정하는 것도 정해야한다. 중요한 특성이 적으면 L1, 그렇지 않으면 L2를 이용한다.선형 모델은 학습 속도와 예측 속도가 빠르다. solver=’sag’ 옵션을 이용하면 더 빨리 처리할 수 있다.아니면 SGDClassifier과 SGDRegressor을 이용할 수도 있다.또한 선형 모델은 예측이 어떻게 만들어지는지 비교적 이해하기 쉽다. 하지만 계수의 값이 명확하지가 않다.Naive Bayes 분류기나이브 베이즈 분류기는 선형 분류기보다 훈련 속도가 빠르지만 일반화 성능이 뒤쳐진다.개별적으로 파라미터를 학습하고 특성에서 클래스별 통계를 단순하게 취합한다.GaussianNB, BernoulliNB, MultinomialNB를 scikit-learn에서 구현되어있다.GaussianNB는 연속적인, BernoulliNB는 이진 데이터를, MultinomialNB는 카운트 데이터를 적용한다.BernoulliNB는 클래스의 특성중 0이 아닌 것이 몇 개인지 센다.MultinomialNB는 클래스별 특성의 평균을, GaussianNB는 클래스별로 각 특성의 표준편차와 평균을 저장한다.MultinomialNB와 GaussianNB는 선형 모델과 예측 공식이 갖지만 coef_는 기울기 w가 아니라 의미는 다르다.장단점과 매개변수MultinomialNB와 BernoulliNB는 모델 복잡도를 조절하는 alpha변수가 하나이다.alpha가 주어지면 알고리즘이 모든 특성에 양의 값을 가진 데이터 포인트를 alpha 개수만큼 추가한다.alpha가 크면 더 완만하고 덜 복잡한 모델이 나오지만 성능 변동은 비교적 크지 않다.GaussianNB는 고차원 데이터 셋을 사용한다. 다른 모델은 데이터를 카운트하는 데 사용된다.",
        "url": "/study-ML1"
    }
    ,
    
    "programming-kaggle1": {
        "title": "캐글 (1) &lt;br&gt; Simple Matplotlib &amp; Visualization Tips 공부하기",
            "author": "keonju",
            "category": "",
            "content": "kaggle 관련 글    캐글 (1) Simple Matplotlib &amp; Visualization Tips 공부하기    캐글 (2) 타이타닉 튜토리얼 1,2 공부하기Simple Matplotlib &amp; Visualization Tips 공부하기https://www.kaggle.com/subinium/simple-matplotlib-visualization-tips/notebook해당과정을 필사하였으며 영어로 되어있는 부분은 다시 정리해서 적었다.  Table of Contents          Settingdpifigsizetitle        Alignments          subplots, tight_layoutsubplot2gridadd_axesadd_gridspec        Colormap          divergingqualitativesequentialscientific        Text &amp; Annotate &amp; Patch          parametertext examplepatches example        Details &amp; Example          font weight, color, size, etcHorizontal and Vertical (barplot)Border(edge) color and thicknessMain Color &amp; Sub ColorTransparencySpan        MEME          xkcd style      import numpy as npimport matplotlib as mplimport matplotlib.pyplot as plt#matplotlib.pyplot 모듈의 각각의 함수를 사용해서 간편하게 그래프를 만들고 변화를 줄 수 있습니다.import matplotlib.gridspec as gridspec# gridspec 에는 Figure 내에서 격자 모양의 패턴으로여러 Axes 레이아웃하는 데 도움이되는 클래스가 포함되어 있습니다.import seaborn as sns# Seaborn은 Matplotlib에 기반하여 제작된 파이썬 데이터 시각화 모듈print(f\"Matplotlib Version :{mpl.__version__}\")print(f\"Seaborn Version :{sns.__version__}\")import pandas as pdnetflix_titles=pd.read_csv(\"netflix_titles.csv\")Matplotlib Version :3.3.2Seaborn Version :0.11.0Setting해상도 설정 matplotlib의 기본 해상도는 떨어지는 편이라고 한다.또한 그래프의 모양에 따라서 느낌이 달라지기 때문에 크기를 많이 변경해봐야한다.plt.title() 그래프의 제목 그리기ax.set_title() 개별 서브 플롯에 제목을 추가하는 데 사용 fig.suptitle() 모든 서브 플롯에 공통 인 메인 타이틀을 추가plt.rcParams['figure.dpi'] = 200 # or dpi=200Alignmentsmatplotlib 레이아웃과 설계의 조합이다.두 개의 그래프가 한 개의 그래프보다 시각적으로 의미적으로 모두 좋다.두 개를 비교하기 위해 가장 쉬운 방법은 직사각형으로 배치하는 것이다.subplot을 통하여 초기 크기로 시작할 수 있다.subplots() 하나의 그림에 여러 플롯을 그리기 subplot2grid() 일반 그리드 내부의 특정 위치에 서브플롯을 생성 add_axes() 축 추가하기 gridspec() Figure 내에 서브플롯을 배치 add_subplot() Figure 내에 서브플롯을 배치inset_axes() 하위에 축 추가하기make_axes_locatable() 축 배치하기fig, axes = plt.subplots(2, 3, figsize=(8, 5))plt.show()# tight_layout을 통해 그래프 사이에 여유공간이 생김fig,axes =plt.subplots(2, 3, figsize=(8, 5))plt.tight_layout()plt.show()# subplot이 항상 같을 필요가 없음. 이 때 subplot2grid를 사용fig=plt.figure(figsize=(8,5)) #시작 크기 지정ax=[None for _ in range(6)]ax[0]=plt.subplot2grid((3,4),(0,0),colspan=4)ax[1]=plt.subplot2grid((3,4),(1,0),colspan=1)ax[2]=plt.subplot2grid((3,4),(1,1),colspan=1)ax[3]=plt.subplot2grid((3,4),(1,2),colspan=1)ax[4]=plt.subplot2grid((3,4),(1,3),colspan=1,rowspan=2)ax[5]=plt.subplot2grid((3,4),(2,0),colspan=3)for ix in range(6):     ax[ix].set_title('ax[{}]'.format(ix)) # subplot에 제목 생성    #ticks는 축에 표시되는 숫자    ax[ix].set_xticks([])    ax[ix].set_yticks([])    fig.tight_layout()plt.show()fig = plt.figure(figsize=(8, 5))ax = [None for _ in range(4)]#add_axes를 이해하기 힘들어서 값들을 눈에 띄게 변경해보았다.[왼쪽, 아래쪽, 너비, 높이]ax[0]=fig.add_axes([0.1,0.2,0.3,0.4])ax[1]=fig.add_axes([0.3,0.4,0.5,0.6])ax[2]=fig.add_axes([0.5,0.6,0.7,0.8]) ax[3]=fig.add_axes([0.6,0.7,0.8,0.9])for ix in range(4):    ax[ix].set_title('ax[{}]'.format(ix))    ax[ix].set_xticks([])    ax[ix].set_yticks([])plt.show()# gridspec을 이용하여 만들기fig=plt.figure(figsize=(8, 5))gs=fig.add_gridspec(3, 3) #(3x3 크기)ax=[None for _ in range(5)]ax[0]=fig.add_subplot(gs[0, :]) ax[0].set_title('gs[0, :]')ax[1]=fig.add_subplot(gs[1, :-1])ax[1].set_title('gs[1, :-1]')ax[2]=fig.add_subplot(gs[1:, -1])ax[2].set_title('gs[1:, -1]')ax[3]=fig.add_subplot(gs[-1, 0])ax[3].set_title('gs[-1, 0]')ax[4]=fig.add_subplot(gs[-1, -2])ax[4].set_title('gs[-1, -2]')for ix in range(5):    ax[ix].set_xticks([])    ax[ix].set_yticks([])plt.tight_layout()plt.show()fig,ax=plt.subplots()axin1=ax.inset_axes([0.8, 0.1, 0.15, 0.15])plt.show()from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatablefig,ax=plt.subplots(1, 1)ax_divider=make_axes_locatable(ax)ax=ax_divider.append_axes(\"right\", size=\"7%\", pad=\"2%\")plt.show()Colormaphttps://medium.com/nightingale/how-to-choose-the-colors-for-your-data-visualizations-50b2557fa335그래프에서 색상은 중요한 요소이다diverging 중앙을 기준으로 색상 변경qualitative 범주별로 색상 변경sequential 순차적으로 색상 변경scientific 다양한 색상으로 순차적 변경def cmap_plot(cmap_list, ctype):    cmaps=cmap_list    n=len(cmaps)    fig=plt.figure(figsize=(8.25, n*.20), dpi=200)    ax=plt.subplot(1, 1, 1, frameon=False, xlim=[0,10], xticks=[], yticks=[])    fig.subplots_adjust(top=0.99, bottom=0.01, left=0.18, right=0.99)    y,dy,pad = 0, 0.3, 0.08    ticks,labels = [], []    for cmap in cmaps[::-1]:        Z=np.linspace(0,1,512).reshape(1,512)        plt.imshow(Z, extent=[0,10,y,y+dy], cmap=plt.get_cmap(cmap))        ticks.append(y+dy/2)        labels.append(cmap)        y = y + dy + pad    ax.set_ylim(-pad,y)    ax.set_yticks(ticks)    ax.set_yticklabels(labels)    ax.tick_params(axis='y', which='both', length=0, labelsize=5)    plt.title(f'{ctype} Colormap', fontweight='bold', fontsize=8)    plt.show()#diverging#양쪽 끝으로 갈수록 색이 어두워진다.diverge_cmap=('PRGn', 'PiYG', 'RdYlGn', 'BrBG', 'RdGy', 'PuOr', 'RdBu', 'RdYlBu',  'Spectral', 'coolwarm_r', 'bwr_r', 'seismic_r')cmap_plot(diverge_cmap, 'Diverging')#Qualitative Colormap#최대 10가지 색상을 구성하고 점점 더 작은 범주, 다른 범주와 그룹화#유사한 색상은 피하고 채도나 밝기보다 색을 분명하게 바꾸는 것이 좋다.qualitative_cmap=('tab10', 'tab20', 'tab20b', 'tab20c',         'Pastel1', 'Pastel2', 'Paired',         'Set1', 'Set2', 'Set3', 'Accent', 'Dark2' )cmap_plot(qualitative_cmap, 'Qualitative')#Sequential Colormap#밀도 표현에 효과적이고 지도 그래프에도 효과적이다.#밝기의 변화에 따라서 값을 비교할 수 있다.sequential_cmap=('Greys', 'Reds', 'Oranges',          'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',         'Purples', 'YlGnBu', 'Blues', 'PuBu', 'GnBu', 'PuBuGn', 'BuGn',         'Greens', 'YlGn','bone', 'gray', 'pink', 'afmhot', 'hot', 'gist_heat', 'copper',          'Wistia', 'autumn_r', 'summer_r', 'spring_r', 'cool', 'winter_r')            cmap_plot(sequential_cmap, 'Sequential')netflix_date = netflix_titles[['date_added']].dropna()netflix_date['year'] = netflix_date['date_added'].apply(lambda x : x.split(', ')[-1])netflix_date['month'] = netflix_date['date_added'].apply(lambda x : x.lstrip().split(' ')[0])month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'][::-1]df = netflix_date.groupby('year')['month'].value_counts().unstack().fillna(0)[month_order].T#응용하면 이런 그래프도 만들어진다.plt.figure(figsize=(10,7),dpi=200)plt.pcolor(df,cmap='gist_heat_r',edgecolors='white',linewidths=2)plt.xticks(np.arange(0.5,len(df.columns),1),df.columns,fontsize=7,fontfamily='serif')plt.yticks(np.arange(0.5,len(df.index),1),df.index,fontsize=7,fontfamily='serif')plt.title('Netflix Contents Update',fontsize=12,fontfamily='serif',fontweight='bold',position=(0.23,1.0+0.02))cbar=plt.colorbar()cbar.ax.tick_params(labelsize=8) cbar.ax.minorticks_on()plt.show()#Scientific Colormapscientific_cmap=('viridis','plasma','inferno','magma')cmap_plot(scientific_cmap,'Scientific')Text &amp; Annotate &amp; Patch그래프에 세부 사항을 넣을 수 있다.ax.text와 ax.annotate는 유사하지만 다르다.ax.text 그래프의 비율 좌표를 표현ax.annotate 그래프의 좌표를 표현va, ha 현재 좌표가 텍스트의 중심, 왼쪽, 오른쪽을 결정color 색상과 RGB값 선택 bbox 텍스트를 포장하는 상자 표현facecolor와 edgecolor가 분리되어있음pad로 html에서 처럼 padding 가능boxstyle로 직사각형의 모서리 조정 가능fig,ax=plt.subplots(figsize=(5, 5), dpi=100)# Gray Boxax.text(0.1, 0.9, 'Test', color='gray', va=\"center\", ha=\"center\")# Red Boxax.text(0.3, 0.7, 'Test', color='red', va=\"center\", ha=\"center\",        bbox=dict(facecolor='none', edgecolor='red'))# Blue Boxax.text(0.5, 0.5, 'Test', color='blue', va=\"center\", ha=\"center\",        bbox=dict(facecolor='none', edgecolor='blue', pad=10.0))# Green Boxax.text(0.7, 0.3, 'Test', color='green', va=\"center\", ha=\"center\",        bbox=dict(facecolor='none', edgecolor='green', boxstyle='round'))# Blackax.text(0.9, 0.1, 'Test', color='black', va=\"center\", ha=\"center\",        bbox=dict(facecolor='none', edgecolor='black', boxstyle='round, pad=0.5'))ax.set_xticks([])ax.set_yticks([])plt.show()효과적인 표현을 위한 그림들import matplotlib.path as mpathimport matplotlib.lines as mlinesimport matplotlib.patches as mpatchesfrom matplotlib.collections import PatchCollectiondef label(xy, text):    y = xy[1] - 0.15      plt.text(xy[0], y, text, ha=\"center\", family='sans-serif', size=14)fig, ax = plt.subplots()grid = np.mgrid[0.2:0.8:3j, 0.2:0.8:3j].reshape(2, -1).Tpatches = []# 원circle = mpatches.Circle(grid[0], 0.1, ec=\"none\")patches.append(circle)label(grid[0], \"Circle\")# 직사각형rect = mpatches.Rectangle(grid[1] - [0.025, 0.05], 0.05, 0.1, ec=\"none\")patches.append(rect)label(grid[1], \"Rectangle\")# wedgewedge = mpatches.Wedge(grid[2], 0.1, 30, 270, ec=\"none\")patches.append(wedge)label(grid[2], \"Wedge\")# Polygonpolygon = mpatches.RegularPolygon(grid[3], 5, 0.1)patches.append(polygon)label(grid[3], \"Polygon\")# ellipseellipse = mpatches.Ellipse(grid[4], 0.2, 0.1)patches.append(ellipse)label(grid[4], \"Ellipse\")# arrowarrow = mpatches.Arrow(grid[5, 0] - 0.05, grid[5, 1] - 0.05, 0.1, 0.1,                       width=0.1)patches.append(arrow)label(grid[5], \"Arrow\")# path patchPath = mpath.Pathpath_data = [    (Path.MOVETO, [0.018, -0.11]),    (Path.CURVE4, [-0.031, -0.051]),    (Path.CURVE4, [-0.115, 0.073]),    (Path.CURVE4, [-0.03, 0.073]),    (Path.LINETO, [-0.011, 0.039]),    (Path.CURVE4, [0.043, 0.121]),    (Path.CURVE4, [0.075, -0.005]),    (Path.CURVE4, [0.035, -0.027]),    (Path.CLOSEPOLY, [0.018, -0.11])]codes, verts = zip(*path_data)path = mpath.Path(verts + grid[6], codes)patch = mpatches.PathPatch(path)patches.append(patch)label(grid[6], \"PathPatch\")# fancy boxfancybox = mpatches.FancyBboxPatch(    grid[7] - [0.025, 0.05], 0.05, 0.1,    boxstyle=mpatches.BoxStyle(\"Round\", pad=0.02))patches.append(fancybox)label(grid[7], \"FancyBboxPatch\")# linex, y = np.array([[-0.06, 0.0, 0.1], [0.05, -0.05, 0.05]])line = mlines.Line2D(x + grid[8, 0], y + grid[8, 1], lw=5., alpha=0.3)label(grid[8], \"Line2D\")colors = np.linspace(0, 1, len(patches))collection = PatchCollection(patches, cmap=plt.cm.hsv, alpha=0.3)collection.set_array(np.array(colors))ax.add_collection(collection)ax.add_line(line)plt.axis('equal')plt.axis('off')plt.tight_layout()plt.show()Details &amp; Examples그림에 대한 다양한 설정Horizontal and Vertical (barplot)Border(edge) color and thicknessMain Color &amp; Sub ColorTransparencySpanFont Weight, Color, Family, Size …글꼴 굵기, 크기를 설정할 수 있다.serifs와 sans serifs도 차이가 있다.fontsize, color, fontweight, fontfamily같은 키워들을 이용할 수 있다.Horizontal keyboard &amp; Vertical (barplot)x축의 수가 많으면 가독성이 낮다. 예를들면 countplot은 x축과 겹치는 경우가 발생한다.이럴 때는 수직으로 배치하면 가독성이 좋다.Border(Edge) Color &amp; Thickness (Width)별도의 테두리를 이용하여 가독성을 높일 수 있다.R에서 자주 이용한다.경계선은 밝기와 투명도를 조절하여 구별하는 것이 좋다.Main Color &amp; Sub Color화려한 색상보다 정보의 전달을 편하게 하는 것에 목적을 둔다. 그래프의 종류에 따라 색상도 변경하는 것이 좋다.특정 부품을 강조 표시할 때 목록으로 전달하는 것이 좋다.from matplotlib.ticker import FuncFormatterdef age_band(num):    for i in range(1, 100):        if num &lt; 10*i :             return f'under {i*10}'titanic_train=pd.read_csv(\"train.csv\")titanic_train['age_band']=titanic_train['Age'].apply(age_band)titanic_age = titanic_train[['age_band', 'Survived']].groupby('age_band')['Survived'].value_counts().sort_index().unstack().fillna(0)titanic_age['Survival rate']=titanic_age[1] / (titanic_age[0] + titanic_age[1]) * 100fig, ax=plt.subplots(1, 2, figsize=(18, 7), dpi=300)# ax1ax[0].bar(titanic_age['Survival rate'].index, titanic_age['Survival rate'], color='gray')ax[0].set_title('Age Band &amp; Survival Rate(Before)')# ax2color_map=['gray' for _ in range(9)]color_map[0] = color_map[8] = '#3caea3'ax[1].bar(titanic_age['Survival rate'].index, titanic_age['Survival rate'], alpha=0.7, color=color_map, width=0.6, edgecolor='black', linewidth=1.2)ax[1].set_title('Age Band &amp; Survival Rate(After)', fontsize=15, fontweight='bold', position=(0.25, 1.0+0.05))for i in titanic_age['Survival rate'].index:    ax[1].annotate(f\"{titanic_age['Survival rate'][i]:.02f}%\",                    xy=(i, titanic_age['Survival rate'][i] + 2),                   va = 'center', ha='center',fontweight='bold', color='#383838')ax[1].yaxis.set_major_formatter(FuncFormatter(lambda y, _: f'{y:}%')) plt.suptitle('* Focus on survival rates for young and old', x=0.65, y=0.94, color='gray')plt.subplots_adjust(left=0.5, right=0.8)plt.tight_layout()plt.show()Main Color &amp; Sub Color산점도와 같이 많은 점들이 겹치면 투명도가 중요하다. 투명도를 이용해서 둘 이상의 그림을 함께 배치할 수 있다.import seaborn as snsexam_data=pd.read_csv(\"StudentsPerformance.csv\")fig, ax=plt.subplots(1, 2, figsize = (15, 7), dpi=150)ax[0].scatter(x='math score', y='reading score',data=exam_data, color='gray')ax[0].set_title('Before')ax[1].scatter(x='math score', y='reading score',data=exam_data[exam_data['gender']=='male'], color='skyblue', alpha=0.5, label='Male', s=70)ax[1].scatter(x='math score', y='reading score',data=exam_data[exam_data['gender']=='female'], color='salmon', alpha=0.5, label='Female', s=70)ax[1].set_title('After', fontsize=15, fontweight='bold')ax[1].legend()plt.gca().spines['top'].set_visible(False)plt.gca().spines['right'].set_visible(False)plt.show()Spanaxvspan: 수직axhspan: 수평sns.set_style('whitegrid') # plot with gridmovie=netflix_titles[netflix_titles['type'] == 'Movie']    rating_order=['G', 'TV-Y', 'TV-G', 'PG', 'TV-Y7', 'TV-Y7-FV', 'TV-PG', 'PG-13', 'TV-14', 'R', 'NC-17', 'TV-MA']movie_rating=movie['rating'].value_counts()[rating_order] fig, ax=plt.subplots(1, 1, figsize=(14, 7), dpi=200)ax.bar(movie_rating.index, movie_rating,  color=\"#d0d0d0\", width=0.6, edgecolor='black')ax.set_title(f'Distribution of Movie Rating (Before)', fontweight='bold')plt.show()def rating_barplot(data, title, height, h_lim=None):    fig, ax=plt.subplots(1,1, figsize=(14, 7), dpi=200)    if h_lim:        ax.set_ylim(0, h_lim)    ax.bar(data.index, data,  color=\"#e0e0e0\", width=0.52, edgecolor='black')    color=['green',  'blue',  'orange',  'red']    span_range=[[0, 2], [3,  6], [7, 8], [9, 11]]    for idx, sub_title in enumerate(['Little Kids', 'Older Kids', 'Teens', 'Mature']):        ax.annotate(sub_title,xy=(sum(span_range[idx])/2 ,height),xytext=(0,0), textcoords='offset points',                    va=\"center\", ha=\"center\",color=\"w\", fontsize=16, fontweight='bold',                    bbox=dict(boxstyle='round4', pad=0.4, color=color[idx], alpha=0.6))        ax.axvspan(span_range[idx][0]-0.4,span_range[idx][1]+0.4,  color=color[idx], alpha=0.07)    ax.set_title(f'Distribution of {title} Rating (After)', fontsize=15, fontweight='bold', position=(0.20, 1.0+0.03))    plt.show()rating_barplot(movie_rating,'Movie', 1200, 1400)MEME : xkcd themeimport matplotlibmatplotlib.font_manager._rebuild()with plt.xkcd():    fig=plt.figure()    ax=fig.add_axes((0.1, 0.2, 0.8, 0.7))    ax.spines['right'].set_color('none')    ax.spines['top'].set_color('none')    ax.set_xticks([])    ax.set_yticks([])    ax.set_ylim([-30, 10])    data=np.ones(100)    data[70:]-=np.arange(30)    ax.annotate('THE DAY I REALIZED\\nI COULD COOK BACON\\nWHENEVER I WANTED',        xy=(70, 1), arrowprops=dict(arrowstyle='-&gt;'), xytext=(15, -10))    ax.plot(data)    ax.set_xlabel('time')    ax.set_ylabel('my overall health')    fig.text(0.5, 0.05,'\"Stove Ownership\" from xkcd by Randall Munroe',ha='center')with plt.xkcd():    fig=plt.figure()    ax=fig.add_axes((0.1, 0.2, 0.8, 0.7))    ax.bar([0, 1], [0, 100], 0.25)    ax.spines['right'].set_color('none')    ax.spines['top'].set_color('none')    ax.xaxis.set_ticks_position('bottom')    ax.set_xticks([0, 1])    ax.set_xticklabels(['CONFIRMED BY\\nEXPERIMENT', 'REFUTED BY\\nEXPERIMENT'])    ax.set_xlim([-0.5, 1.5])    ax.set_yticks([])    ax.set_ylim([0, 110])    ax.set_title(\"CLAIMS OF SUPERNATURAL POWERS\")    fig.text(0.5, -0.05,'\"The Data So Far\" from xkcd by Randall Munroe',ha='center')plt.show()",
        "url": "/programming-kaggle1"
    }
    ,
    
    "programming-baekjoon2": {
        "title": "백준 (2) &lt;br&gt; (1018, 1085, 1181, 1259, &lt;br&gt; 1436, 1654, 1874, 1920)",
            "author": "keonju",
            "category": "",
            "content": "백준 관련 글    백준 (1) (2557, 8958, 1000, 1001, 1008, 2935, 2753, 2884, 5063, 4101)    백준 (2) (1018, 1085, 1181, 1259, 1436, 1654, 1874, 1920)    백준 (3) 문자열 알고리즘(11720, 8958, 1152, 10809, 1157, 9012, 11718)    백준 (4) (1157, 1546, 2577, 2675, 2908, 1018, 1436, 1259, 7568, 10250)    백준 (5) 정렬 알고리즘(2750,11399,2751,1427, 10989,1181,11650)    백준 (6) (3085, 2563, 4673, 5635, 11170)    백준 (7) 스택 알고리즘(10828,10773,1874,10799, 4949,1406,2493)solved.ac의 class 2단계 8문항을 풀어보았다.파이썬 알고리즘 과제는 알고리즘 공부를 많이 하지 않은 나로써는 조금 어려웠다.https://solved.ac/search?query=in_class:21018번 체스판 다시 칠하기https://www.acmicpc.net/problem/1018N,M 크기를  받고 보드 만들기nXm형태의 위치를 파악하기 쉽게 리스트 형태로 받았다.n, m=map(int,input().split())if 8&lt;=n&lt;=50 and 8&lt;=m&lt;=50:    board = [input() for i in range(n)]10 13BBBBBBBBWBWBWBBBBBBBBBWBWBBBBBBBBBWBWBWBBBBBBBBBWBWBBBBBBBBBWBWBWBBBBBBBBBWBWBBBBBBBBBWBWBWBBBBBBBBBWBWBWWWWWWWWWWBWBWWWWWWWWWWBWB위치가 짝수일 때와 홀수일 때로 나눠서  W, B가 아닐 때마다 점수를 추가해준 다음 가장 최소가 되는 값만 찾아내면 된다.따라서 n * m의 보드에서 가능한 경우의 수는 n-7 * m-7이다. ex)10 13을 입력받을 경우 18가지.8 * 8로 잘라주기 위해서 k와 l을 (i,i+8), (j,j+8)로 한정짓는다.k+l이 홀수일 경우와 짝수일 경우, W로 시작할 경우와 B로 시작할 경우를 나눠서 모든 경우의 수를 반복문으로 확인해준다.마지막으로 total_score에 들어있는 값들 중 최솟값을 구해준다.total_score=[]# 보드에서 경우의 수 나누어주기for i in range(n-7):    for j in range(m-7):        count_w=0 #w가 아닐때        count_b=0 #b가 아닐때        #8*8 크기로 잘라주기        for k in range(i,i+8):             for l in range (j,j+8):                #각 경우의 수마다 비교해서 점수 추가하기                if (k+l)%2==0:                    if board[k][l]!='W':                                                    count_w=count_w+1                    if board[k][l]!='B':                        count_b=count_b+1                else:                    if board[k][l]!='W':                        count_b=count_b+1                    if board[k][l]!='B':                                                    count_w=count_w+1        # 점수들 한 list에 모아주기        total_score.append(count_w)        total_score.append(count_b)print(min(total_score)) #최솟값 출력121085번 직사각형에서 탈출https://www.acmicpc.net/problem/1085x,y,w,h 입력받기x,y,w,h =map(int,input().split())6 2 10 30과 가까운 경계선은 x, y로 w,h와 가까운 경계선은 w-x, h-y로 표현해주는 대신 음수가 나올수 있기때문에 abs()를 이용하여 절댓값으로 표현.print(min(x,y,abs(w-x),abs(h-y)))11181번 단어 정렬https://www.acmicpc.net/problem/1181단어 리스트 입력받기n=int(input())word_list=[input() for i in range(n)]13butiwonthesitatenomorenomoreitcannotwaitimyours길이가 짧은 것부터 같으면 사전 순으로 정렬하기 (단, 중복 제외)set함수로 중복을 먼저 제거하였다.단어의 길이를 먼저, 그다음에 단어를 하나의 tuple로 만들어 리스트를 다시 만들어주었다.sort를 이용하면 앞에 숫자가 들어갔기 떄문에 길이, 알파벳 순으로 정렬된다.# 중복 단어 제거word_list=list(set(word_list))len_word_list=[]# (단어 길이, 단어) 형태의 tuple 만들기for i in word_list:    len_word_list.append((len(i),i))# 정렬하기len_word_list.sort()print(len_word_list)# 출력하기for j,k in len_word_list:    print(k)[(1, 'i'), (2, 'im'), (2, 'it'), (2, 'no'), (3, 'but'), (4, 'more'), (4, 'wait'), (4, 'wont'), (5, 'yours'), (6, 'cannot'), (8, 'hesitate')]iimitnobutmorewaitwontyourscannothesitate1259번 팰린드롬수https://www.acmicpc.net/problem/1259앞에서 읽어도 뒤에서 읽어도 같은 숫자 찾기0을 입력하면 반복문이 끝나게 while과 if를 이용하였다.입력받은 숫자는 위치를 찾기 편하게 문자형으로 입력받았다.입력받은 숫자의 길이/2 만큼의 반복문을 돌리면 반대쪽은 (숫자의 길이-i-1)로 대응된다.한가지 숫자라도 값이 다르면 False 값을 가지고 ‘no’를 출력하면 ‘yes’를 출력하는 것을 만들 때보다 길이가 짧아질 수 있다.while True:    word=input() # 숫자를 무한으로 입력받기 위해 while문 사용    quest=True # 한가지 입력값을 처리하고나서 True, False값을 True로 초기화    if word=='0': # 0을 입력하면 반복문 종료        break    else:        word_len=len(word)        for i in range(int((word_len)/2)): #단어 길이의 반만 확인하면 반대쪽 숫자와 대응된다.                if word[i]!=word[word_len-1-i]: #반대쪽 숫자와 대응하기 위해서 word_len-1-i 사용                    quest=False # 하나의 경우라도 False가 나오면 반복문 종료                    continue        if quest==False: # False가 나오면 바로 'no' 출력            print('no')        else: print('yes')121yes1231no12421yes01436번 영화감독 숌https://www.acmicpc.net/problem/1436666이 적어도 3개이상 연속으로 들어가는 수를 만든다처음에 문제를 풀 때 중간에 666이 3개 이상 들어가는 경우를 제외해서 틀렸다.list666에 가장 작은 숫자인 666부터 ‘666’이 문자열로 들어가있는 숫자들을 확인해서 추가하였다.입력받은 숫자가 list666의 길이보다 크면 계속 추가해주었고 list666[num-1]을 통하여 값을 출력해준다.num=int(input())list666=[]i=666while len(list666)&lt;num:    if '666' in str(i):        list666.append(i)    i=i+1print(list666[num-1])326661654번 랜선 자르기https://www.acmicpc.net/problem/1654숫자 입력받기k,n=map(int,input().split())lan=[int(input()) for i in range(k)]4 11802743457539시간초과된 코드for문을 이용하니까 연산자가 너무 많아서 시간이 초과되었던 것 같다.div_list=[]for i in range(min(lan)):    div=int(min(lan))-i    count=[]    for w in lan:        count.append(w//div)    n_result=0    for j in range(k):        n_result=n_result+count[j]    if n_result==n:        div_list.append(div)print(max(div_list))200이진탐색을 이용하여보자.이진탐색이란 마치 병뚜껑 숫자맞추기를 할 때 50을 먼저 외치고 다음에 25나 75를 외치는 것처럼 가운데에 위치한 값들을 기반으로 탐색하는 것이다.정렬된 데이터일 때 사용 가능하다.따라서 입력받은 값들을 기준으로 max값과 1을 양 끝 값으로 놓는다.시작과 끝이 같을 때 까지 while문을 돌련준다.중간값을 구하고 이 값으로 입력받은 값들을 나누어준다.이때 잘라진 갯수가 n보다 크면 시작값에 중간값+1을, 작으면 끝값을 중간값-1을 해준다.while문이 다 돌고 나면 그 중 작은 값이 정답이다.start , end= 1,max(lan) #시작값과 끝값 구하기while start&lt;=end: #루프를 돌기위한 조건문    mid=(start+end)//2 #중간값 설정    cutting=0 #잘라진 선의 갯수 선언    for i in lan:        cutting+=i//mid #잘라진 선의 갯수 구하는 for문    if cutting&gt;=n: #n과 잘라진 선의 크기 비교를 통한 중간값 찾기        start=mid+1     else:        end=mid-1print(min(start,end))2001874번 스택 수열https://www.acmicpc.net/problem/1874스택과 푸쉬, 팝 이해하기push를 세 번 하면 [1,2,3] 스택이 쌓이게 되고 여기서 pop을 하면 3이 출력된다.n을 통해 입력할 숫자의 갯수를 입력받고 num을 통해 숫자를 입력받는다.count는 입력받을 숫자가 stack에 입력되도록 해준다. 0으로 두면 0부터 시작이다.따라서 1로 한다.result를 통해 +와 -를 입력받고 stack에는 count에 생긴 숫자들을 쌓아둔다.while문을 통해 stack을 완성하고 if문을 통해 해당 숫자가 나오면 -를 입력한 뒤pop해서 숫자를 제거한다.n=int(input())count=1 #count=1로 해줘야 0부터 숫자를 세지않는다.result=[] # +와 -를 저장하기 위한 리스트stack=[] # 쌓인 숫자를 저장하기 위한 리스트temp=True # 불가능한 경우에 False처리하기 위한 tempfor i in range(n):    num=int(input())     while count&lt;=num: #num과 같거나 작아질때 까지 stack에 숫자를 입력받는다.        stack.append(count)        result.append('+') #입력받은 숫자만큼 결과에 +를 입력해준다.        count=count+1    if stack[-1]==num: #스택의 마지막 숫자가 num과 같을 경우 해당 숫자를 pop하고 -를 입력해준다.        stack.pop()        result.append('-')    else:        temp=False # if문이 적용되지 않는 경우에는 False를 전달해준다.        if temp==False:    print('NO')else:    for j in result:        print(j)843687521++++--++-++-----1920번 스택 수열https://www.acmicpc.net/problem/1920시간초과list를 사용했을 때는 시간초과가 나왔고 set을 이용했을 때는 정상적으로 나왔다.리스트의 in연산자를 통한 포함 여부의 시간 복잡도는 O(N)이다.이분 탐색의 시간 복잡도는 O(logN) 이다.Set과 Dictionary의 in연산을 통한 포함 여부 확인의 시간 복잡도는 O(1)이다.따라서 N만 set으로 받아줘도 시간이 매우 단축된다.n=int(input())N=set(map(int,input().split()))m=int(input())M=list(map(int,input().split()))54 1 5 2 351 3 7 9 5for i in range(m):    if M[i] in N:        print(1)    else:        print(0)11001",
        "url": "/programming-baekjoon2"
    }
    ,
    
    "programming-baekjoon1": {
        "title": "백준 (1) &lt;br&gt; (2557, 8958, 1000, 1001, 1008, &lt;br&gt; 2935, 2753, 2884, 5063,4101)",
            "author": "keonju",
            "category": "",
            "content": "백준 관련 글    백준 (1) (2557, 8958, 1000, 1001, 1008, 2935, 2753, 2884, 5063, 4101)    백준 (2) (1018, 1085, 1181, 1259, 1436, 1654, 1874, 1920)    백준 (3) 문자열 알고리즘(11720, 8958, 1152, 10809, 1157, 9012, 11718)    백준 (4) (1157, 1546, 2577, 2675, 2908, 1018, 1436, 1259, 7568, 10250)    백준 (5) 정렬 알고리즘(2750,11399,2751,1427, 10989,1181,11650)    백준 (6) (3085, 2563, 4673, 5635, 11170)    백준 (7) 스택 알고리즘(10828,10773,1874,10799, 4949,1406,2493)백준 10문제를 풀어보았다.2557. Hello Worldhttps://www.acmicpc.net/problem/2557Hello World!를 출력해야하는데 Hello World를 출력하여서 한번 틀렸다. 문제를 잘 읽어야한다.print(\"Hello World!\")Hello World!8958. OX퀴즈https://www.acmicpc.net/problem/8958for문을 이용하여 입력받을 ox의 갯수를 입력받고 for문 중첩을 이용하여 ox의 길이를 파악하고 if문으로 ox 여부를 확인하였다.ox의 연속성에 따른 점수변화를 num_score로 두고 total_score을 num_score의 합으로 설정하였다.num=int(input())for i in range(num):    ox=input()    total_score=0    num_score=0    for i in range(len(ox)):        if (ox[i]=='O') is True:            num_score=num_score+1        else:            num_score=0        total_score=total_score+num_score    print(total_score)5OOXXOXXOOO10OOXXOOXXOO9OXOXOXOXOXOXOX7OOOOOOOOOO55OOOOXOOOOXOOOOX301000. A+Bhttps://www.acmicpc.net/problem/1000map을 이용하여 a와 b를 사이 공백으로 분류시켜주는 것이 필요한 문제이다.a,b=map(int,input().split())if a &gt;0 and b&lt;10:    print(a+b)1 231001. A-Bhttps://www.acmicpc.net/problem/1001위 문제와 마찬가지로 map을 이용하여 a와 b를 사이 공백으로 분류시켜주는 것이 필요한 문제이다.a,b=map(int,input().split())if a &gt;0 and b&lt;10:    print(a-b)3 211008. A/Bhttps://www.acmicpc.net/problem/1008위 문제와 마찬가지로 map을 이용하여 a와 b를 사이 공백으로 분류시켜주는 것이 필요한 문제이다.무한 소수일 경우a,b=map(int,input().split())if a &gt;0 and b&lt;10:    print(a/b)1 30.3333333333333333유한 소수일 경우a,b=map(int,input().split())if a &gt;0 and b&lt;10:    print(a/b)4 50.82935. 소음https://www.acmicpc.net/problem/2935a와 b는 정수형으로 입력받고 + 와 * 는 문자형으로 입력받았다.a와 b가 10의 제곱 형태이므로 반복문을 통하여 10 ** i, 10 ** j로 제곱 형태를 판별하였고 + 와 * 는 if문으로 구분지어서 계산을 해주었다.파이썬에서는 제곱을 ** 형태로 표현하는 것을 상기해야한다.*를 이용한 경우a=int(input())cal=input()b=int(input())for i in range(99):    for j in range(99):        if (a==10**i) is True and (b==10**j) is True:            if cal=='+':                print(a+b)            if cal=='*':                print(a*b)1000*100100000+를 이용한 경우a=int(input())cal=input()b=int(input())for i in range(99):    for j in range(99):        if (a==10**i) is True and (b==10**j) is True:            if cal=='+':                print(a+b)            if cal=='*':                print(a*b)10000+10100102753. 윤년https://www.acmicpc.net/problem/2753입력받은 연도를 1 이상 4000 이하로 제한하고 연도를 4로 나눈 나머지가 0, 100으로 나눈 나머지가 0이 아닌 경우로 하나, 400으로 나눈 나머지가 0인 경우 하나로 나누어서 1을 출력해주고 나머지는 0을 출력하는 형태로 만들었다.나머지는 %로 구한다는 것을 상기해주었다.윤년인 경우year=int(input())if year&gt;=1 and year&lt;=4000:    if year%4==0 and year%100!=0:        print(1)    elif year%400==0:        print(1)    else:        print(0)20001윤년이 아닌 경우year=int(input())if year&gt;=1 and year&lt;=4000:    if year%4==0 and year%100!=0:        print(1)    elif year%400==0:        print(1)    else:        print(0)199902884. 알람 시계https://www.acmicpc.net/problem/2884위에 사칙연산 문제와 같이 map을 이용해서 시와 분을 분리하여 입력받는다.우선 시를 0 이상 23 이하, 분을 0 이상 59 이하로 한정해었다.첫번째 경우 분이 45 이상일 경우 분에서 45를 빼주더라도 시간은 변하지 않는다. 따라서 시간, 분-45 를 출력해주면 된다.두번째 경우 분이 45 미만일 경우 시가 하나 작아진다. 0 시 45 분 이전에는 날짜가 바뀌므로 23 에서 시를 빼주고 나머지 경우는 시에서 1 빼준다.분이 45 미만일 경우 60 - (45 - 분) 해주면 바뀐 분이 나온다. 따라서 분 + 15 로 표현해 주었다.시와 분 모두 바뀔 때h,m=map(int,input().split())if 0&lt;=h&lt;=23 and 0&lt;=m&lt;=59 :    if m-45&gt;=0:        print(h,m-45)    else:        if h-1&lt;0:            print(23-h,m+15)        else:            print(h-1,m+15)10 109 25날짜 까지 바뀔 때h,m=map(int,input().split())if 0&lt;=h&lt;=23 and 0&lt;=m&lt;=59 :    if m-45&gt;=0:        print(h,m-45)    else:        if h-1&lt;0:            print(23-h,m+15)        else:            print(h-1,m+15)0 3023 455063. TGNhttps://www.acmicpc.net/problem/5063test_case를 입력받아서 for문의 횟수를 한정시킨다.r, e, c를 map을 이용하여 입력받았으며 범위를 한정시켜주었다. 이때 (-10) ** 6으로 잘못 작성하여서 코드가 실행되지 않았다.광고 비용이 광고 수익과 일반 수익의 차보다 작을 때 광고를 하고 같으면 소용이 없고 크면 광고를 하지 않아야하므로 if문으로 구분시켰다.test_case=int(input())for i in range(test_case):    r,e,c=map(int,input().split())    if -(10**6)&lt;=r&lt;=(10**6) and -(10**6)&lt;=e&lt;=(10**6) and 0&lt;=c&lt;=(10**6):        if e-r&gt;c:            print('advertise')        elif e-r==c:            print('does not matter')        else:            print('do not advertise')30 100 70advertise100 130 30does not matter-100 -70 40do not advertise4101. 크냐?https://www.acmicpc.net/problem/4101while 반복문을 사용하여 계속 두 숫자를 입력받았으며 map을 통하여 공백을 기준으로 숫자를 나누었다.먼저 두 숫자가 0이면 해당 while문이 정지를 하게 만들어주고, 그 뒤에 두 숫자의 범위가 True면 두 숫자의 대소비교를 진행하였다.while True:    a,b=map(int,input().split())    if a==0 and b==0:            break    if 0&lt;a&lt;=10**6 and 0&lt;b&lt;=10**6:        if a&gt;b:            print(\"Yes\")        else:            print(\"No\")1 19No4 4No23 14Yes0 0",
        "url": "/programming-baekjoon1"
    }
    ,
    
    "programming-webcrawling1": {
        "title": "웹크롤링 (1) &lt;br&gt; urllib사용을 통한 크롤링",
            "author": "keonju",
            "category": "",
            "content": "웹크롤링 관련 글    웹크롤링 (1)-urllib사용을 통한 크롤링urllib사용을 통한 크롤링  url을 입력하여 작동하는 라이브러리로 통신을 통해 데이터를 주고받는 기능을 한다.  데이터를 받아오거나 다운로드할 수 있다1.urlretrieve  url로 표시된 네트워크 정보를 파일로 저장할 수 있는 기능 (이미지 , html)  (filename, headers) 튜플로 반환  ex file, header = req.urlretrieve(url, path)import urllib.request as requrl 에 접근할 url주소를 담고, path에 저장할 경로와 파일명을 적으면 된다.파일명만 적을 경우 현재 위치로 저장이 된다.url = \"https://search.pstatic.net/common/?src=http%3A%2F%2Fblogfiles.naver.net%2FMjAyMTA4MjBfMTQx%2FMDAxNjI5NDIxNjQ5NzM5.D1F-l6COowiUicFVRlpfQeSJRtkR4f9lkbVZgwJm6r4g.lBjYtG_wiubtJdiCYg8reMDwyC3wkFhPy5Ou0VXWRIQg.JPEG.hyun_0930%2F1629420539963.jpg&amp;type=sc960_832\"path = \"test1.jpg\"url'https://search.pstatic.net/common/?src=http%3A%2F%2Fblogfiles.naver.net%2FMjAyMTA4MjBfMTQx%2FMDAxNjI5NDIxNjQ5NzM5.D1F-l6COowiUicFVRlpfQeSJRtkR4f9lkbVZgwJm6r4g.lBjYtG_wiubtJdiCYg8reMDwyC3wkFhPy5Ou0VXWRIQg.JPEG.hyun_0930%2F1629420539963.jpg&amp;type=sc960_832'path'test1.jpg'현재위치 조회import osos.getcwd()file, header = req.urlretrieve(url,path)print(file)test1.jpgprint(header)accept-ranges: bytescache-control: max-age=2592000content-length: 37532content-type: image/jpegexpires: Sun, 26 Sep 2021 23:53:24 GMTlast-modified: Fri, 27 Aug 2021 23:53:24 GMTp3p: CP=\"ALL CURa ADMa DEVa TAIa OUR BUS IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE LOC OTC\"date: Fri, 27 Aug 2021 23:53:24 GMTage: 665797server: Testa/5.1.1strict-transport-security: max-age=31536000connection: closehtml저장url2 = \"https://www.naver.com/\"path2 = \"naver.html\"file2, header2 = req.urlretrieve(url2, path2)print(\"----------------------------------------------------\")print(f\"file name: {file}\")print(\"----------------------------------------------------\")print(\"Header Info :\")print(header)print(\"----------------------------------------------------\")print(f\"file name: {file2}\")print(\"----------------------------------------------------\")print(\"Header Info :\")print(header2)----------------------------------------------------file name: test1.jpg----------------------------------------------------Header Info :accept-ranges: bytescache-control: max-age=2592000content-length: 37532content-type: image/jpegexpires: Sun, 26 Sep 2021 23:53:24 GMTlast-modified: Fri, 27 Aug 2021 23:53:24 GMTp3p: CP=\"ALL CURa ADMa DEVa TAIa OUR BUS IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE LOC OTC\"date: Fri, 27 Aug 2021 23:53:24 GMTage: 665797server: Testa/5.1.1strict-transport-security: max-age=31536000connection: close----------------------------------------------------file name: naver.html----------------------------------------------------Header Info :Server: NWSDate: Sat, 04 Sep 2021 16:50:00 GMTContent-Type: text/html; charset=UTF-8Transfer-Encoding: chunkedConnection: closeSet-Cookie: PM_CK_loc=4d397054570413bd11c4b9094901203f9fef0e3df1bd78a55cef2ac0fd1d9e5e; Expires=Sun, 05 Sep 2021 16:50:00 GMT; Path=/; HttpOnlyCache-Control: no-cache, no-store, must-revalidatePragma: no-cacheP3P: CP=\"CAO DSP CURa ADMa TAIa PSAa OUR LAW STP PHY ONL UNI PUR FIN COM NAV INT DEM STA PRE\"X-Frame-Options: DENYX-XSS-Protection: 1; mode=blockStrict-Transport-Security: max-age=63072000; includeSubdomainsReferrer-Policy: unsafe-url2.urlerror  크롤링에서 발생할 수 있는 에러처리  에러처리를 통해서 어떤 에러가 발생하였는지 파악하고 코드를 수정  URLError: 요청한 곳의 서버가 없거나 네트워크 연결이 없는 상황  HTTPError: HTTP응답에 있는 status에 따라서 상태를 반환, status코드에 따라서 에러 유형이 다름  주의사항: URLError가 HTTPError도 잡기 때문에 HTTPError처리를 먼저 해줘야함1번 예제와 다르게 list에 넣고 for문을 통한 이미지 다운로드를 실시from urllib.error import URLError, HTTPErrorurl_list = ['https://search.pstatic.net/common/?src=http%3A%2F%2Fblogfiles.naver.net%2FMjAyMTA4MjBfMTQx%2FMDAxNjI5NDIxNjQ5NzM5.D1F-l6COowiUicFVRlpfQeSJRtkR4f9lkbVZgwJm6r4g.lBjYtG_wiubtJdiCYg8reMDwyC3wkFhPy5Ou0VXWRIQg.JPEG.hyun_0930%2F1629420539963.jpg&amp;type=sc960_832',            'https://search.pstatic.net/common/?src=http%3A%2F%2Fblogfiles.naver.net%2FMjAyMDA5MTNfNjMg%2FMDAxNjAwMDAxNjM1NzQ2.TuGLdOsJ8vLFnN589WEiiA5j5XrsWRA7lJUJicpozJwg.694y_QRQKQwqd7QR41nweA3T4vYnAGT4OqVuxWvJdrYg.JPEG.ecoanimal%2F51d63faf6312a3bc4873ee24d98cdfed.jpg&amp;type=a340']name_list = ['nuguli1.jpg', 'nuguli2.jpg']for i,url in enumerate(url_list):    # 예외 처리    try:        # 웹 수신 정보 읽기        response = req.urlopen(url)                # 수신 내용        contents = response.read()        print('----------------------------------------------------------------------------------------------------------------')        # 상태 정보 중간 출력        print(f'file_name : {name_list[i]}')        print('&lt;Header Info&gt;')        print(f'{response.info()}')        print(f'Status Code : {response.getcode()}')        print()        print('----------------------------------------------------------------------------------------------------------------')        # 파일 쓰기        with open(name_list[i], 'wb') as c:            c.write(contents)            except HTTPError as e: # HTTP 에러        print(\"다운로드 실패.\")        print('HTTPError Code : ', e.code)    except URLError as e: # URL 에러        print(\"Download failed.\")        print('URL Error Reason : ', e.reason)        # 성공    else:        print()        print(f'{name_list[i]}이미지 다운 완료.')----------------------------------------------------------------------------------------------------------------file_name : nuguli1.jpg&lt;Header Info&gt;accept-ranges: bytescache-control: max-age=2592000content-length: 37532content-type: image/jpegexpires: Sun, 26 Sep 2021 23:53:24 GMTlast-modified: Fri, 27 Aug 2021 23:53:24 GMTp3p: CP=\"ALL CURa ADMa DEVa TAIa OUR BUS IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE LOC OTC\"date: Fri, 27 Aug 2021 23:53:24 GMTage: 665797server: Testa/5.1.1strict-transport-security: max-age=31536000connection: closeStatus Code : 200----------------------------------------------------------------------------------------------------------------nuguli1.jpg이미지 다운 완료.----------------------------------------------------------------------------------------------------------------file_name : nuguli2.jpg&lt;Header Info&gt;accept-ranges: bytescache-control: max-age=2592000content-length: 50098content-type: image/jpegexpires: Fri, 24 Sep 2021 14:11:17 GMTlast-modified: Wed, 25 Aug 2021 14:11:17 GMTp3p: CP=\"ALL CURa ADMa DEVa TAIa OUR BUS IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE LOC OTC\"date: Wed, 25 Aug 2021 14:11:17 GMTage: 873524server: Testa/5.1.1strict-transport-security: max-age=31536000connection: closeStatus Code : 200----------------------------------------------------------------------------------------------------------------nuguli2.jpg이미지 다운 완료.3.urlopen/ urlparseimport urllib.request as reqfrom urllib.parse import urlparseurl=\"https://www.seoultech.ac.kr/index.jsp\"ele=req.urlopen(url)print('type : {}'.format(type(ele)))print()print(\"geturl : {}\".format(ele.geturl()))print()print(\"status : {}\".format(ele.status))print()print(\"headers : {}\".format(ele.getheaders()))print()print()print('parse : {}'.format(urlparse('https://www.smu.ac.kr/ko/index.do?param=test').query))print()type : &lt;class 'http.client.HTTPResponse'&gt;geturl : https://www.seoultech.ac.kr/index.jspstatus : 200headers : [('Date', 'Sat, 04 Sep 2021 16:50:01 GMT'), ('Content-Type', 'text/html; charset=UTF-8'), ('Set-Cookie', 'JSESSIONID=5BabR1bj8eGHwllZbNNO9LXiYD2V1HlqI1KZJiR7EG01ZnEBpYTlBwaFVwCi61YT.web1_servlet_www;Path=/;HttpOnly'), ('X-Cache', 'MISS from cf4.seoultech.ac.kr'), ('X-Cache-Lookup', 'HIT from cf4.seoultech.ac.kr:3128'), ('Transfer-Encoding', 'chunked'), ('Via', ''), ('Connection', 'close')]parse : param=testprint(ele.info())Date: Sat, 04 Sep 2021 16:50:01 GMTContent-Type: text/html; charset=UTF-8Set-Cookie: JSESSIONID=5BabR1bj8eGHwllZbNNO9LXiYD2V1HlqI1KZJiR7EG01ZnEBpYTlBwaFVwCi61YT.web1_servlet_www;Path=/;HttpOnlyX-Cache: MISS from cf4.seoultech.ac.krX-Cache-Lookup: HIT from cf4.seoultech.ac.kr:3128Transfer-Encoding: chunkedVia: Connection: closeheaders에 데이터 추가하기# pip install fake_useragentfrom fake_useragent import UserAgentua = UserAgent()### fake_useragentua = UserAgent()print(ua.random)print(ua.ie)print(ua.msie)print(ua['Internet Explorer'])print(ua.opera)print(ua.chrome)print(ua.google)print(ua['google chrome'])print(ua.firefox)print(ua.ff)print(ua.safari)Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.3319.102 Safari/537.36Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/4.0; GTB7.4; InfoPath.1; SV1; .NET CLR 2.8.52393; WOW64; en-US)Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.2; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0)Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0; FunWebProducts)Mozilla/5.0 (Windows NT 5.1; U; en; rv:1.8.1) Gecko/20061208 Firefox/5.0 Opera 11.11Mozilla/5.0 (Windows NT 6.4; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2225.0 Safari/537.36Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1468.0 Safari/537.36Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:23.0) Gecko/20131011 Firefox/23.0Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20130401 Firefox/31.0Mozilla/5.0 (Windows; U; Windows NT 6.0; de-DE) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4야후 파이낸스 데이터 받아오기import jsonimport urllib.request as reqfrom fake_useragent import UserAgent  url 주소를 찾는 것에서 시간이 조금 걸림이미지같은 경우 주소가 연동되지만 변동되는 데이터는 적용되지않음크롬 개발자도구에서 Network항목에서 RequestURL 찾기import jsonimport urllib.request as reqfrom fake_useragent import UserAgent# Fake Header 정보(가상으로 User-Agent 생성)ua = UserAgent()# 헤더 선언headers = {    'User-Agent': ua.ie,    'referer': 'https://finance.yahoo.com/'}# 다음 주식 요청 URLurl = \"https://query1.finance.yahoo.com/v7/finance/quote?formatted=true&amp;crumb=5b5ru0zoR.q&amp;lang=en-US&amp;region=US&amp;symbols=ADA-USD%2CBTC-USD%2CDOGE-USD%2CETH-USD%2CZM&amp;fields=symbol%2CshortName%2ClongName%2CregularMarketPrice%2CregularMarketChange%2CregularMarketChangePercent&amp;corsDomain=finance.yahoo.com\"res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')# 응답 데이터 str -&gt; json 변환 및 data 값 저장_json_data = json.loads(res)print( _json_data, '\\n'){'quoteResponse': {'result': [{'fullExchangeName': 'CCC', 'exchangeTimezoneName': 'Europe/London', 'symbol': 'ADA-USD', 'regularMarketChange': {'raw': -0.12517643, 'fmt': '-0.13'}, 'gmtOffSetMilliseconds': 3600000, 'firstTradeDateMilliseconds': 1506812400000, 'exchangeDataDelayedBy': 0, 'language': 'en-US', 'regularMarketTime': {'raw': 1630774030, 'fmt': '5:47PM BST'}, 'regularMarketChangePercent': {'raw': -4.1827593, 'fmt': '-4.18%'}, 'exchangeTimezoneShortName': 'BST', 'quoteType': 'CRYPTOCURRENCY', 'marketState': 'REGULAR', 'regularMarketPrice': {'raw': 2.8674967, 'fmt': '2.87'}, 'market': 'ccc_market', 'quoteSourceName': 'CoinMarketCap', 'tradeable': False, 'exchange': 'CCC', 'sourceInterval': 15, 'shortName': 'Cardano USD', 'region': 'US', 'regularMarketPreviousClose': {'raw': 2.9606647, 'fmt': '2.96'}, 'triggerable': True}, {'fullExchangeName': 'CCC', 'exchangeTimezoneName': 'Europe/London', 'symbol': 'BTC-USD', 'regularMarketChange': {'raw': -611.96094, 'fmt': '-611.96'}, 'gmtOffSetMilliseconds': 3600000, 'firstTradeDateMilliseconds': 1410908400000, 'exchangeDataDelayedBy': 0, 'language': 'en-US', 'regularMarketTime': {'raw': 1630774082, 'fmt': '5:48PM BST'}, 'regularMarketChangePercent': {'raw': -1.2106228, 'fmt': '-1.21%'}, 'exchangeTimezoneShortName': 'BST', 'quoteType': 'CRYPTOCURRENCY', 'marketState': 'REGULAR', 'regularMarketPrice': {'raw': 49937.133, 'fmt': '49,937.13'}, 'market': 'ccc_market', 'quoteSourceName': 'CoinMarketCap', 'tradeable': False, 'exchange': 'CCC', 'sourceInterval': 15, 'shortName': 'Bitcoin USD', 'region': 'US', 'regularMarketPreviousClose': {'raw': 49922.355, 'fmt': '49,922.36'}, 'triggerable': True}, {'fullExchangeName': 'CCC', 'exchangeTimezoneName': 'Europe/London', 'symbol': 'DOGE-USD', 'regularMarketChange': {'raw': 0.0015876293, 'fmt': '0.00'}, 'gmtOffSetMilliseconds': 3600000, 'firstTradeDateMilliseconds': 1410908400000, 'exchangeDataDelayedBy': 0, 'language': 'en-US', 'regularMarketTime': {'raw': 1630774083, 'fmt': '5:48PM BST'}, 'regularMarketChangePercent': {'raw': 0.52755743, 'fmt': '0.53%'}, 'exchangeTimezoneShortName': 'BST', 'quoteType': 'CRYPTOCURRENCY', 'marketState': 'REGULAR', 'regularMarketPrice': {'raw': 0.30252412, 'fmt': '0.30'}, 'market': 'ccc_market', 'quoteSourceName': 'CoinMarketCap', 'tradeable': False, 'exchange': 'CCC', 'sourceInterval': 15, 'shortName': 'Dogecoin USD', 'region': 'US', 'regularMarketPreviousClose': {'raw': 0.29575953, 'fmt': '0.30'}, 'triggerable': True}, {'fullExchangeName': 'CCC', 'exchangeTimezoneName': 'Europe/London', 'symbol': 'ETH-USD', 'regularMarketChange': {'raw': -63.86255, 'fmt': '-63.86'}, 'gmtOffSetMilliseconds': 3600000, 'firstTradeDateMilliseconds': 1438902000000, 'exchangeDataDelayedBy': 0, 'language': 'en-US', 'regularMarketTime': {'raw': 1630774082, 'fmt': '5:48PM BST'}, 'regularMarketChangePercent': {'raw': -1.608492, 'fmt': '-1.61%'}, 'exchangeTimezoneShortName': 'BST', 'quoteType': 'CRYPTOCURRENCY', 'marketState': 'REGULAR', 'regularMarketPrice': {'raw': 3906.476, 'fmt': '3,906.48'}, 'market': 'ccc_market', 'quoteSourceName': 'CoinMarketCap', 'tradeable': False, 'exchange': 'CCC', 'sourceInterval': 15, 'shortName': 'Ethereum USD', 'region': 'US', 'regularMarketPreviousClose': {'raw': 3933.8274, 'fmt': '3,933.83'}, 'triggerable': True}, {'fullExchangeName': 'NasdaqGS', 'symbol': 'ZM', 'gmtOffSetMilliseconds': -14400000, 'language': 'en-US', 'regularMarketTime': {'raw': 1630699203, 'fmt': '4:00PM EDT'}, 'regularMarketChangePercent': {'raw': 1.084419, 'fmt': '1.08%'}, 'quoteType': 'EQUITY', 'tradeable': False, 'regularMarketPreviousClose': {'raw': 295.09, 'fmt': '295.09'}, 'exchangeTimezoneName': 'America/New_York', 'regularMarketChange': {'raw': 3.2000122, 'fmt': '3.20'}, 'firstTradeDateMilliseconds': 1555594200000, 'exchangeDataDelayedBy': 0, 'exchangeTimezoneShortName': 'EDT', 'marketState': 'CLOSED', 'regularMarketPrice': {'raw': 298.29, 'fmt': '298.29'}, 'market': 'us_market', 'quoteSourceName': 'Delayed Quote', 'priceHint': 2, 'exchange': 'NMS', 'sourceInterval': 15, 'shortName': 'Zoom Video Communications, Inc.', 'region': 'US', 'triggerable': True, 'longName': 'Zoom Video Communications, Inc.'}], 'error': None}} data_list=_json_data['quoteResponse']['result']from pprint import pprintpprint(data_list)[{'exchange': 'CCC',  'exchangeDataDelayedBy': 0,  'exchangeTimezoneName': 'Europe/London',  'exchangeTimezoneShortName': 'BST',  'firstTradeDateMilliseconds': 1506812400000,  'fullExchangeName': 'CCC',  'gmtOffSetMilliseconds': 3600000,  'language': 'en-US',  'market': 'ccc_market',  'marketState': 'REGULAR',  'quoteSourceName': 'CoinMarketCap',  'quoteType': 'CRYPTOCURRENCY',  'region': 'US',  'regularMarketChange': {'fmt': '-0.13', 'raw': -0.12517643},  'regularMarketChangePercent': {'fmt': '-4.18%', 'raw': -4.1827593},  'regularMarketPreviousClose': {'fmt': '2.96', 'raw': 2.9606647},  'regularMarketPrice': {'fmt': '2.87', 'raw': 2.8674967},  'regularMarketTime': {'fmt': '5:47PM BST', 'raw': 1630774030},  'shortName': 'Cardano USD',  'sourceInterval': 15,  'symbol': 'ADA-USD',  'tradeable': False,  'triggerable': True}, {'exchange': 'CCC',  'exchangeDataDelayedBy': 0,  'exchangeTimezoneName': 'Europe/London',  'exchangeTimezoneShortName': 'BST',  'firstTradeDateMilliseconds': 1410908400000,  'fullExchangeName': 'CCC',  'gmtOffSetMilliseconds': 3600000,  'language': 'en-US',  'market': 'ccc_market',  'marketState': 'REGULAR',  'quoteSourceName': 'CoinMarketCap',  'quoteType': 'CRYPTOCURRENCY',  'region': 'US',  'regularMarketChange': {'fmt': '-611.96', 'raw': -611.96094},  'regularMarketChangePercent': {'fmt': '-1.21%', 'raw': -1.2106228},  'regularMarketPreviousClose': {'fmt': '49,922.36', 'raw': 49922.355},  'regularMarketPrice': {'fmt': '49,937.13', 'raw': 49937.133},  'regularMarketTime': {'fmt': '5:48PM BST', 'raw': 1630774082},  'shortName': 'Bitcoin USD',  'sourceInterval': 15,  'symbol': 'BTC-USD',  'tradeable': False,  'triggerable': True}, {'exchange': 'CCC',  'exchangeDataDelayedBy': 0,  'exchangeTimezoneName': 'Europe/London',  'exchangeTimezoneShortName': 'BST',  'firstTradeDateMilliseconds': 1410908400000,  'fullExchangeName': 'CCC',  'gmtOffSetMilliseconds': 3600000,  'language': 'en-US',  'market': 'ccc_market',  'marketState': 'REGULAR',  'quoteSourceName': 'CoinMarketCap',  'quoteType': 'CRYPTOCURRENCY',  'region': 'US',  'regularMarketChange': {'fmt': '0.00', 'raw': 0.0015876293},  'regularMarketChangePercent': {'fmt': '0.53%', 'raw': 0.52755743},  'regularMarketPreviousClose': {'fmt': '0.30', 'raw': 0.29575953},  'regularMarketPrice': {'fmt': '0.30', 'raw': 0.30252412},  'regularMarketTime': {'fmt': '5:48PM BST', 'raw': 1630774083},  'shortName': 'Dogecoin USD',  'sourceInterval': 15,  'symbol': 'DOGE-USD',  'tradeable': False,  'triggerable': True}, {'exchange': 'CCC',  'exchangeDataDelayedBy': 0,  'exchangeTimezoneName': 'Europe/London',  'exchangeTimezoneShortName': 'BST',  'firstTradeDateMilliseconds': 1438902000000,  'fullExchangeName': 'CCC',  'gmtOffSetMilliseconds': 3600000,  'language': 'en-US',  'market': 'ccc_market',  'marketState': 'REGULAR',  'quoteSourceName': 'CoinMarketCap',  'quoteType': 'CRYPTOCURRENCY',  'region': 'US',  'regularMarketChange': {'fmt': '-63.86', 'raw': -63.86255},  'regularMarketChangePercent': {'fmt': '-1.61%', 'raw': -1.608492},  'regularMarketPreviousClose': {'fmt': '3,933.83', 'raw': 3933.8274},  'regularMarketPrice': {'fmt': '3,906.48', 'raw': 3906.476},  'regularMarketTime': {'fmt': '5:48PM BST', 'raw': 1630774082},  'shortName': 'Ethereum USD',  'sourceInterval': 15,  'symbol': 'ETH-USD',  'tradeable': False,  'triggerable': True}, {'exchange': 'NMS',  'exchangeDataDelayedBy': 0,  'exchangeTimezoneName': 'America/New_York',  'exchangeTimezoneShortName': 'EDT',  'firstTradeDateMilliseconds': 1555594200000,  'fullExchangeName': 'NasdaqGS',  'gmtOffSetMilliseconds': -14400000,  'language': 'en-US',  'longName': 'Zoom Video Communications, Inc.',  'market': 'us_market',  'marketState': 'CLOSED',  'priceHint': 2,  'quoteSourceName': 'Delayed Quote',  'quoteType': 'EQUITY',  'region': 'US',  'regularMarketChange': {'fmt': '3.20', 'raw': 3.2000122},  'regularMarketChangePercent': {'fmt': '1.08%', 'raw': 1.084419},  'regularMarketPreviousClose': {'fmt': '295.09', 'raw': 295.09},  'regularMarketPrice': {'fmt': '298.29', 'raw': 298.29},  'regularMarketTime': {'fmt': '4:00PM EDT', 'raw': 1630699203},  'shortName': 'Zoom Video Communications, Inc.',  'sourceInterval': 15,  'symbol': 'ZM',  'tradeable': False,  'triggerable': True}]result_list = []for data in data_list:    _set={}    _set['symbol'] = data['symbol']    _set['Last_price'] = data['regularMarketPrice']['fmt']    _set['Change'] = data['regularMarketChange']['fmt']    _set['%Change'] = data['regularMarketChangePercent']['fmt']    result_list.append(_set)import pandas as pddf = pd.DataFrame(result_list)df                  symbol      Last_price      Change      %Change                  0      ADA-USD      2.87      -0.13      -4.18%              1      BTC-USD      49,937.13      -611.96      -1.21%              2      DOGE-USD      0.30      0.00      0.53%              3      ETH-USD      3,906.48      -63.86      -1.61%              4      ZM      298.29      3.20      1.08%      ",
        "url": "/programming-webcrawling1"
    }
    ,
    
    "project-first": {
        "title": "project 연습글",
            "author": "keonju",
            "category": "",
            "content": "project 게시글 목록    project 연습글프로젝트 게시판 첫 글 연습",
        "url": "/project-first"
    }
    
    
    };
</script>
<script src="assets/js/lunr.js"></script>
<script src="assets/js/search.js"></script>
            </section>

        </article>

    </div>
</main>

<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->
<script>
$(function() {
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
});
</script>



        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://keonju2.github.io/">주건나's Blog</a> &copy; 2021</section>
                <!--
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                -->
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    <a href="https://facebook.com/monkeykeonju" target="_blank" rel="noopener">Facebook</a>
                    
                    <!--
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                     -->
                </nav>

            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
    <div id="subscribe" class="subscribe-overlay">
        <a class="subscribe-overlay-close" href="#"></a>
        <div class="subscribe-overlay-content">
            
            <h1 class="subscribe-overlay-title">Search 주건나's Blog</h1>
            <p class="subscribe-overlay-description">
            검색어를 입력해주세요 </p>
            <span id="searchform" method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  />
    <input class="location" type="hidden" name="location"  />
    <input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" onkeyup="myFunc()" 
               id="searchtext" type="text" name="searchtext"  
               placeholder="Search..." />
    </div>
    <script type="text/javascript">
        function myFunc() {
            if(event.keyCode == 13) {
                var url = encodeURIComponent($("#searchtext").val());
                location.href = "/search.html?query=" + url;
            }
        }
    </script>
</span>
        </div>
    </div>
    


    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'G-6FJ2289869', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>
$(function() {
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
